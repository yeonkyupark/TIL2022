[["index.html", "Today I Learned in 2022 시작하며", " Today I Learned in 2022 PARK Yeonkyu 2022-09-01 시작하며 1/01 github에 매일매일 잔디 심고 있었다. 2/18 github를 청소해 보겠다고 repo를 전체 삭제했다. 잔디도 깔끔하게 같이 사라졌다. 다시 시작하는걸로... "],["년-01월.html", "1 2022년 01월", " 1 2022년 01월 2월 18일, 날짜도 참… 심어 두었던 잔디를 모두 날려 먹었다. "],["년-02월.html", "2 2022년 02월 ", " 2 2022년 02월 "],["til20220201.html", "2.1 TIL20220201", " 2.1 TIL20220201 "],["til20220202.html", "2.2 TIL20220202", " 2.2 TIL20220202 "],["til20220203.html", "2.3 TIL20220203", " 2.3 TIL20220203 "],["til20220204.html", "2.4 TIL20220204", " 2.4 TIL20220204 "],["til20220205.html", "2.5 TIL20220205", " 2.5 TIL20220205 "],["til20220206.html", "2.6 TIL20220206", " 2.6 TIL20220206 "],["til20220207.html", "2.7 TIL20220207", " 2.7 TIL20220207 "],["til20220208.html", "2.8 TIL20220208", " 2.8 TIL20220208 "],["til20220209.html", "2.9 TIL20220209", " 2.9 TIL20220209 "],["til20220210.html", "2.10 TIL20220210", " 2.10 TIL20220210 "],["til20220211.html", "2.11 TIL20220211", " 2.11 TIL20220211 "],["til20220212.html", "2.12 TIL20220212", " 2.12 TIL20220212 "],["til20220213.html", "2.13 TIL20220213", " 2.13 TIL20220213 "],["til20220214.html", "2.14 TIL20220214", " 2.14 TIL20220214 "],["til20220215.html", "2.15 TIL20220215", " 2.15 TIL20220215 "],["til20220216.html", "2.16 TIL20220216", " 2.16 TIL20220216 "],["til20220217.html", "2.17 TIL20220217", " 2.17 TIL20220217 "],["til20220218.html", "2.18 TIL20220218", " 2.18 TIL20220218 2.18.1 github repo 삭제하면 잔디도 죽는다 사용하던 github repo를 모두 삭제했다. repo가 삭제되면 심어 두었던 잔디도 같이 죽는다는 것을 알게 되었다. 덕분에 깨끗한 마음으로 새로 시작할 수 있을 것 같다 ‘^’ 2.18.2 bookdown으로 블로그 전환 jekyll로 잘 운영하던 블로그를 bookdown으로 이사, 일단 가볍고 문서 작성하기 편하고 체계적이고, 무엇보다 기존 repo 싹 날려서 그렇다. RStudio, Bookdown, Github pages 등으로 검색하면 여러 정보를 얻을 수 있다. 중간중간 설명이 필요한 부분도 있지만 우선 여기 참조하면 세팅할 수 있다. "],["til20220219.html", "2.19 TIL20220219", " 2.19 TIL20220219 2.19.1 netlify와 bookdown 연동 https://bookdown.org/yihui/blogdown/netlify.html "],["til20220220.html", "2.20 TIL20220220", " 2.20 TIL20220220 2.20.1 netlify 자동 배포 1 rendering 안해도 netlify에 deploy되나 (’’ ?) 우선 rendering된 docs 폴더를 netlify에 연결하는 걸로 하자. 2.20.2 netlify 자동 배포 2 https://www.emilhvitfeldt.com/post/bookdown-netlify-github-actions/ 1차 실패 2차 진행 중 … 3차, 편한 방법을 찾자. "],["til20220221.html", "2.21 TIL20220221", " 2.21 TIL20220221 2.21.1 Github Actions를 이용한 자동 배포 세상은 넓고 똑똑한 사람은 참 많은 것 같다. ref to: How to publish bookdown projects with GitHub Actions on GitHub Pages 2.21.2 실습 RStudio에서 bookdown project를 하나 만든다. GitHub에서 Repository를 하나 만든다. 둘이 연결한다. GitHub Actions를 위한 workflows를 생성한다. usethis::use_github_action(url = &quot;https://raw.githubusercontent.com/ropenscilabs/actions_sandbox/main/.github/workflows/deploy_bookdown.yml&quot;) 배포할 브랜치를 변경해 준다. 코드 업데이트 후 정상 동작 확인한다. ! 주의 deploy_bookdown.yml의 branch 이름 확인할 것, 최근에 master에서 main으로 변경됨 bookdown의 _bookdown.yml의 output_dir과 deploy_bookdown.yml의 build_dir 일치시킬 것 repository에 build_dir(_book)가 없으면 만들어 둘 것 "],["til20220222.html", "2.22 TIL20220222", " 2.22 TIL20220222 2.22.1 code snippet in R RStudio에서 snippet 설정을 한다. Tools → Global Options → Code → Editing → Snippets image # snippet 등록 snippet myggplot # 코드 작성 시 반드시 tab으로 띄워쓰기 할 것 p &lt;- ggplot(data = ${1:데이터}, aes(x=${2:변수1}, y=${3:변수2}, col=${4:범주1}, fill=${5:범주2})) + geom_${6:그래프종류}() + labs(title=&quot;${7:그래프제목}&quot;, x=&quot;${8:x축}&quot;, y=&quot;${9:y축}&quot;) + theme_bw() p "],["til20220223.html", "2.23 TIL20220223", " 2.23 TIL20220223 2.23.1 rstudio.cloud PAT 업데이트 https://stackoverflow.com/questions/66065099/how-to-update-github-authentification-token-on-rstudio-to-match-the-new-policy credentials::set_gethub_pat() image 위 코드로 해결함. 2.23.2 파비콘 만들기 https://www.favicon-generator.org "],["til20220224.html", "2.24 TIL20220224", " 2.24 TIL20220224 2.24.1 RStudio + bookdown + github 배포하기 GitHub Repository 생성하기 생성된 Git Repo로 RStudio 빈 Project 생성하기 Bookdown Project 생성하기 생성된 Project GitHub에 올리기 git checkout main git add . git commit -m &#39;1st commit on main&#39; git push origin main GitHub Action workflow 생성하기 gh-pages 브랜치를 생성한다. git checkout --orphan gh-pages git rm -rf . git commit --allow-empty -m &#39;1st commit on gh-pages&#39; git push origin gh-pages git checkout main RStudio Console에서 Workflow를 생성한다. usethis::use_github_action(url = &quot;https://raw.githubusercontent.com/ropenscilabs/actions_sandbox/main/.github/workflows/deploy_bookdown.yml&quot;) 수정된 파일 GitHub에 올리기 Workflow 및 배포된 페이지 확인하기 page 생성/수정 후 정상동작 확인하기 https://yeonkyupark.github.io/Rdataanalysis/ "],["til20220225.html", "2.25 TIL20220225", " 2.25 TIL20220225 2.25.1 R에서 데이터 읽어 오기 csv 포멧으로 사용하는게 가장 편하고, 파일 형식이 다른 경우 csv 파일 형태로 변환하여 사용하길 추천. 여건이 되지 않으면 구글링해서 해당 포멧 처리하는 것으로, 하지만 가능하면 엑셀로 기본 전처리 후 csv로 변환하여 사용. read.csv(file, header = TRUE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;, fill = TRUE, comment.char = &quot;&quot;, ...) "],["til20220226.html", "2.26 TIL20220226", " 2.26 TIL20220226 2.26.1 데이터 훑어보기 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;) library(palmerpenguins) } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages 우선 데이터 구조는 str() 일반적으로 summary()를 통해 수치 연산 결과를 전체적인 모습을 살펴볼 수 있다. # base package summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 skimr 패키지의 skim()을 통해 유사한 수치연산 결과를 보다 가독성이 좋은 형태로 출력해 준다. if(!require(skimr)) { install.packages(&quot;skimr&quot;) library(skimr) } ## ## There is a binary version available but the source version is later: ## binary source needs_compilation ## dplyr 1.0.9 1.0.10 TRUE ## ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages skim(penguins) TABLE 2.1: Data summary Name penguins Number of rows 344 Number of columns 8 _______________________ Column type frequency: factor 3 numeric 5 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts species 0 1.00 FALSE 3 Ade: 152, Gen: 124, Chi: 68 island 0 1.00 FALSE 3 Bis: 168, Dre: 124, Tor: 52 sex 11 0.97 FALSE 2 mal: 168, fem: 165 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist bill_length_mm 2 0.99 43.92 5.46 32.1 39.23 44.45 48.5 59.6 ▃▇▇▆▁ bill_depth_mm 2 0.99 17.15 1.97 13.1 15.60 17.30 18.7 21.5 ▅▅▇▇▂ flipper_length_mm 2 0.99 200.92 14.06 172.0 190.00 197.00 213.0 231.0 ▂▇▃▅▂ body_mass_g 2 0.99 4201.75 801.95 2700.0 3550.00 4050.00 4750.0 6300.0 ▃▇▆▃▂ year 0 1.00 2008.03 0.82 2007.0 2007.00 2008.00 2009.0 2009.0 ▇▁▇▁▇ "],["til20220227.html", "2.27 TIL20220227", " 2.27 TIL20220227 2.27.1 GitHub에 파일 올리기 연습용 csv 파일 올리기, GitHub Edit 창에 Drop&amp;Drop으로 등록할 수 있다. Sample_w_Header.csv Sample_wo_Header.csv sample &lt;- read.csv(&quot;https://github.com/yeonkyupark/TIL2022/files/8148798/Sample_w_Header.csv&quot;, fileEncoding=&quot;UTF-8-BOM&quot;) colnames(sample) ## [1] &quot;Time&quot; &quot;LSL&quot; &quot;USL&quot; &quot;Measure&quot; &quot;Result&quot; sample &lt;- read.csv(&quot;https://github.com/yeonkyupark/TIL2022/files/8148798/Sample_w_Header.csv&quot;) colnames(sample) ## [1] &quot;Time&quot; &quot;LSL&quot; &quot;USL&quot; &quot;Measure&quot; &quot;Result&quot; 읽어들인 첫번째 데이터가 깨지는 경우 인코딩을 확인해 본다. R을 이용하여 CSV 파일을 읽을 때 첫번째 문자가 깨지는 오류 해결 방법 2.27.2 엑셀 if 함수 정리 엑셀 IF 함수 사용법 및 예제 정리 :: 논리함수 =IF(AND(D2&gt;=C2, D2&lt;=B2), &quot;PASS&quot;, &quot;FAIL&quot;) "],["til20220228.html", "2.28 TIL20220228", " 2.28 TIL20220228 2.28.1 데이터 수집 통계데이터분석 - 데이터 수집1 2.28.1.1 데이터 수집 원천 출판물(publication) 실험(experiment) 관찰(observation) 서베이(servey) 2.28.1.2 표본과 모집단 표본, 데이터 수집에 포한된 참여자의 집단, 기술통계(descriptive statistics) 모집단, 우리가 궁극적으로 결론을 도출하고자 하는 대상이 되는 전체 집단, 추론통계(inferential statistics) 2.28.1.3 표본의 선정 판단표본(judgment sample) 편의표본(convenience sample) 무작위표본(random sample) 2.28.1.4 측정척도 측정(measurement), 데이터 항목의 속성에 숫자를 부여하는 과정 척도(scale), 측정을 위하여 사용되는 도구 2.28.1.5 척도의 종류 명목척도(nominal scale) 서열척도(ordinal scale) 간격척도(interval scale) 비율척도(ratio scale) https://www.youtube.com/watch?v=Z4Hn4LoNuE8&amp;list=PLY0OaF78qqGAxKX91WuRigHpwBU0C2SB_↩︎ "],["년-03월.html", "3 2022년 03월 ", " 3 2022년 03월 "],["til20220301.html", "3.1 TIL20220301", " 3.1 TIL20220301 3.1.1 데이터 요약 3.1.1.1 범주형 변수 요약 기술통계와 추론통계, 대부분은 모집단을 설명하는 추론통계이지만 모집단을 잘 설명하기 위해서는 표본집단을 잘 이해사고 적절한 통계기법을 선택하는 것이 중요하다. 3.1.1.1.1 빈도표 if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } ## Loading required package: MASS str(survey) ## &#39;data.frame&#39;: 237 obs. of 12 variables: ## $ Sex : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 1 2 2 2 2 1 2 1 2 2 ... ## $ Wr.Hnd: num 18.5 19.5 18 18.8 20 18 17.7 17 20 18.5 ... ## $ NW.Hnd: num 18 20.5 13.3 18.9 20 17.7 17.7 17.3 19.5 18.5 ... ## $ W.Hnd : Factor w/ 2 levels &quot;Left&quot;,&quot;Right&quot;: 2 1 2 2 2 2 2 2 2 2 ... ## $ Fold : Factor w/ 3 levels &quot;L on R&quot;,&quot;Neither&quot;,..: 3 3 1 3 2 1 1 3 3 3 ... ## $ Pulse : int 92 104 87 NA 35 64 83 74 72 90 ... ## $ Clap : Factor w/ 3 levels &quot;Left&quot;,&quot;Neither&quot;,..: 1 1 2 2 3 3 3 3 3 3 ... ## $ Exer : Factor w/ 3 levels &quot;Freq&quot;,&quot;None&quot;,..: 3 2 2 2 3 3 1 1 3 3 ... ## $ Smoke : Factor w/ 4 levels &quot;Heavy&quot;,&quot;Never&quot;,..: 2 4 3 2 2 2 2 2 2 2 ... ## $ Height: num 173 178 NA 160 165 ... ## $ M.I : Factor w/ 2 levels &quot;Imperial&quot;,&quot;Metric&quot;: 2 1 NA 2 2 1 1 2 2 2 ... ## $ Age : num 18.2 17.6 16.9 20.3 23.7 ... levels(survey$Smoke) ## [1] &quot;Heavy&quot; &quot;Never&quot; &quot;Occas&quot; &quot;Regul&quot; frqtab &lt;- table(survey$Smoke) frqtab ## ## Heavy Never Occas Regul ## 11 189 19 17 class(frqtab) ## [1] &quot;table&quot; frqtab[2] ## Never ## 189 frqtab[&quot;Never&quot;] ## Never ## 189 3.1.1.1.2 최빈값 frqtab == max(frqtab) ## ## Heavy Never Occas Regul ## FALSE TRUE FALSE FALSE frqtab[frqtab == max(frqtab)] ## Never ## 189 names(frqtab[frqtab == max(frqtab)]) ## [1] &quot;Never&quot; which.max(frqtab) ## Never ## 2 frqtab[which.max(frqtab)] ## Never ## 189 names(frqtab[which.max(frqtab)]) ## [1] &quot;Never&quot; 3.1.1.1.3 비율도표 frqtab.prop &lt;- prop.table(frqtab) frqtab.prop ## ## Heavy Never Occas Regul ## 0.04661017 0.80084746 0.08050847 0.07203390 frqtab.prop[&quot;Never&quot;] ## Never ## 0.8008475 frqtab.prop * 100 ## ## Heavy Never Occas Regul ## 4.661017 80.084746 8.050847 7.203390 "],["til20220302.html", "3.2 TIL20220302", " 3.2 TIL20220302 3.2.1 데이터 요약 3.2.1.1 범주형 변수 요약 3.2.1.1.1 비율 계산 if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } survey$Smoke==&quot;Never&quot; # 비흡연자에 대한 논리연산 ## [1] TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [13] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE FALSE FALSE ## [37] TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [49] FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE FALSE ## [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE NA TRUE FALSE ## [73] TRUE TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE ## [85] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [97] FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE ## [109] TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE ## [121] FALSE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE ## [133] TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [145] TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE ## [157] FALSE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE FALSE ## [169] TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE FALSE TRUE FALSE TRUE ## [181] FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [193] FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE ## [205] FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [217] TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [229] FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE mean(survey$Smoke==&quot;Never&quot;, na.rm = T) # 비흡연자에 대한 비율 ## [1] 0.8008475 head(anorexia) ## Treat Prewt Postwt ## 1 Cont 80.7 80.2 ## 2 Cont 89.4 80.1 ## 3 Cont 91.8 86.4 ## 4 Cont 74.0 86.3 ## 5 Cont 78.1 76.1 ## 6 Cont 88.3 78.1 anorexia$Postwt &gt; anorexia$Prewt # 치료 후의 몸무게가 치료 전의 몸무게보다 큰가? ## [1] FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE ## [13] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE ## [25] TRUE FALSE TRUE TRUE FALSE FALSE FALSE TRUE TRUE TRUE FALSE TRUE ## [37] TRUE TRUE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE ## [49] TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE ## [61] FALSE FALSE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE mean(anorexia$Postwt &gt; anorexia$Prewt) ## [1] 0.5833333 head(mammals) ## body brain ## Arctic fox 3.385 44.5 ## Owl monkey 0.480 15.5 ## Mountain beaver 1.350 8.1 ## Cow 465.000 423.0 ## Grey wolf 36.330 119.5 ## Goat 27.660 115.0 # 두뇌의 무게가 2개의 표준편차보다 큰 논리연산식 abs(mammals$brain - mean(mammals$brain)) &gt; 2*sd(mammals$brain) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE mean(abs(mammals$brain - mean(mammals$brain)) &gt; 2*sd(mammals$brain)) ## [1] 0.03225806 head(SP500) ## [1] -0.2588908 -0.8650307 -0.9804139 0.4504321 -1.1856666 -0.6629097 # 수익률이 전일보다 증가한 일자 논리식 head(diff(SP500) &gt; 0, 10) ## [1] FALSE FALSE TRUE FALSE TRUE TRUE FALSE TRUE TRUE FALSE mean(diff(SP500) &gt; 0) ## [1] 0.4857863 if(!require(vcd)) { install.packages(&quot;vcd&quot;); library(vcd); } ## Loading required package: vcd ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;vcd&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;zoo&#39;, &#39;colorspace&#39;, &#39;lmtest&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages ## Loading required package: grid str(Arthritis) # 류마티스 관절염 치료 효과 ## &#39;data.frame&#39;: 84 obs. of 5 variables: ## $ ID : int 57 46 77 17 36 23 75 39 33 55 ... ## $ Treatment: Factor w/ 2 levels &quot;Placebo&quot;,&quot;Treated&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Sex : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Age : int 27 29 30 32 46 58 59 59 63 63 ... ## $ Improved : Ord.factor w/ 3 levels &quot;None&quot;&lt;&quot;Some&quot;&lt;..: 2 1 1 3 3 3 1 3 1 1 ... levels(Arthritis$Treatment) ## [1] &quot;Placebo&quot; &quot;Treated&quot; levels(Arthritis$Improved) ## [1] &quot;None&quot; &quot;Some&quot; &quot;Marked&quot; crosstab &lt;- table(Arthritis$Improved, Arthritis$Treatment, dnn=c(&quot;Improved&quot;, &quot;Treatment&quot;)) crosstab ## Treatment ## Improved Placebo Treated ## None 29 13 ## Some 7 7 ## Marked 7 21 crosstab[&quot;Marked&quot;, &quot;Treated&quot;] ## [1] 21 crosstab &lt;- xtabs(~ Improved + Treatment, data = Arthritis) crosstab ## Treatment ## Improved Placebo Treated ## None 29 13 ## Some 7 7 ## Marked 7 21 margin.table(crosstab, margin = 1) # 행 ## Improved ## None Some Marked ## 42 14 28 margin.table(crosstab, margin = 2) # 열 ## Treatment ## Placebo Treated ## 43 41 prop.table(crosstab, margin = 1) # 행의 합이 1 ## Treatment ## Improved Placebo Treated ## None 0.6904762 0.3095238 ## Some 0.5000000 0.5000000 ## Marked 0.2500000 0.7500000 prop.table(crosstab, margin = 2) # 열의 합이 1 ## Treatment ## Improved Placebo Treated ## None 0.6744186 0.3170732 ## Some 0.1627907 0.1707317 ## Marked 0.1627907 0.5121951 prop.table(crosstab) ## Treatment ## Improved Placebo Treated ## None 0.34523810 0.15476190 ## Some 0.08333333 0.08333333 ## Marked 0.08333333 0.25000000 addmargins(crosstab, margin = 1) # 합의 행을 생성 ## Treatment ## Improved Placebo Treated ## None 29 13 ## Some 7 7 ## Marked 7 21 ## Sum 43 41 addmargins(crosstab, margin = 2) # 합의 열을 생성 ## Treatment ## Improved Placebo Treated Sum ## None 29 13 42 ## Some 7 7 14 ## Marked 7 21 28 addmargins(crosstab) ## Treatment ## Improved Placebo Treated Sum ## None 29 13 42 ## Some 7 7 14 ## Marked 7 21 28 ## Sum 43 41 84 addmargins(prop.table(crosstab, margin = 2), 1) ## Treatment ## Improved Placebo Treated ## None 0.6744186 0.3170732 ## Some 0.1627907 0.1707317 ## Marked 0.1627907 0.5121951 ## Sum 1.0000000 1.0000000 if(!require(gmodels)) { install.packages(&quot;gmodels&quot;); library(gmodels); } ## Loading required package: gmodels ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;gmodels&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;gtools&#39;, &#39;gdata&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages CrossTable(Arthritis$Improved, Arthritis$Treatment, dnn=c(&quot;Improved&quot;, &quot;Treatment&quot;)) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 84 ## ## ## | Treatment ## Improved | Placebo | Treated | Row Total | ## -------------|-----------|-----------|-----------| ## None | 29 | 13 | 42 | ## | 2.616 | 2.744 | | ## | 0.690 | 0.310 | 0.500 | ## | 0.674 | 0.317 | | ## | 0.345 | 0.155 | | ## -------------|-----------|-----------|-----------| ## Some | 7 | 7 | 14 | ## | 0.004 | 0.004 | | ## | 0.500 | 0.500 | 0.167 | ## | 0.163 | 0.171 | | ## | 0.083 | 0.083 | | ## -------------|-----------|-----------|-----------| ## Marked | 7 | 21 | 28 | ## | 3.752 | 3.935 | | ## | 0.250 | 0.750 | 0.333 | ## | 0.163 | 0.512 | | ## | 0.083 | 0.250 | | ## -------------|-----------|-----------|-----------| ## Column Total | 43 | 41 | 84 | ## | 0.512 | 0.488 | | ## -------------|-----------|-----------|-----------| ## ## multtab &lt;- table(Arthritis$Improved, Arthritis$Sex, Arthritis$Treatment) multtab ## , , = Placebo ## ## ## Female Male ## None 19 10 ## Some 7 0 ## Marked 6 1 ## ## , , = Treated ## ## ## Female Male ## None 6 7 ## Some 5 2 ## Marked 16 5 multtab &lt;- xtabs(~ Improved + Sex + Treatment, data = Arthritis) multtab ## , , Treatment = Placebo ## ## Sex ## Improved Female Male ## None 19 10 ## Some 7 0 ## Marked 6 1 ## ## , , Treatment = Treated ## ## Sex ## Improved Female Male ## None 6 7 ## Some 5 2 ## Marked 16 5 ftable(multtab) ## Treatment Placebo Treated ## Improved Sex ## None Female 19 6 ## Male 10 7 ## Some Female 7 5 ## Male 0 2 ## Marked Female 6 16 ## Male 1 5 ftable(multtab, row.vars = c(2,3)) ## Improved None Some Marked ## Sex Treatment ## Female Placebo 19 7 6 ## Treated 6 5 16 ## Male Placebo 10 0 1 ## Treated 7 2 5 ftable(Arthritis[c(&quot;Improved&quot;, &quot;Sex&quot;, &quot;Treatment&quot;)], row.vars = c(2,3)) ## Improved None Some Marked ## Sex Treatment ## Female Placebo 19 7 6 ## Treated 6 5 16 ## Male Placebo 10 0 1 ## Treated 7 2 5 margin.table(multtab, 1) ## Improved ## None Some Marked ## 42 14 28 margin.table(multtab, 2) ## Sex ## Female Male ## 59 25 margin.table(multtab, 3) ## Treatment ## Placebo Treated ## 43 41 ftable(prop.table(multtab, c(2,3))) ## Treatment Placebo Treated ## Improved Sex ## None Female 0.59375000 0.22222222 ## Male 0.90909091 0.50000000 ## Some Female 0.21875000 0.18518519 ## Male 0.00000000 0.14285714 ## Marked Female 0.18750000 0.59259259 ## Male 0.09090909 0.35714286 ftable(addmargins(prop.table(multtab, c(2,3)))) ## Treatment Placebo Treated Sum ## Improved Sex ## None Female 0.59375000 0.22222222 0.81597222 ## Male 0.90909091 0.50000000 1.40909091 ## Sum 1.50284091 0.72222222 2.22506313 ## Some Female 0.21875000 0.18518519 0.40393519 ## Male 0.00000000 0.14285714 0.14285714 ## Sum 0.21875000 0.32804233 0.54679233 ## Marked Female 0.18750000 0.59259259 0.78009259 ## Male 0.09090909 0.35714286 0.44805195 ## Sum 0.27840909 0.94973545 1.22814454 ## Sum Female 1.00000000 1.00000000 2.00000000 ## Male 1.00000000 1.00000000 2.00000000 ## Sum 2.00000000 2.00000000 4.00000000 "],["til20220303.html", "3.3 TIL20220303", " 3.3 TIL20220303 3.3.1 데이터 요약 3.3.1.1 연속형 변수 요약 3.3.1.1.1 중심경향 지표 중심경향 지표(measures of central tendency)는 데이터가 특정 값을 중심으로 집중되어 있는 정도를 뜻한다. 중위수(median) 백분위수(quantile, percentile) 사분위수(quartile) 평균(mean) if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS) } median(survey$Pulse) # 결측, 즉 NA 값에 따른 결과 ## [1] NA median(survey$Pulse, na.rm=T) # 결측값 제거 후 계산산 ## [1] 72.5 quantile(survey$Pulse, probs = 0.5, na.rm = T) # 중위수 ## 50% ## 72.5 quantile(survey$Pulse, probs = c(0.05, 0.95), na.rm = T) ## 5% 95% ## 59.55 92.00 # Q1, ... Q4 quantile(survey$Pulse, na.rm = T) ## 0% 25% 50% 75% 100% ## 35.0 66.0 72.5 80.0 104.0 quantile(survey$Pulse, seq(0,1,0.25), na.rm = T) ## 0% 25% 50% 75% 100% ## 35.0 66.0 72.5 80.0 104.0 # 주어진 값으로 백분위수 계산 survey$Pulse &lt;=80 # 80보다 작거나 같은 맥박수수 ## [1] FALSE FALSE FALSE NA TRUE TRUE FALSE TRUE TRUE FALSE TRUE TRUE ## [13] NA TRUE TRUE NA FALSE TRUE NA TRUE TRUE TRUE TRUE TRUE ## [25] TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [37] NA TRUE TRUE NA NA TRUE TRUE TRUE TRUE NA FALSE FALSE ## [49] TRUE TRUE TRUE TRUE TRUE TRUE TRUE NA TRUE TRUE TRUE NA ## [61] TRUE TRUE TRUE NA TRUE NA NA TRUE NA TRUE TRUE NA ## [73] TRUE TRUE FALSE TRUE TRUE NA TRUE NA TRUE TRUE FALSE NA ## [85] FALSE TRUE TRUE TRUE TRUE FALSE TRUE NA TRUE NA TRUE NA ## [97] TRUE TRUE NA TRUE NA TRUE NA TRUE TRUE TRUE NA FALSE ## [109] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE ## [121] TRUE TRUE FALSE TRUE TRUE NA TRUE TRUE TRUE FALSE FALSE TRUE ## [133] FALSE TRUE FALSE FALSE TRUE TRUE NA TRUE FALSE NA TRUE FALSE ## [145] TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE ## [157] NA TRUE NA FALSE TRUE NA TRUE TRUE NA FALSE TRUE TRUE ## [169] NA TRUE NA TRUE TRUE TRUE TRUE FALSE TRUE FALSE NA TRUE ## [181] TRUE FALSE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [193] TRUE TRUE NA TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE ## [205] TRUE FALSE TRUE FALSE FALSE NA TRUE FALSE TRUE TRUE TRUE NA ## [217] NA FALSE NA TRUE NA TRUE FALSE NA NA FALSE TRUE TRUE ## [229] TRUE TRUE TRUE NA FALSE FALSE NA FALSE FALSE mean(survey$Pulse &lt;= 80, na.rm = T) ## [1] 0.7552083 mean(survey$Pulse, na.rm = T) ## [1] 74.15104 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } summary(penguins$body_mass_g) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2700 3550 4050 4202 4750 6300 2 summary(penguins$species) ## Adelie Chinstrap Gentoo ## 152 68 124 summary(as.character(penguins$species)) ## Length Class Mode ## 344 character character summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 # list 형태를 인자로 입력하는 경우 penguins.list &lt;- as.list(penguins) summary(penguins.list) ## Length Class Mode ## species 344 factor numeric ## island 344 factor numeric ## bill_length_mm 344 -none- numeric ## bill_depth_mm 344 -none- numeric ## flipper_length_mm 344 -none- numeric ## body_mass_g 344 -none- numeric ## sex 344 factor numeric ## year 344 -none- numeric # lapply()를 통해 요약통계량 계산 lapply(penguins.list, summary) ## $species ## Adelie Chinstrap Gentoo ## 152 68 124 ## ## $island ## Biscoe Dream Torgersen ## 168 124 52 ## ## $bill_length_mm ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 32.10 39.23 44.45 43.92 48.50 59.60 2 ## ## $bill_depth_mm ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 13.10 15.60 17.30 17.15 18.70 21.50 2 ## ## $flipper_length_mm ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 172.0 190.0 197.0 200.9 213.0 231.0 2 ## ## $body_mass_g ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2700 3550 4050 4202 4750 6300 2 ## ## $sex ## female male NA&#39;s ## 165 168 11 ## ## $year ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2007 2007 2008 2008 2009 2009 3.3.2 변동성 지표 변동성 지표(measures of variability)는 데이터의 산포 정도를 뜻한다. 범위(range) 사분위 범위(interquartile range) 분산(variance) 표준편차(standard deviation) range(survey$Pulse, na.rm = T) ## [1] 35 104 var(survey$Pulse, na.rm = T) ## [1] 136.5896 sd(survey$Pulse, na.rm = T) ## [1] 11.68716 R에서는 다양한 기술 통계량을 계산하는 함수들을 제공한다. if(!require(pastecs)) { install.packages(&quot;pastecs&quot;); library(pastecs); } ## Loading required package: pastecs ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;pastecs&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages stat.desc(mtcars[c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)]) ## mpg hp wt ## nbr.val 32.0000000 32.0000000 32.0000000 ## nbr.null 0.0000000 0.0000000 0.0000000 ## nbr.na 0.0000000 0.0000000 0.0000000 ## min 10.4000000 52.0000000 1.5130000 ## max 33.9000000 335.0000000 5.4240000 ## range 23.5000000 283.0000000 3.9110000 ## sum 642.9000000 4694.0000000 102.9520000 ## median 19.2000000 123.0000000 3.3250000 ## mean 20.0906250 146.6875000 3.2172500 ## SE.mean 1.0654240 12.1203173 0.1729685 ## CI.mean.0.95 2.1729465 24.7195501 0.3527715 ## var 36.3241028 4700.8669355 0.9573790 ## std.dev 6.0269481 68.5628685 0.9784574 ## coef.var 0.2999881 0.4674077 0.3041285 if(!require(psych)) { install.packages(&quot;psych&quot;); library(psych); } ## Loading required package: psych ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;psych&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependency &#39;mnormt&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages describe(mtcars[c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)]) ## vars n mean sd median trimmed mad min max range skew kurtosis ## mpg 1 32 20.09 6.03 19.20 19.70 5.41 10.40 33.90 23.50 0.61 -0.37 ## hp 2 32 146.69 68.56 123.00 141.19 77.10 52.00 335.00 283.00 0.73 -0.14 ## wt 3 32 3.22 0.98 3.33 3.15 0.77 1.51 5.42 3.91 0.42 -0.02 ## se ## mpg 1.07 ## hp 12.12 ## wt 0.17 집단별 기술 통계량을 계산한다. levels(survey$Exer) ## [1] &quot;Freq&quot; &quot;None&quot; &quot;Some&quot; tapply(survey$Pulse, survey$Exer, mean, na.rm = T) ## Freq None Some ## 71.96842 76.76471 76.18750 tapply(survey$Pulse, list(survey$Exer, survey$Sex), mean, na.rm = T) ## Female Male ## Freq 73.60976 70.67925 ## None 71.42857 80.50000 ## Some 77.00000 75.03030 aggregate(survey$Pulse, list(Exercise=survey$Exer, Sex=survey$Sex), mean, na.rm = T) ## Exercise Sex x ## 1 Freq Female 73.60976 ## 2 None Female 71.42857 ## 3 Some Female 77.00000 ## 4 Freq Male 70.67925 ## 5 None Male 80.50000 ## 6 Some Male 75.03030 aggregate(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), mean, na.rm = T) ## Exercise Sex Pulse Age ## 1 Freq Female 73.60976 20.11229 ## 2 None Female 71.42857 22.32582 ## 3 Some Female 77.00000 20.29316 ## 4 Freq Male 70.67925 20.50257 ## 5 None Male 80.50000 20.75646 ## 6 Some Male 75.03030 19.91675 aggregate()는 FUN 인수에 사용자 정의 함수를 사용할 수 있다. myStats &lt;- function(x, na.rm = F) { if(na.rm) x &lt;- x[!is.na(x)] n &lt;- length(x) mean &lt;- mean(x) sd &lt;- sd(x) skew &lt;- sum((x-mean)^3/sd^3)/n kurt &lt;- sum((x-mean)^4/sd^4)/n - 3 return(c(n=n, mean=mean, sd=sd, skewness=skew, kurtosis=kurt)) } aggregate(survey$Pulse, list(Exercise=survey$Exer, Sex=survey$Sex), myStats, na.rm = T) ## Exercise Sex x.n x.mean x.sd x.skewness ## 1 Freq Female 41.000000000 73.609756098 12.491753377 -0.007083877 ## 2 None Female 7.000000000 71.428571429 11.414276775 -0.582777800 ## 3 Some Female 47.000000000 77.000000000 10.270260993 -0.057861601 ## 4 Freq Male 53.000000000 70.679245283 9.593213917 0.484695772 ## 5 None Male 10.000000000 80.500000000 15.204166096 0.148604585 ## 6 Some Male 33.000000000 75.030303030 13.501122288 -0.674836829 ## x.kurtosis ## 1 0.443768611 ## 2 -0.795725215 ## 3 -0.215883000 ## 4 0.543653114 ## 5 -1.649344568 ## 6 0.299978722 by(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), summary) ## Exercise: Freq ## Sex: Female ## Pulse Age ## Min. : 40.00 Min. :16.92 ## 1st Qu.: 68.00 1st Qu.:17.42 ## Median : 72.00 Median :18.50 ## Mean : 73.61 Mean :20.11 ## 3rd Qu.: 80.00 3rd Qu.:20.17 ## Max. :104.00 Max. :39.75 ## NA&#39;s :8 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Female ## Pulse Age ## Min. :50.00 Min. :17.17 ## 1st Qu.:69.00 1st Qu.:18.54 ## Median :70.00 Median :19.83 ## Mean :71.43 Mean :22.33 ## 3rd Qu.:78.00 3rd Qu.:20.79 ## Max. :86.00 Max. :41.58 ## NA&#39;s :4 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Female ## Pulse Age ## Min. : 50.0 Min. :16.92 ## 1st Qu.: 70.0 1st Qu.:17.50 ## Median : 76.0 Median :18.21 ## Mean : 77.0 Mean :20.29 ## 3rd Qu.: 83.5 3rd Qu.:19.15 ## Max. :100.0 Max. :73.00 ## NA&#39;s :11 ## ------------------------------------------------------------ ## Exercise: Freq ## Sex: Male ## Pulse Age ## Min. : 48.00 Min. :17.17 ## 1st Qu.: 64.00 1st Qu.:17.92 ## Median : 70.00 Median :18.58 ## Mean : 70.68 Mean :20.50 ## 3rd Qu.: 76.00 3rd Qu.:20.33 ## Max. :100.00 Max. :70.42 ## NA&#39;s :12 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Male ## Pulse Age ## Min. : 60.00 Min. :16.92 ## 1st Qu.: 68.00 1st Qu.:18.17 ## Median : 80.00 Median :18.92 ## Mean : 80.50 Mean :20.76 ## 3rd Qu.: 93.75 3rd Qu.:19.67 ## Max. :104.00 Max. :43.83 ## NA&#39;s :3 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Male ## Pulse Age ## Min. :35.00 Min. :16.75 ## 1st Qu.:66.00 1st Qu.:18.31 ## Median :75.00 Median :18.92 ## Mean :75.03 Mean :19.92 ## 3rd Qu.:85.00 3rd Qu.:20.04 ## Max. :96.00 Max. :35.50 ## NA&#39;s :7 aggregate(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), summary) ## Exercise Sex Pulse.Min. Pulse.1st Qu. Pulse.Median Pulse.Mean ## 1 Freq Female 40.00000 68.00000 72.00000 73.60976 ## 2 None Female 50.00000 69.00000 70.00000 71.42857 ## 3 Some Female 50.00000 70.00000 76.00000 77.00000 ## 4 Freq Male 48.00000 64.00000 70.00000 70.67925 ## 5 None Male 60.00000 68.00000 80.00000 80.50000 ## 6 Some Male 35.00000 66.00000 75.00000 75.03030 ## Pulse.3rd Qu. Pulse.Max. Pulse.NA&#39;s Age.Min. Age.1st Qu. Age.Median Age.Mean ## 1 80.00000 104.00000 8.00000 16.91700 17.41700 18.50000 20.11229 ## 2 78.00000 86.00000 4.00000 17.16700 18.54200 19.83300 22.32582 ## 3 83.50000 100.00000 11.00000 16.91700 17.50000 18.20850 20.29316 ## 4 76.00000 100.00000 12.00000 17.16700 17.91700 18.58300 20.50257 ## 5 93.75000 104.00000 3.00000 16.91700 18.16700 18.91700 20.75646 ## 6 85.00000 96.00000 7.00000 16.75000 18.31225 18.91700 19.91675 ## Age.3rd Qu. Age.Max. ## 1 20.16700 39.75000 ## 2 20.79150 41.58300 ## 3 19.14600 73.00000 ## 4 20.33300 70.41700 ## 5 19.66700 43.83300 ## 6 20.04200 35.50000 by(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), function(x) sapply(x, myStats, na.rm=T)) ## Exercise: Freq ## Sex: Female ## Pulse Age ## n 41.000000000 49.000000 ## mean 73.609756098 20.112286 ## sd 12.491753377 4.831792 ## skewness -0.007083877 2.455680 ## kurtosis 0.443768611 5.815635 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Female ## Pulse Age ## n 7.0000000 11.000000 ## mean 71.4285714 22.325818 ## sd 11.4142768 7.345709 ## skewness -0.5827778 1.687717 ## kurtosis -0.7957252 1.500502 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Female ## Pulse Age ## n 47.0000000 58.000000 ## mean 77.0000000 20.293155 ## sd 10.2702610 8.244537 ## skewness -0.0578616 4.976422 ## kurtosis -0.2158830 27.133862 ## ------------------------------------------------------------ ## Exercise: Freq ## Sex: Male ## Pulse Age ## n 53.0000000 65.000000 ## mean 70.6792453 20.502569 ## sd 9.5932139 7.098771 ## skewness 0.4846958 5.585797 ## kurtosis 0.5436531 35.161334 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Male ## Pulse Age ## n 10.0000000 13.000000 ## mean 80.5000000 20.756462 ## sd 15.2041661 7.024934 ## skewness 0.1486046 2.688832 ## kurtosis -1.6493446 5.973724 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Male ## Pulse Age ## n 33.0000000 40.000000 ## mean 75.0303030 19.916750 ## sd 13.5011223 3.516292 ## skewness -0.6748368 2.719822 ## kurtosis 0.2999787 8.174582 describeBy(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], group = list(Exercise=survey$Exer)) ## ## Descriptive statistics by group ## Exercise: Freq ## vars n mean sd median trimmed mad min max range skew ## Pulse 1 95 71.97 10.93 71.0 71.57 10.38 40.00 104.00 64.0 0.28 ## Age 2 115 20.34 6.18 18.5 19.08 1.61 16.92 70.42 53.5 5.32 ## kurtosis se ## Pulse 0.73 1.12 ## Age 36.42 0.58 ## ------------------------------------------------------------ ## Exercise: None ## vars n mean sd median trimmed mad min max range skew kurtosis ## Pulse 1 17 76.76 14.14 76.00 76.73 11.86 50.00 104.00 54.00 0.20 -0.79 ## Age 2 24 21.48 7.06 19.33 19.80 1.61 16.92 43.83 26.92 2.32 4.09 ## se ## Pulse 3.43 ## Age 1.44 ## ------------------------------------------------------------ ## Exercise: Some ## vars n mean sd median trimmed mad min max range skew kurtosis ## Pulse 1 80 76.19 11.67 76.00 76.66 11.86 35.00 100 65.00 -0.52 0.63 ## Age 2 98 20.14 6.70 18.54 18.80 1.54 16.75 73 56.25 5.69 38.61 ## se ## Pulse 1.30 ## Age 0.68 "],["til20220304.html", "3.4 TIL20220304", " 3.4 TIL20220304 3.4.1 가설검정 가설의 종류 대립가설(alternative hypothesis), 모집단에 대한 새로운 주장 귀무가설(null hypothesis), 기존의 주장 통계적 검정(statistical test) 또는 가설검정(hypothesis test)이란 표본 데이터를 기반으로 모집단에 대한 새로운 주장의 옮고 그름을 추론하는 과정을 말한다. 가설검정 절차 귀무가설이 사실이라는 전제하에서 수행되며 일반적으로 다음과 같은 절차를 따른다. 표본으로부터 검정하고자 하는 검정통계량(test statistic) 계산 검정통계량과 그 확률분포로부터 p-값(p-value) 계산 귀무가설이 사실이라는 가정하에서 관측한 통계량과 같거나 그보다 더 극단적인 값이 발생할 확률을 의미 유의확률(significance probability)이라고도 함 p-값이 매우 작으면 귀무가설 기각 판단의 기준으로 사용하는 5% 또는 1%의 확률을 유의수준(significance level)이라고 함 표본으로부터 관측된 결과(즉 계산된 통계량)가 나타날 가능성이 5% 미만 또는 1% 미만이 되는 귀무가설을 기각하면 이를 통계적으로 유의하다(statistically significant)라고 표현함 가설검정과 검정력 출처2 3.4.2 확률분포 출처3 이항분포(binomial distribution) 대표적인 이산확률분포(discrete probability distribution)로서 매회 어떤 사건이 일어날 확률이 동일한 독립 시행의 경우에 있어서 이 사건이 일어나는 횟수가 만들어 내는 분포이다. 예를 들면 동전 던지기로 동전을 일정 횟수 반복하여 던지는 실험에서 매 시행시마다 숫자면이 나타날 확률이 1/2이라고 할 때 숫자면이 나타나는 횟수는 이항분포를 따른다고 할 수 있다. dbinom(7, 10, 0.5) # 10번 던져 숫자면이 7번 나타날 확률 ## [1] 0.1171875 pbinom(7, 10, 0.5) # 10번 던져 숫자면이 7번 이하가 나타날 확률 ## [1] 0.9453125 누적확률은 밀도함수의 합으로 계산이 가능하다. sum(dbinom(c(0:7), 10, 0.5)) # 0번, 1번, ..., 7번 나타날 확률의 합 ## [1] 0.9453125 pbinom(7, 10, 0.5, lower.tail = F) # 1 - pbinom(7, 10, 0.5) ## [1] 0.0546875 # 4번 이상 7번 이하 발생할 누적확률, 7번에서 4번의 누적확률을 빼서 계산 pbinom(7, 10, 0.5) - pbinom(3, 10, 0.5) ## [1] 0.7734375 diff(pbinom(c(3,7), 10, 0.5)) ## [1] 0.7734375 set.seed(1) rbinom(1, size=10, prob = 0.5) ## [1] 4 rbinom(5, size=10, prob = 0.5) ## [1] 4 5 7 4 7 http://www.ktword.co.kr/img_data/5094_2.JPG↩︎ https://miro.medium.com/max/1400/1*fP1TTrA7TYD58rYgMHiL_A.png↩︎ "],["til20220305.html", "3.5 TIL20220305", " 3.5 TIL20220305 3.5.1 정규분포 정규분포(normal distribution)는 대표적인 연속확률분포(continuous probability distribution)으로 통계적 검정을 위해 가장 널리 사용되는 분포이다. 정규분포에서는 대부분의 관측값이 중앙에 몰려 있으며 중앙에서 멀어질수록 그 빈도수가 점점 작아지는 종 모양의 대칭인 모습을 가진다. if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } ## ## There is a binary version available but the source version is later: ## binary source needs_compilation ## gtable 0.3.0 0.3.1 FALSE ## ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages x &lt;- seq(-4, 4, length=100) y &lt;- dnorm(x) df &lt;- data.frame(x=x, y=y) ggplot(df, aes(x,y)) + geom_line() + theme_bw() ggplot(data = data.frame(x=c(65,135)), aes(x)) + stat_function(fun=dnorm, n=101, args=list(mean=100, sd=10)) + labs(title=&quot;Normal Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + theme_bw() # IQ가 110 이하일 누적확률 계산 pnorm(110, mean=100, sd=10) ## [1] 0.8413447 # IQ가 110 초과일 누적확률 계산 pnorm(110, mean=100, sd=10, lower.tail = F) # 1 - pnorm(110, mean=100, sd=10) ## [1] 0.1586553 pnorm(0) # 표준정규 분포를 가정정 ## [1] 0.5 pnorm(0, mean=0, sd=1) ## [1] 0.5 # 90 ~ 110 사이의 누적확률 pnorm(110, mean=100, sd=10) - pnorm(90, mean=100, sd=10) ## [1] 0.6826895 diff(pnorm(c(90, 110), mean=100, sd=10)) ## [1] 0.6826895 주어진 누적확률의 관측값을 알고자 할 때는 qnorm() 함수를 수행한다. qnorm(0.05, mean=100, sd=10) ## [1] 83.55146 qnorm(0.95, mean=100, sd=10) ## [1] 116.4485 qnorm(c(0.05, 0.95), mean=100, sd=10) ## [1] 83.55146 116.44854 qnorm(c(0.025, 0.975)) ## [1] -1.959964 1.959964 rnorm(1, mean=100, sd=10) ## [1] 115.9528 rnorm(5, mean=100, sd=10) ## [1] 103.29508 91.79532 104.87429 107.38325 105.75781 rnorm(1) ## [1] -0.3053884 rnorm(5) ## [1] 1.5117812 0.3898432 -0.6212406 -2.2146999 1.1249309 3.5.2 데이터의 정규성 검정 set.seed(123) shapiro.test(rnorm(100, mean=100, sd=10)) # 정규분포 ## ## Shapiro-Wilk normality test ## ## data: rnorm(100, mean = 100, sd = 10) ## W = 0.99388, p-value = 0.9349 shapiro.test(runif(100, min=2, max=4)) # 일항분포 ## ## Shapiro-Wilk normality test ## ## data: runif(100, min = 2, max = 4) ## W = 0.9454, p-value = 0.0004182 set.seed(123) qqnorm(rnorm(100, mean=100, sd=10), col=&quot;blue&quot;, main = &quot;Sample from Normal Distribution&quot;) qqline(rnorm(100, mean=100, sd=10)) x축은 이론적 정규 분포에 의해 생성된 표본이고 y축은 실제 표본이다. set.seed(123) qqnorm(runif(100, min=2, max=4), col=&quot;red&quot;, main = &quot;Sample from Uniform Distribution&quot;) qqline(runif(100, min=2, max=4)) "],["til20220306.html", "3.6 TIL20220306", " 3.6 TIL20220306 3.6.1 대응표본 평균검정 독립표본 평균검정은 두 개의 표본이 서로 독립인 모집단으로부터추출되었다는 가정을 전제로 한다. 두 표본의 값이 쌍(pair)을 이루고 있는 경우 쌍을 이룬 값은 서로 독립이 아니며, 이처럼 검정하려고 하는 두 개의 표본이 서로 독립이 아닌 모집단으로부터 추출되었을 대 대응표본 평균검정(paired-samples t test)을 이용하여 두 집단 간의차이 검정을 수행할 수 있다. 독립표본 대응표본 무작위로 실험 대상자를선정하여 두 개의 집단으로 나눔 무작위로 실험 대상자를 선정 한 집단에는 앛미식사를 하고 IQ 테스트에 응하도록 하고 다른 집단에는 앛미식사를 거르고 IQ 테스트에참가하도록 함 각 실험 대아자를 대상으로 IQ 테스트를 두 차례 실시 각 실험 대상자에 대해 하나씩의 IQ 테스트 점수를 얻게 됨 한번은 아침칫가를 하고 테스트에 응하고 다른 한번은 아침식사를 하지 않은 상태로 테스트에 참가하도록 함 각 식험 대상자에 대해 두 개의 IQ 테스트 점수를 얻게 됨 str(sleep) ## &#39;data.frame&#39;: 20 obs. of 3 variables: ## $ extra: num 0.7 -1.6 -0.2 -1.2 -0.1 3.4 3.7 0.8 0 2 ... ## $ group: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ ID : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... t.test(extra ~ group, data = sleep, paired = T) ## ## Paired t-test ## ## data: extra by group ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean difference ## -1.58 주어진 표본이 wide format일 경우 벡터를 직접 지정하여 수행한다. if(!require(tidyr)) { install.packages(&quot;tidyr&quot;); library(tidyr); } sleep.wide &lt;- spread(sleep, key = group, value = extra) sleep.wide ## ID 1 2 ## 1 1 0.7 1.9 ## 2 2 -1.6 0.8 ## 3 3 -0.2 1.1 ## 4 4 -1.2 0.1 ## 5 5 -0.1 -0.1 ## 6 6 3.4 4.4 ## 7 7 3.7 5.5 ## 8 8 0.8 1.6 ## 9 9 0.0 4.6 ## 10 10 2.0 3.4 t.test(sleep.wide$`1`, sleep.wide$`2`, paired = T) ## ## Paired t-test ## ## data: sleep.wide$`1` and sleep.wide$`2` ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean difference ## -1.58 3.6.2 독립표본 비율검정 귀무가설: 폐질환자 대비 흡연자의 비율이 병원별로 같다. 대립가설: 폐질환자 대비 흡연자의 비율이 병원별로 다르다. # 4개 병원에 대한 폐질환자 및 흡연자 비율 patients &lt;- c(86, 93, 136, 82) # 폐질환자 smokers &lt;- c(83, 90, 129,70) # 흡연자 smokers/patients # 페질환자 대비 흡연자 비율 ## [1] 0.9651163 0.9677419 0.9485294 0.8536585 prop.test(x=smokers, n=patients) ## ## 4-sample test for equality of proportions without continuity correction ## ## data: smokers out of patients ## X-squared = 12.6, df = 3, p-value = 0.005585 ## alternative hypothesis: two.sided ## sample estimates: ## prop 1 prop 2 prop 3 prop 4 ## 0.9651163 0.9677419 0.9485294 0.8536585 검정 수행 결과 네 병원의 폐질환자 대비 흡연자 수는 값다고 볼 수 없다. 3.6.3 독립표본 평균검정 독립표본 평균검정(two-independent samples t test)는 두 개의 독립표본 데이터를 이용하여 각각 대응되는 두 개의 모집단 평균이 서로 동일한지 검정한다. 두 집단이 서로 차이가 있는지를 검정하고자 할 때 수행한다. 귀무가설: 두 집단의 평균에는 차이가 없다(같다). 대립가설: 두 집단의 평균에는 차이가 있다(다르다). 예제 고양이의 성별에 따른 몸무게의 차이가 있는지를 검정한다. 귀무가설: 고양이 성별에 따른 몸무게 차이는 없다. 대립가설: 고양이 성별에 따른 몸무게 차이는 있다. t.test(formula = Bwt ~ Sex, data = cats) ## ## Welch Two Sample t-test ## ## data: Bwt by Sex ## t = -8.7095, df = 136.84, p-value = 8.831e-15 ## alternative hypothesis: true difference in means between group F and group M is not equal to 0 ## 95 percent confidence interval: ## -0.6631268 -0.4177242 ## sample estimates: ## mean in group F mean in group M ## 2.359574 2.900000 Bwt.f &lt;- cats$Bwt[cats$Sex==&quot;F&quot;] Bwt.m &lt;- cats$Bwt[cats$Sex==&quot;M&quot;] mean(Bwt.f); mean(Bwt.m); ## [1] 2.359574 ## [1] 2.9 t.test(Bwt.f, Bwt.m) ## ## Welch Two Sample t-test ## ## data: Bwt.f and Bwt.m ## t = -8.7095, df = 136.84, p-value = 8.831e-15 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.6631268 -0.4177242 ## sample estimates: ## mean of x mean of y ## 2.359574 2.900000 3.6.4 일표본 비율검정 prop.test() 함수는 모집단에 대한 표본의 비율에 대한 검정을 수행한다. 예제 프로야구 팀이 30경기 중 18승을 거두었을 때, 승률이 50%가 넘는다고 말할 수 있는가? 귀무가설: 승률이 50% 이하다. 대립가설: 승률이 50% 이상이다. # prop.test(x=성공횟수, n=시행횟수, p=검정코자하는비율) prop.test(x=18, n=30, p=0.5, alternative = &quot;greater&quot;) ## ## 1-sample proportions test with continuity correction ## ## data: 18 out of 30, null probability 0.5 ## X-squared = 0.83333, df = 1, p-value = 0.1807 ## alternative hypothesis: true p is greater than 0.5 ## 95 percent confidence interval: ## 0.4344744 1.0000000 ## sample estimates: ## p ## 0.6 3.6.5 일표본 평균검정 일표본 평균검정(one-sample t test)는 하나의 표본 데이터를 이용하여 모집단의 평균이 특정 값과 같은지 검정하는 것이다. 표본집단이 특정 모집단과 일치하는지 혹은 그렇지 않은지를 알고 싶을 때 이용한다. str(cats) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ Sex: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Bwt: num 2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ... ## $ Hwt: num 7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ... 귀무가설: 고양이의 몸무게가 2.6kg이다. 대립가설: 고양이의 몸무게가 2.6kg이 아니다. t.result &lt;- t.test(x=cats$Bwt, mu=2.6); t.result ## ## One Sample t-test ## ## data: cats$Bwt ## t = 3.0565, df = 143, p-value = 0.002673 ## alternative hypothesis: true mean is not equal to 2.6 ## 95 percent confidence interval: ## 2.643669 2.803553 ## sample estimates: ## mean of x ## 2.723611 p95 &lt;- qt(0.975, df=143) ggplot(data = data.frame(x=c(-4,4)), aes(x)) + stat_function(fun=dt, args = list(df=143)) + labs(title=&quot;t Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + geom_vline(xintercept=t.result$statistic, color=&quot;blue&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=t.result$statistic+0.4, y=0.02, aes(label=round(t.result$statistic,2)), col=&quot;blue&quot;) + geom_vline(xintercept=p95, color=&quot;red&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=p95+0.3, y=0.06, aes(label=round(p95,2)), col=&quot;red&quot;) + theme_bw() 귀무가설: 고양이의 몸무게가 2.7kg이다. 대립가설: 고양이의 몸무게가 2.7kg이 아니다. t.result &lt;- t.test(x=cats$Bwt, mu=2.7); t.result ## ## One Sample t-test ## ## data: cats$Bwt ## t = 0.58382, df = 143, p-value = 0.5603 ## alternative hypothesis: true mean is not equal to 2.7 ## 95 percent confidence interval: ## 2.643669 2.803553 ## sample estimates: ## mean of x ## 2.723611 p95 &lt;- qt(0.975, df=143) ggplot(data = data.frame(x=c(-4,4)), aes(x)) + stat_function(fun=dt, args = list(df=143)) + labs(title=&quot;t Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + geom_vline(xintercept=t.result$statistic, color=&quot;blue&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=t.result$statistic+0.4, y=0.02, aes(label=round(t.result$statistic,2)), col=&quot;blue&quot;) + geom_vline(xintercept=p95, color=&quot;red&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=p95+0.3, y=0.06, aes(label=round(p95,2)), col=&quot;red&quot;) + theme_bw() 3.6.6 평균검정 평균검정은 평균에 대한 가설검정을 의미한다. 선정한 표본이 특정 평균값을 갖는 모집단에 속하는지(즉 표본의 평균과 모집단의 평균이 동일한지) 또는 두 표본 집단의 평균값 간에 차이가 존재하는지(즉 두 표본집단이 동일한 모집단에 속하는지) 검정한다. 일표본 평균검정, 독립표본 평균검정, 대응표본 평균 검정이 있다. 평균에 대한 가설검정은 t검정(t test)을 통해 수행할 수 있다. 표본평균이 모집단 평균과 동일한지 여부는 t값을 검정 통계량으로 사용하여 검정한다. \\[ t = \\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}} \\] 예제 귀무가설: 벤처기업 경영자의 혈압은 일반일과 같다 대립가설; 벤터기업 경영자의 혈압은 일반일과 다르다 표본: 20명의 벤처기업 경영자 평균 135, 표준편차 25 모집단: 일반인 혈압 평균 115 \\[ 검정통계량 \\ \\ t = \\frac{135-115}{\\frac{25}{\\sqrt{20}}} = 3.58 \\] t &lt;- 3.58; n &lt;- 20; pt(t, df=n-1) # t값에 해당하는 누적확률 계산 ## [1] 0.9990014 # 특정 t값 이상의 누적확률에 관심이 있으므로 lower.tail을 F로 설정 # 반대편도 고려해야 함으로 두배 함 pt(t, df=n-1, lower.tail = F)*2 ## [1] 0.001997274 모집단 평균 115라는 가정하에서 135라는 평균은 0.002의 유의확률을 가지므로 5% 유의수준 하에서 귀무가설을 기각하고 대립가설을 채택한다. 유사한 방식으로 유의수준 0.05에 해당하는 t값을 계산하고 관측된 t값을 비교하여 검정한다. p95 &lt;- qt(0.025, df=n-1, lower.tail = F); p95 ## [1] 2.093024 주어진 t 값은 유의수준 5%에 해당하는 t값의 오른쪽에 위치함으로 귀무가설을 기각하고 대립가설을 채택한다. dt_range &lt;- function(x) { y &lt;- dt(x, df=19) y[x &lt; 2.09] &lt;- NA return(y) } ggplot(data = data.frame(x=c(-4,4)), aes(x)) + stat_function(fun=dt, args = list(df=19)) + stat_function(fun=dt_range, geom=&quot;area&quot;, fill=&quot;salmon&quot;, alpha=.5) + labs(title=&quot;t Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + geom_vline(xintercept=t, color=&quot;blue&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=t+0.3, y=0.02, aes(label=t), col=&quot;blue&quot;) + geom_vline(xintercept=p95, color=&quot;red&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=p95+0.3, y=0.06, aes(label=round(p95,2)), col=&quot;red&quot;) + theme_bw() "],["til20220307.html", "3.7 TIL20220307", " 3.7 TIL20220307 3.7.1 결측치 처리 3.7.1.1 결측치 종류 결측치 종류 3.7.1.2 확인 ## summary() summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 colSums(is.na(penguins)); nrow(penguins) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 ## [1] 344 등등등 3.7.1.3 제거 penguins.naomit &lt;- na.omit(penguins) colSums(is.na(penguins.naomit)); nrow(penguins.naomit) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex year ## 0 0 0 0 ## [1] 333 penguins.naomit &lt;- penguins[complete.cases(penguins), ] colSums(is.na(penguins.naomit)); nrow(penguins.naomit) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex year ## 0 0 0 0 ## [1] 333 제거 후 11개 행이 감소된 것을 볼 수 있다. 3.7.1.4 대체 3.7.1.5 0으로 대체 # 연속형 변수에 대해서만 적용 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } penguins.0 &lt;- penguins[c(3:6)] %&gt;% select_if(function(x) any(is.na(x))) %&gt;% replace(is.na(.), 0) colSums(is.na(penguins.0)) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 0 0 0 0 3.7.1.6 평균으로 대체 penguins.mean &lt;- penguins[c(3:6)] %&gt;% select_if(function(x) any(is.na(x))) %&gt;% mutate(bill_length_mm = ifelse(is.na(bill_length_mm), mean(bill_length_mm, na.rm=T), bill_length_mm), bill_depth_mm = ifelse(is.na(bill_depth_mm), mean(bill_depth_mm, na.rm=T), bill_depth_mm), flipper_length_mm = ifelse(is.na(flipper_length_mm), mean(flipper_length_mm, na.rm=T), flipper_length_mm), body_mass_g = ifelse(is.na(body_mass_g), mean(body_mass_g, na.rm=T), body_mass_g)) colSums(is.na(penguins.mean)) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 0 0 0 0 # 0으로 대체한 경우와 평균값으로 대체한 경우의 차이 colMeans(penguins[c(3:6)], na.rm = T); colMeans(penguins.0); colMeans(round(penguins.mean,1)); ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92193 17.15117 200.91520 4201.75439 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.66657 17.05145 199.74709 4177.32558 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92180 17.15145 200.91512 4201.75465 all_column_median &lt;- apply(penguins[c(3:6)], 2, median, na.rm=T); all_column_median ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 44.45 17.30 197.00 4050.00 penguins.median &lt;- penguins[c(3:6)] for(i in colnames(penguins.median)) { penguins.median[is.na(penguins.median[,i]), i] &lt;- all_column_median[i] } colMeans(round(penguins.median)) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.93314 17.15407 200.89244 4200.87209 "],["til20220308.html", "3.8 TIL20220308", " 3.8 TIL20220308 3.8.1 R 에러 수정 &gt; library(dplyr) Error: package or namespace load failed for ‘dplyr’ in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]): ‘rlang’이라고 불리는 패키지가 없습니다 In addition: Warning message: 패키지 ‘dplyr’는 R 버전 3.4.4에서 작성되었습니다 이런 식으로 에러가 발생하면 깔끔하게 R을 재설치 하자. libpath나 패키지 재설치 등의 방법이 언급되지만 안되는 경우가 있다. 한시간 반 소비하고 내린 결론이다. 4.0.3에서 문제가 일어났고 4.1.2로 버전 업해서 문제 해결되었다. Error: ! Assigned data `all_column_mean[i]` must be compatible with existing data. i Error occurred for column `flipper_length_mm`. x Can&#39;t convert from &lt;double&gt; to &lt;integer&gt; due to loss of precision. * Locations: 1. Backtrace: 1. base::`[&lt;-`(`*tmp*`, is.na(p.mean[, i]), i, value = `&lt;dbl&gt;`) 19. tibble `&lt;fn&gt;`(`&lt;vctrs___&gt;`) p.mean &lt;- as.data.frame(penguins[c(3:6)])와 같이 데이터 형태를 명시적으로 지정해 준다. 3.8.2 결측치 시각화 if(!require(mice)) { install.packages(&quot;mice&quot;); library(mice); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages md.pattern(penguins, plot=T, rotate.names = T) ## species island year bill_length_mm bill_depth_mm flipper_length_mm ## 333 1 1 1 1 1 1 ## 9 1 1 1 1 1 1 ## 2 1 1 1 0 0 0 ## 0 0 0 2 2 2 ## body_mass_g sex ## 333 1 1 0 ## 9 1 0 1 ## 2 0 0 5 ## 2 11 19 "],["til20220309.html", "3.9 TIL20220309", " 3.9 TIL20220309 3.9.1 클래스 불균형과 샘플링 분류 분석의 경우 관찰된 표본 범주 비율이 큰 쪽으로 편향되는 경향이 있다. 이를 해결하기 위해 범주의 비율을 조절하여 정제한다. Downsampling &amp; Upsampling4 SMOTE5 Upsampling: this method increases the size of the minority class by sampling with replacement so that the classes will have the same size. Downsampling: in contrast to the above method, this one decreases the size of the majority class to be the same or closer to the minority class size by just taking out a random sample. Hybrid methods : The well known hybrid methods are ROSE (Random oversampling examples), and SMOTE (Synthetic minority oversampling technique), they downsample the majority class, and creat new artificial points in the minority class. For more detail about SMOTE method click here, and for ROSE click here. from: Methods for dealing with imbalanced data6 https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png↩︎ https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/smote.png↩︎ https://www.r-bloggers.com/2019/04/methods-for-dealing-with-imbalanced-data/↩︎ "],["til20220310.html", "3.10 TIL20220310", " 3.10 TIL20220310 if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } data(&quot;BreastCancer&quot;) bc &lt;- BreastCancer[, -1] # Id 열 제외 ## Error in eval(expr, envir, enclos): object &#39;BreastCancer&#39; not found str(bc) ## Error in str(bc): object &#39;bc&#39; not found train.index &lt;- createDataPartition(bc$Class, p=0.75, list=F) bc.train &lt;- bc[train.index, ]; bc.test &lt;- bc[-train.index, ]; rbind(TrainData = table(bc.train$Class), TestData = table(bc.test$Class)) # upsampling / downsample / SMOTE bc.train.up &lt;- upSample(subset(bc.train, select = -Class), bc.train$Class) bc.train.down &lt;- downSample(subset(bc.train, select = -Class), bc.train$Class) bc.train.smote &lt;- SMOTE(Class ~ ., bc.train, prec.over = 900, perc.under=150) rbind(Upsampling = table(bc.train.up$Class), Downsampling = table(bc.train.down$Class), SMOTE = table(bc.train.smote$Class)) p.dt &lt;- rpart(Class ~ ., bc.train) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) orig.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] p.dt &lt;- rpart(Class ~ ., bc.train.up) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) up.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] p.dt &lt;- rpart(Class ~ ., bc.train.down) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) down.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] p.dt &lt;- rpart(Class ~ ., bc.train.smote) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) smote.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] rbind(Orig = orig.cm, Upsampling = up.cm, Downsampling = down.cm, SMOTE = smote.cm) 상황에 따라 결과가 다르게 나오지만 대체적으로 SMOTE에서 높은 정확도를 보인다. 3.10.1 SMOTE 데이터 형식 오류 Why do I get ‘Error in T[, col] &lt;- data[, col]’ when I use SMOTE in R? 변수는 facter형이고, tibble 형식을 지원하지 않는다. "],["til20220311.html", "3.11 TIL20220311", " 3.11 TIL20220311 DWmR 패키지는 github actions로 설치 안되는 걸로… RStudio에서 rendering 후 업로드 하자. 3.11.1 URL을 통해 직접 패키지 설치 Install an R package directly from a URL for the package source7 install.packages(&quot;https://cran.r-project.org/src/contrib/Archive/DMwR/DMwR_0.4.1.tar.gz&quot;, repos=NULL, method=&quot;libcurl&quot;) data(&quot;BreastCancer&quot;) bc &lt;- BreastCancer[, -1] # Id 열 제외 ## Error in eval(expr, envir, enclos): object &#39;BreastCancer&#39; not found bc.smote &lt;- SMOTE(Class ~ ., bc, perc.over = 100, perc.under = 200) bc.smote.compete &lt;- complete(bc.smote) rbind(Orig = table(bc$Class), SMOTE = table(bc.smote.compete$Class)) https://stackoverflow.com/questions/16412638/install-an-r-package-directly-from-a-url-for-the-package-source↩︎ "],["til20220312.html", "3.12 TIL20220312", " 3.12 TIL20220312 3.12.1 RStudio Chunk options R Code Chunks8 Rmarkdown으로 문서 작성 시 꼭 필요한 사용하게 된다. 알아 둘 것. knitr::opts_chunk$set(# root.dir = &#39;../..&#39;, # 프로젝트 폴더 지정 eval = TRUE, echo = FALSE, cache = FALSE, include = TRUE, tidy = TRUE, tidy.opts = list(blank=FALSE, width.cutoff=120), # 소스 출력길이 지정 message = FALSE, warning = FALSE, engine = &quot;R&quot;, # Chunks will always have R code, unless noted error = TRUE, fig.path=&quot;Figures/&quot;, # Set the figure options fig.align = &quot;center&quot;, fig.width = 7, fig.height = 7, fig.keep=&#39;all&#39;, fig.retina=2) https://zorba78.github.io/cnu-r-programming-lecture-note/r-code-chunks.html↩︎ "],["til20220313.html", "3.13 TIL20220313", " 3.13 TIL20220313 3.13.1 시계열 데이터 분할 출처: 시계열 데이터 - 항공여객(Air Passenger) 데이터9 시계열은 일반적인 방법으로 표본상에서 랜덤하게 원소를 추출할 수 없다. 시간 흐름을 고려하여 훈련 데이터와 시험 데이터로 분할해야 한다. train = 1:18 test = 19:24 par(mar=c(0,0,0,0)) {plot(0,0,xlim=c(0,26),ylim=c(0,2),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,bty=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;,type=&quot;n&quot;) arrows(0,0.5,25,0.5,0.05) points(train, train*0+0.5, pch=19, col=&quot;blue&quot;) points(test, test*0+0.5, pch=19, col=&quot;red&quot;) text(26,0.5,&quot;시간&quot;) text(10,0.7,&quot;훈련데이터&quot;,col=&quot;blue&quot;) text(21,0.7,&quot;시험데이터&quot;,col=&quot;red&quot;)} # Core Tidyverse if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(glue)) { install.packages(&quot;glue&quot;); library(glue); } if(!require(forcats)) { install.packages(&quot;forcats&quot;); library(forcats); } # Time Series if(!require(timetk)) { install.packages(&quot;timetk&quot;); library(timetk); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(tidyquant)) { install.packages(&quot;tidyquant&quot;); library(tidyquant); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(tibbletime)) { install.packages(&quot;tibbletime&quot;); library(tibbletime); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(sweep)) { install.packages(&quot;sweep&quot;); library(sweep); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages # Visualization if(!require(cowplot)) { install.packages(&quot;cowplot&quot;); library(cowplot); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages # Preprocessing if(!require(recipes)) { install.packages(&quot;recipes&quot;); library(recipes); } # Sampling / Accuracy if(!require(rsample)) { install.packages(&quot;rsample&quot;); library(rsample); } if(!require(yardstick)) { install.packages(&quot;yardstick&quot;); library(yardstick); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages # Modeling if(!require(forecast)) { install.packages(&quot;forecast&quot;); library(forecast); } data(&quot;AirPassengers&quot;) ap_ts &lt;- AirPassengers %&gt;% tk_tbl() %&gt;% mutate(index = as_date(index)) %&gt;% as_tbl_time(index = index) %&gt;% filter(index &gt;= &quot;1950-01-01&quot;, index &lt;= &quot;1959-12-31&quot;) ggplot(ap_ts, aes(x=index, y=value)) + geom_line() 오늘은 여기까지… http://aispiration.com/model/model-rsampling-time-series.html↩︎ "],["til20220314.html", "3.14 TIL20220314", " 3.14 TIL20220314 데이터 분할, 이건 내일 정리하자. 양이 많네. 3.14.1 일반적인 데이터 분할 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages trainIndex &lt;- createDataPartition(penguins$species, p=.7, list=F) pTrain &lt;- penguins[trainIndex, ] pTest &lt;- penguins[-trainIndex, ] addmargins(addmargins(rbind( pTrain = table(pTrain$species), pTest = table(pTest$species) ),2),1) ## Adelie Chinstrap Gentoo Sum ## pTrain 107 48 87 242 ## pTest 45 20 37 102 ## Sum 152 68 124 344 "],["til20220315.html", "3.15 TIL20220315", " 3.15 TIL20220315 3.15.1 caret을 이용한 기계학습 절차 데이터 전처리 데이터 분할 학습 성능평가 하이퍼 파라메터 튜닝 # 0. 데이터 준비 data(&quot;penguins&quot;) str(penguins) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 # 1. 데이터 전처리 if(!require(mice)) { install.packages(&quot;mice&quot;); library(mice); } penguins.preprocessing &lt;- mice(penguins, m=1, print=F) # 결측치 처리 data &lt;- complete(penguins.preprocessing) # 수치형 변수 정규화 data[, c(3:6)] &lt;- scale(data[, c(3:6)]) # 년도 범주로 변환 data$year &lt;- as.factor(data$year) summary(data) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :-2.1700 Min. :-2.03915 ## Chinstrap: 68 Dream :124 1st Qu.:-0.8530 1st Qu.:-0.79363 ## Gentoo :124 Torgersen: 52 Median : 0.0969 Median : 0.07446 ## Mean : 0.0000 Mean : 0.00000 ## 3rd Qu.: 0.8403 3rd Qu.: 0.77900 ## Max. : 2.8777 Max. : 2.18808 ## flipper_length_mm body_mass_g sex year ## Min. :-2.0579 Min. :-1.8762 female:173 2007:110 ## 1st Qu.:-0.7774 1st Qu.:-0.8142 male :171 2008:114 ## Median :-0.2794 Median :-0.1895 2009:120 ## Mean : 0.0000 Mean : 0.0000 ## 3rd Qu.: 0.8766 3rd Qu.: 0.6851 ## Max. : 2.1394 Max. : 2.6216 # 2. 데이터 분할 train.index &lt;- createDataPartition(data$sex, p=0.7, list=F) data.train &lt;- data[train.index, ] data.test &lt;- data[-train.index, ] addmargins(rbind( TrainSet = table(data.train$sex), TestSet = table(data.test$sex) ),2) ## female male Sum ## TrainSet 122 120 242 ## TestSet 51 51 102 # 3. 학습 fitControl &lt;- trainControl(method = &quot;repeatedcv&quot;, repeats = 5) model.rf &lt;- train(sex ~ ., data=data.train, method = &quot;rf&quot;, trControl = fitControl); model.rf ## Error: Required packages are missing: randomForest ## Error in eval(expr, envir, enclos): object &#39;model.rf&#39; not found # 4. 성능평가 model.rf.pred &lt;- predict(model.rf, newdata = data.test) ## Error in predict(model.rf, newdata = data.test): object &#39;model.rf&#39; not found model.rf.cm &lt;- confusionMatrix(model.rf.pred, data.test$sex); model.rf.cm ## Error in confusionMatrix(model.rf.pred, data.test$sex): object &#39;model.rf.pred&#39; not found ## Error in eval(expr, envir, enclos): object &#39;model.rf.cm&#39; not found # 5. 하이퍼 파라메터 튜닝 ## 5-1. custom search grid customGrid &lt;- expand.grid(mtry = 1:(dim(data.train)[2]-1)) model.rf.tuned &lt;- train(sex ~ ., data=data.train, method = &quot;rf&quot;, trControl = fitControl, tuneGrid = customGrid); model.rf.tuned ## Error: Required packages are missing: randomForest ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned&#39; not found model.rf.tuned.pred &lt;- predict(model.rf.tuned, newdata = data.test) ## Error in predict(model.rf.tuned, newdata = data.test): object &#39;model.rf.tuned&#39; not found model.rf.tuned.cm &lt;- confusionMatrix(model.rf.tuned.pred, data.test$sex); model.rf.tuned.cm ## Error in confusionMatrix(model.rf.tuned.pred, data.test$sex): object &#39;model.rf.tuned.pred&#39; not found ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned.cm&#39; not found # 5-2. Random Search Grid fitControl.random &lt;- trainControl(method = &quot;repeatedcv&quot;, repeats = 5, search = &quot;random&quot;) model.rf.tuned2 &lt;- train(sex ~ ., data=data.train, method = &quot;rf&quot;, trControl = fitControl.random, tuneLength = 10); model.rf.tuned2 ## Error: Required packages are missing: randomForest ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned2&#39; not found model.rf.tuned2.pred &lt;- predict(model.rf.tuned2, newdata = data.test) ## Error in predict(model.rf.tuned2, newdata = data.test): object &#39;model.rf.tuned2&#39; not found model.rf.tuned2.cm &lt;- confusionMatrix(model.rf.tuned2.pred, data.test$sex); model.rf.tuned2.cm ## Error in confusionMatrix(model.rf.tuned2.pred, data.test$sex): object &#39;model.rf.tuned2.pred&#39; not found ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned2.cm&#39; not found "],["til20220316.html", "3.16 TIL20220316", " 3.16 TIL20220316 3.16.1 페널티 회귀분석 - 1 페널티 회귀분석(penalized regression analysis)10 릿지 (Ridge) 회귀계수를 0에 가깝게 만듬(모든 변수 사용), 독립변수의 회귀계수가 비슷한 경우 우수 라소 (Lasso) 설명력에 기여하지 못하는 독립변수의 회귀계수를 0으로 만듬(간명한 모델), 독립변수의 회귀변수간 차이가 클 때 우수 일래스틱넷 (ElasticNet), 릿지 + 라소 지나치게많은 독립변수를 갖는 모델에 페널티를 부과하는 방식으로 보다 간명한 회귀모델을 생성할 수 있다. 모델의 성능에 크게 기여하지 못하는 변수의 영향력을 축소(Lasso)하거나 모델에서 제거(Ridge)한다. 최소자승법에 의한 잔차(=관측값-예측값)의 제곱합과 페널티항의 합이 최소가 되도록 회귀계수를 추정한다. str(Boston) ## &#39;data.frame&#39;: 506 obs. of 14 variables: ## $ crim : num 0.00632 0.02731 0.02729 0.03237 0.06905 ... ## $ zn : num 18 0 0 0 0 0 12.5 12.5 12.5 12.5 ... ## $ indus : num 2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ... ## $ chas : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nox : num 0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ... ## $ rm : num 6.58 6.42 7.18 7 7.15 ... ## $ age : num 65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ... ## $ dis : num 4.09 4.97 4.97 6.06 6.06 ... ## $ rad : int 1 2 2 3 3 3 5 5 5 5 ... ## $ tax : num 296 242 242 222 222 222 311 311 311 311 ... ## $ ptratio: num 15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ... ## $ black : num 397 397 393 395 397 ... ## $ lstat : num 4.98 9.14 4.03 2.94 5.33 ... ## $ medv : num 24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ... glmnet 패키지 내 glmnet() 함수를 통해 페널티 회귀분석을 수행할 수 있다. glmnet() 함수는 인자로 결과변수 y는 벡터로 예측변수 x는 행렬 형태로 제공해야 한다. 추가로 연속형 변수만 처리 가능하므로 범주형 변수는 사전에 더미변수로 변환해야 한다. family = 결과변수의 확률분포, gaussian, binomial 등 alpha = 0(Ridge), 1(Lasso), 0~1(ElasticNet) lambda = 패널티 크기 조절, 예측오차를 최소화 하는 람다 설정, 교차검정을 통해 설정 3.16.1.1 Ridge Regression # 최적의 람다 계산 set.seed(123) Boston.cv &lt;- cv.glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0) # Ridge ## Error in cv.glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0): could not find function &quot;cv.glmnet&quot; plot(Boston.cv) ## Error in plot(Boston.cv): object &#39;Boston.cv&#39; not found 왼쪽의 점선은 최적 람다의 로그 값, 상단의 숫자는 예측변수의 개수, Ridge 회귀분석은 회귀계수를 0으로 만들지 않기 때문에 예측변수 개수가 줄어들지 않는다. str(Boston.cv) ## Error in str(Boston.cv): object &#39;Boston.cv&#39; not found cbind(lambda.min = Boston.cv$lambda.min, lambda.min.log = log(Boston.cv$lambda.min)) ## Error in cbind(lambda.min = Boston.cv$lambda.min, lambda.min.log = log(Boston.cv$lambda.min)): object &#39;Boston.cv&#39; not found Boston.gnet &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0, lambda = Boston.cv$lambda.min) ## Error in glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0, lambda = Boston.cv$lambda.min): could not find function &quot;glmnet&quot; coef(Boston.gnet) ## Error in coef(Boston.gnet): object &#39;Boston.gnet&#39; not found Boston.pred &lt;- predict(Boston.gnet, newx = Boston.test.x) ## Error in predict(Boston.gnet, newx = Boston.test.x): object &#39;Boston.gnet&#39; not found head(Boston.pred) ## Error in head(Boston.pred): object &#39;Boston.pred&#39; not found postResample(pred = Boston.pred, obs = Boston.test.y) ## Error in postResample(pred = Boston.pred, obs = Boston.test.y): object &#39;Boston.pred&#39; not found RMSE와 MAE는 오차 지표로 값이 작을수록, Rsquared는 모델의 설명력 지표로 값이 클수록 우수한 모델이다. 3.16.2 Markdown 문법 https://daringfireball.net/projects/markdown/syntax#p https://www.youtube.com/watch?v=3OEwk2VxZdE&amp;list=PLY0OaF78qqGAxKX91WuRigHpwBU0C2SB_&amp;index=31&amp;t=228s↩︎ "],["til20220317.html", "3.17 TIL20220317", " 3.17 TIL20220317 3.17.1 분산분석 분산분석(analysis of variance, ANOVA)은 여러 모집단 간의 평균의 동일성을 검정한다.11 일원분산분석 (one-way ANOVA) 이원분산분석 (two-way ANOVA) 공분산분석 (analysis of corvariance, ANCOVA) 반복측정 분산분석 (repeated measures ANOVA) 다변량 분산분석 (multivariate analysis of variance, MANOVA) 다변량 공분산분석 (multivariate analysis of covariance, MANCOVA) 3.17.2 페널티 회귀분석 - 2 str(Boston) ## &#39;data.frame&#39;: 506 obs. of 14 variables: ## $ crim : num 0.00632 0.02731 0.02729 0.03237 0.06905 ... ## $ zn : num 18 0 0 0 0 0 12.5 12.5 12.5 12.5 ... ## $ indus : num 2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ... ## $ chas : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nox : num 0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ... ## $ rm : num 6.58 6.42 7.18 7 7.15 ... ## $ age : num 65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ... ## $ dis : num 4.09 4.97 4.97 6.06 6.06 ... ## $ rad : int 1 2 2 3 3 3 5 5 5 5 ... ## $ tax : num 296 242 242 222 222 222 311 311 311 311 ... ## $ ptratio: num 15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ... ## $ black : num 397 397 393 395 397 ... ## $ lstat : num 4.98 9.14 4.03 2.94 5.33 ... ## $ medv : num 24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ... set.seed(123) train.index &lt;- createDataPartition(y = Boston$medv, p = 0.7, list = F) Boston.train &lt;- Boston[train.index, ] Boston.test &lt;- Boston[-train.index, ] Boston.test.x &lt;- model.matrix(medv ~ ., Boston.test)[, -1] Boston.test.y &lt;- Boston.test$medv Boston.split &lt;- rbind(Train.Data = nrow(Boston.train), Test.Data = nrow(Boston.test)) colnames(Boston.split) &lt;- c(&quot;Number&quot;); Boston.split ## Number ## Train.Data 356 ## Test.Data 150 glmnet 패키지 내 glmnet() 함수를 통해 페널티 회귀분석을 수행할 수 있다. glmnet() 함수는 인자로 결과변수 y는 벡터로 예측변수 x는 행렬 형태로 제공해야 한다. 추가로 연속형 변수만 처리 가능하므로 범주형 변수는 사전에 더미변수로 변환해야 한다. family = 결과변수의 확률분포, gaussian, binomial 등 alpha = 0(Ridge), 1(Lasso), 0~1(ElasticNet) lambda = 패널티 크기 조절, 예측오차를 최소화 하는 람다 설정, 교차검정을 통해 설정 if(!require(glmnet)) { install.packages(&quot;glmnet&quot;); library(glmnet); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages # 예측변수 행렬 + 더미변수 생성 x &lt;- model.matrix(medv ~., Boston.train)[, -1] # 불필요한 첫 번째 열 삭제 head(x) ## crim zn indus chas nox rm age dis rad tax ptratio black lstat ## 1 0.00632 18.0 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 ## 4 0.03237 0.0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 2.94 ## 10 0.17004 12.5 7.87 0 0.524 6.004 85.9 6.5921 5 311 15.2 386.71 17.10 ## 12 0.11747 12.5 7.87 0 0.524 6.009 82.9 6.2267 5 311 15.2 396.90 13.27 ## 13 0.09378 12.5 7.87 0 0.524 5.889 39.0 5.4509 5 311 15.2 390.50 15.71 ## 16 0.62739 0.0 8.14 0 0.538 5.834 56.5 4.4986 4 307 21.0 395.62 8.47 # 결과변수 y &lt;- Boston.train$medv 3.17.2.1 Lasso Regression set.seed(123) Boston.cv &lt;- cv.glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 1) # Lasso plot(Boston.cv) 왼쪽의 점선은 예측오차를 최소화하는, 즉 예측 정확도를 가장 크게하는 로그 람다값을 나타낸다. Lasso 회귀분석에서는 영향력이 작은 예측변수의 회귀계수를 0으로 만들어 제거할 수 있다. 우측 상단의 예측변수 개수에서 확인이 가능하다. cbind(lambda.min = Boston.cv$lambda.min, lambda.min.log = log(Boston.cv$lambda.min)) ## lambda.min lambda.min.log ## [1,] 0.01189058 -4.432009 예측 정확도와 모델 간명도를 고려하여 최소 예측 오차의 1개 표준편차 이내에 있으면서 예측변수의 개수를 최소화하는 람다를 제공한다. cbind(lambda.1se = Boston.cv$lambda.1se, lambda.1se.log = log(Boston.cv$lambda.1se)) ## lambda.1se lambda.1se.log ## [1,] 0.3716657 -0.9897604 cbind(lambda.min = coef(Boston.cv, Boston.cv$lambda.min), lambda.1se = coef(Boston.cv, Boston.cv$lambda.1se)) ## 14 x 2 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 s1 ## (Intercept) 32.720731705 16.0297569500 ## crim -0.087271032 -0.0139981876 ## zn 0.027462832 . ## indus -0.045858550 -0.0166198270 ## chas 2.904607308 2.0413930420 ## nox -15.675976627 -2.5456625823 ## rm 3.997011835 4.3113894194 ## age . . ## dis -1.236733449 -0.2334310319 ## rad 0.255230956 . ## tax -0.009918317 -0.0007771602 ## ptratio -0.920530277 -0.7681696792 ## black 0.008606410 0.0061710231 ## lstat -0.481377769 -0.4700816156 lambda.min은 1개의, lambda.1se는 3개의 예측변수가 제거되었다. Boston.gnet1 &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 1, lambda = Boston.cv$lambda.min) Boston.pred1 &lt;- predict(Boston.gnet1, newx = Boston.test.x) postResample(pred = Boston.pred1, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.1150340 0.7197637 3.3091787 Boston.gnet2 &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 1, lambda = Boston.cv$lambda.1se) Boston.pred2 &lt;- predict(Boston.gnet2, newx = Boston.test.x) postResample(pred = Boston.pred2, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.5656605 0.6795993 3.6151777 3.17.2.2 ElasticNet Regression ElasticNet읜 L2-norm, L1-norm 페널티항을 설정해야 하므로 최적의 alpha값을 산출해야 한다. caret 패키지 내 train() 함수를 이용한다. set.seed(123) Boston.cv &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneLength = 10) Boston.cv$bestTune ## alpha lambda ## 6 0.1 0.2020812 Boston.gnet &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = Boston.cv$bestTune$alpha, lambda = Boston.cv$bestTune$lambda) coef(Boston.gnet) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s0 ## (Intercept) 29.766401348 ## crim -0.078819914 ## zn 0.021807176 ## indus -0.064680920 ## chas 2.966225220 ## nox -13.617871871 ## rm 4.056442437 ## age . ## dis -1.097715391 ## rad 0.194940136 ## tax -0.007343684 ## ptratio -0.891291598 ## black 0.008443963 ## lstat -0.466614849 Boston.pred &lt;- predict(Boston.gnet, newx = Boston.test.x) postResample(pred = Boston.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.1766444 0.7148912 3.3115941 3.17.3 모델별 비교 lambda &lt;- 10^seq(-1, 5, length = 100) # ridge set.seed(123) ridge &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneGrid = expand.grid(alpha = 0, lambda = lambda)) coef(ridge$finalModel, ridge$bestTune$lambda) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 26.531756149 ## crim -0.074428914 ## zn 0.017800440 ## indus -0.084013662 ## chas 3.079990715 ## nox -10.929321371 ## rm 4.075749392 ## age -0.003350370 ## dis -0.950562016 ## rad 0.143524673 ## tax -0.005528583 ## ptratio -0.844792464 ## black 0.008418506 ## lstat -0.433322899 ridge.pred &lt;- predict(ridge, Boston.test) postResample(pred = ridge.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.2697535 0.7078302 3.3430299 # lasso set.seed(123) lasso &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneGrid = expand.grid(alpha = 1, lambda = lambda)) coef(lasso$finalModel, lasso$bestTune$lambda) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 27.091673886 ## crim -0.057263747 ## zn 0.011752233 ## indus -0.060580843 ## chas 2.817475257 ## nox -11.877653738 ## rm 4.155604866 ## age . ## dis -0.934714973 ## rad 0.114348391 ## tax -0.004015459 ## ptratio -0.877240341 ## black 0.007739894 ## lstat -0.477162631 lasso.pred &lt;- predict(lasso, Boston.test) postResample(pred = lasso.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.245637 0.708739 3.362308 # lasso set.seed(123) elastic &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneLength = 10) coef(elastic$finalModel, elastic$bestTune$lambda) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 29.765523097 ## crim -0.078486897 ## zn 0.021723671 ## indus -0.064825528 ## chas 2.965478459 ## nox -13.585240410 ## rm 4.054072843 ## age . ## dis -1.097151673 ## rad 0.194485494 ## tax -0.007329651 ## ptratio -0.891156341 ## black 0.008442569 ## lstat -0.467123628 elastic.pred &lt;- predict(elastic, Boston.test) postResample(pred = elastic.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.1769223 0.7148754 3.3120692 models &lt;- list(ridge = ridge, lasso = lasso, elastic = elastic) summary(resamples(models)) ## ## Call: ## summary.resamples(object = resamples(models)) ## ## Models: ridge, lasso, elastic ## Number of resamples: 10 ## ## MAE ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## ridge 2.314983 3.095864 3.358949 3.350092 3.553519 4.758853 0 ## lasso 2.334122 3.113956 3.355747 3.384424 3.536837 4.889416 0 ## elastic 2.370271 3.091582 3.351099 3.369054 3.544919 4.741635 0 ## ## RMSE ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## ridge 3.217597 4.220445 4.527056 4.702958 5.047501 6.966902 0 ## lasso 3.259155 4.242220 4.489430 4.744627 5.168922 7.113506 0 ## elastic 3.323486 4.222079 4.511393 4.699214 5.056862 6.952270 0 ## ## Rsquared ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## ridge 0.5685060 0.7102964 0.7569726 0.7432102 0.7896808 0.8415753 0 ## lasso 0.5567794 0.6909231 0.7576300 0.7387044 0.7934118 0.8391494 0 ## elastic 0.5743693 0.7076979 0.7608565 0.7432037 0.7831245 0.8450374 0 세 모델이 RMSE 관점에서 비슷한 성능을 보이는 것 같다. 통계적으로 유의한 차이가 있는지 검정해 본다. summary(diff(resamples(models), metric=&quot;RMSE&quot;)) ## ## Call: ## summary.diff.resamples(object = diff(resamples(models), metric = &quot;RMSE&quot;)) ## ## p-value adjustment: bonferroni ## Upper diagonal: estimates of the difference ## Lower diagonal: p-value for H0: difference = 0 ## ## RMSE ## ridge lasso elastic ## ridge -0.041669 0.003744 ## lasso 0.7838 0.045413 ## elastic 1.0000 0.6350 행렬의 대각선 위쪽은 모델간 차이, 아래쪽은 유의확률을 나타낸다. 세 모델 간 통계적 유의한 차이는 없는 것으로 확인된다. 따라서 간명도 관점에서 예측변수의 개수가 적은 모델을 선택하는 것이 바람직하다. https://www.youtube.com/watch?v=BnFkVjjSv6I&amp;list=PLY0OaF78qqGAxKX91WuRigHpwBU0C2SB_&amp;index=11↩︎ "],["til20220318.html", "3.18 TIL20220318", " 3.18 TIL20220318 3.18.1 구미시 선별진료소 구미시 선별진료소12 https://www.mohw.go.kr/react/ncov/selclinic04ls.jsp↩︎ "],["til20220319.html", "3.19 TIL20220319", " 3.19 TIL20220319 3.19.1 일반선형델회귀모델 일반선형회귀모델 \\(f(\\mu \\_y) = \\beta\\_0 + \\beta\\_1 x_1 + \\beta\\_2 x_2 + ... + \\beta\\_n x_n\\) 로지스틱 선형회귀모델 \\(ln( \\frac{p}{1-p} ) = \\beta\\_0 + \\beta\\_1 x_1 + \\beta\\_2 x_2 + ... + \\beta\\_m x_m\\) 포아송 선형회귀모델 \\(ln(\\lambda) = \\beta\\_0 + \\beta\\_1 x_1 + \\beta\\_2 x_2 + ... + \\beta\\_m x_m\\) 3.19.2 이항 로지스틱 회귀분석 결과변수(종속변수)가 이분형 범주를 가질 때 예측변수(독립변수)로부터 결과변수의 범주를 예측한다. if(!require(modeldata)) { install.packages(&quot;modeldata&quot;); library(modeldata); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages data(mlc_churn) str(mlc_churn) ## tibble [5,000 × 20] (S3: tbl_df/tbl/data.frame) ## $ state : Factor w/ 51 levels &quot;AK&quot;,&quot;AL&quot;,&quot;AR&quot;,..: 17 36 32 36 37 2 20 25 19 50 ... ## $ account_length : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ... ## $ area_code : Factor w/ 3 levels &quot;area_code_408&quot;,..: 2 2 2 1 2 3 3 2 1 2 ... ## $ international_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 2 2 2 1 2 1 2 ... ## $ voice_mail_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 1 2 1 1 2 ... ## $ number_vmail_messages : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ... ## $ total_day_minutes : num [1:5000] 265 162 243 299 167 ... ## $ total_day_calls : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ... ## $ total_day_charge : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ... ## $ total_eve_minutes : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ... ## $ total_eve_calls : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ... ## $ total_eve_charge : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ... ## $ total_night_minutes : num [1:5000] 245 254 163 197 187 ... ## $ total_night_calls : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ... ## $ total_night_charge : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ... ## $ total_intl_minutes : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ... ## $ total_intl_calls : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ... ## $ total_intl_charge : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ... ## $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ... ## $ churn : Factor w/ 2 levels &quot;yes&quot;,&quot;no&quot;: 2 2 2 2 2 2 2 2 2 2 ... churn &lt;- mlc_churn[-c(1,3)] churn$churn &lt;- factor(ifelse(churn$churn==&quot;no&quot;, 1, 2), levels=c(1,2), labels=c(&quot;no&quot;, &quot;yes&quot;)) str(churn) ## tibble [5,000 × 18] (S3: tbl_df/tbl/data.frame) ## $ account_length : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ... ## $ international_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 2 2 2 1 2 1 2 ... ## $ voice_mail_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 1 2 1 1 2 ... ## $ number_vmail_messages : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ... ## $ total_day_minutes : num [1:5000] 265 162 243 299 167 ... ## $ total_day_calls : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ... ## $ total_day_charge : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ... ## $ total_eve_minutes : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ... ## $ total_eve_calls : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ... ## $ total_eve_charge : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ... ## $ total_night_minutes : num [1:5000] 245 254 163 197 187 ... ## $ total_night_calls : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ... ## $ total_night_charge : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ... ## $ total_intl_minutes : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ... ## $ total_intl_calls : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ... ## $ total_intl_charge : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ... ## $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ... ## $ churn : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... churn_train &lt;- churn[1:3333,] churn_test &lt;- churn[3334:5000,] rbind(ChurnTrain = prop.table(table(churn_train$churn)), ChurnTest = prop.table(table(churn_test$churn))) ## no yes ## ChurnTrain 0.8550855 0.1449145 ## ChurnTest 0.8656269 0.1343731 churn_logit &lt;- glm(churn ~ ., data = churn_train, family = binomial(link = &quot;logit&quot;)) summary(churn_logit) ## ## Call: ## glm(formula = churn ~ ., family = binomial(link = &quot;logit&quot;), data = churn_train) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.1532 -0.5132 -0.3402 -0.1953 3.2528 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -8.6515638 0.7243142 -11.944 &lt; 2e-16 *** ## account_length 0.0008458 0.0013912 0.608 0.543199 ## international_planyes 2.0427543 0.1454974 14.040 &lt; 2e-16 *** ## voice_mail_planyes -2.0250146 0.5740840 -3.527 0.000420 *** ## number_vmail_messages 0.0358803 0.0180108 1.992 0.046355 * ## total_day_minutes -0.2441993 3.2742224 -0.075 0.940547 ## total_day_calls 0.0031962 0.0027612 1.158 0.247048 ## total_day_charge 1.5127081 19.2601862 0.079 0.937398 ## total_eve_minutes 0.8186945 1.6357258 0.501 0.616717 ## total_eve_calls 0.0010579 0.0027826 0.380 0.703817 ## total_eve_charge -9.5463678 19.2437266 -0.496 0.619840 ## total_night_minutes -0.1238287 0.8764906 -0.141 0.887650 ## total_night_calls 0.0006993 0.0028419 0.246 0.805628 ## total_night_charge 2.8338084 19.4769043 0.145 0.884319 ## total_intl_minutes -4.3377914 5.3009719 -0.818 0.413185 ## total_intl_calls -0.0929680 0.0250603 -3.710 0.000207 *** ## total_intl_charge 16.3900316 19.6323938 0.835 0.403804 ## number_customer_service_calls 0.5135638 0.0392678 13.079 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2758.3 on 3332 degrees of freedom ## Residual deviance: 2158.7 on 3315 degrees of freedom ## AIC: 2194.7 ## ## Number of Fisher Scoring iterations: 6 exp(coef(churn_logit)) # 해석상의 용이를 위해 오즈비를 지수변환 함 ## (Intercept) account_length ## 1.748532e-04 1.000846e+00 ## international_planyes voice_mail_planyes ## 7.711821e+00 1.319919e-01 ## number_vmail_messages total_day_minutes ## 1.036532e+00 7.833315e-01 ## total_day_calls total_day_charge ## 1.003201e+00 4.539006e+00 ## total_eve_minutes total_eve_calls ## 2.267538e+00 1.001058e+00 ## total_eve_charge total_night_minutes ## 7.146035e-05 8.835312e-01 ## total_night_calls total_night_charge ## 1.000700e+00 1.701012e+01 ## total_intl_minutes total_intl_calls ## 1.306535e-02 9.112226e-01 ## total_intl_charge number_customer_service_calls ## 1.312503e+07 1.671236e+00 로지스틱 회귀모델의 통계적 유의성은 summary() 함수를 통해 제공되지 않아 직접 계산을 한다. Null deviance와 Residual deviance를 통해 검정할 수 있다. Deviance(이탈도) 모델의 적합도 정도를 나타내는 지표, 이탈도가 적을수록 우수한 모델임 Null deviance는 상수항만을 포함하는 모델이고, Residual deviance는 모든변수를 포함하는 모델이다. 예측변수를 포함될수록 설명력은 좋아지기 때문에 이탈도는 작아질 수밖에 없다. 예측변수에 의해 작아지는 정도가 통계적으로 유의한지를 검정한다. 이탈도는 \\(\\chi^2\\) 분포를 따르므로 \\(\\chi^2\\) 검정 통계량을 계산해서 검정한다. pchisq(q=(2758.3-2158.7), df=(3332-3315), lower.tail = F) ## [1] 1.731898e-116 pchisq(q = (churn_logit$null.deviance - churn_logit$deviance), df = (churn_logit$df.null - churn_logit$df.residual), lower.tail = F) ## [1] 1.757917e-116 churn_logit_pred &lt;- predict(churn_logit, newdata = churn_test, type = &quot;response&quot;) head(churn_logit_pred) ## 1 2 3 4 5 6 ## 0.07236813 0.05774332 0.22650409 0.15289153 0.07078500 0.05880824 churn_logit_pred &lt;- factor(churn_logit_pred &gt; 0.5, levels = c(FALSE, TRUE), labels = c(&quot;no&quot;, &quot;yes&quot;)) head(churn_logit_pred) ## 1 2 3 4 5 6 ## no no no no no no ## Levels: no yes table(churn_logit_pred) ## churn_logit_pred ## no yes ## 1595 72 table(churn_test$churn, churn_logit_pred, dnn=c(&quot;Acutal&quot;, &quot;Predicted&quot;)) ## Predicted ## Acutal no yes ## no 1414 29 ## yes 181 43 mean(churn_test$churn == churn_logit_pred) ## [1] 0.8740252 단계별 변수 선택을 통해 유의한 변수만 선택하만 보다 간결한 모델을 생성할 수 있다. churn_logit2 &lt;- step(churn_logit, trace = F) summary(churn_logit2) ## Error in summary(churn_logit2): class name too long in &#39;summary&#39; pchisq(q = (churn_logit2$null.deviance - churn_logit2$deviance), df = (churn_logit2$df.null - churn_logit2$df.residual), lower.tail = F) ## Error in churn_logit2$null.deviance: class name too long in &#39;$&#39; 특정 예측변수의 변화에 따른 결과변수의 변화를 보기 위해서는 다른 변수를 고정한 후 특정 변수만 변화를 시키면서 결과를 확인할 수 있다. table(churn_test$number_customer_service_calls) ## ## 0 1 2 3 4 5 6 7 ## 326 605 368 236 86 30 12 4 서비스센터 전화회수의 분포는 0 ~ 7번으로 구성되어 있다. 나머지 변수는 평균이나 가장 낮은 변주 유형으로 고정한 데이터셋을 생성한다. testdata &lt;- data.frame( number_customer_service_calls = c(0:7), international_plan = &quot;no&quot;, voice_mail_plan =&quot;no&quot; , number_vmail_messages = mean(churn_test$number_vmail_messages), total_day_charge = mean(churn_test$total_day_charge), total_eve_minutes = mean(churn_test$total_eve_minutes), total_night_charge = mean(churn_test$total_night_charge), total_intl_calls = mean(churn_test$total_intl_calls), total_intl_charge = mean(churn_test$total_intl_charge) ); testdata ## number_customer_service_calls international_plan voice_mail_plan ## 1 0 no no ## 2 1 no no ## 3 2 no no ## 4 3 no no ## 5 4 no no ## 6 5 no no ## 7 6 no no ## 8 7 no no ## number_vmail_messages total_day_charge total_eve_minutes total_night_charge ## 1 7.067786 30.82434 199.9492 8.974559 ## 2 7.067786 30.82434 199.9492 8.974559 ## 3 7.067786 30.82434 199.9492 8.974559 ## 4 7.067786 30.82434 199.9492 8.974559 ## 5 7.067786 30.82434 199.9492 8.974559 ## 6 7.067786 30.82434 199.9492 8.974559 ## 7 7.067786 30.82434 199.9492 8.974559 ## 8 7.067786 30.82434 199.9492 8.974559 ## total_intl_calls total_intl_charge ## 1 4.346731 2.784421 ## 2 4.346731 2.784421 ## 3 4.346731 2.784421 ## 4 4.346731 2.784421 ## 5 4.346731 2.784421 ## 6 4.346731 2.784421 ## 7 4.346731 2.784421 ## 8 4.346731 2.784421 testdata$prob &lt;- predict(churn_logit2, newdata = testdata, type = &quot;response&quot;) ## Error in predict(churn_logit2, newdata = testdata, type = &quot;response&quot;): class name too long in &#39;predict&#39; testdata[c(1,10)] ## Error in `[.data.frame`(testdata, c(1, 10)): undefined columns selected 이항 로지스틱분석은 과산포의 문제를 확인해야 한다. 결과변수의 실제 관측된 분산이 이항분포의 기대되는 분산보다 더 클 때 발생한다. 과산포는 표준오차를 왜곡시켜 회귀계수의 유의성 검정을 부정확하게 만들 위험성이 있다. 과산포 발생 시 family 인수에 quasibinomial() 함수를 적용한다. 과산포를 확인하는 방법은 이탈도와 자유도간의 비율을 살펴본다. 이탈도대 자유도의 비율이 1을 크게 상외하면 과산포를 의심한다. deviance(churn_logit2) / df.residual(churn_logit2) ## Error in deviance(churn_logit2): class name too long in &#39;deviance&#39; 또는 binomial()와 quasibinomial() 함수를 적용한 모델을 생성하고 통계적으로 유의성을 검정하는 방법도 있다. fit.origin1 &lt;- glm(churn ~ number_customer_service_calls + international_plan + voice_mail_plan + number_vmail_messages + total_day_charge + total_eve_minutes + total_night_charge + total_intl_calls + total_intl_charge, data = churn_train, family = binomial(link = &quot;logit&quot;)) fit.origin2 &lt;- glm(churn ~ number_customer_service_calls + international_plan + voice_mail_plan + number_vmail_messages + total_day_charge + total_eve_minutes + total_night_charge + total_intl_calls + total_intl_charge, data = churn_train, family = quasibinomial(link = &quot;logit&quot;)) pchisq(summary(fit.origin2)$dispersion*fit.origin1$df.residual, fit.origin1$df.residual, lower.tail = F) ## [1] 0.08385493 위 예제에서는 p값이 0.08385493로 유의수준 0.05에서 통계적으로 과산포의 가능성은 작다고 볼 수 있다. 3.19.3 패널티 로지스틱회귀분석 3.16 참고 당뇨평(diabetes) 여부를 예측하는 모델을 생성한다. if(!require(mlbench)) { install.packages(&quot;mlbench&quot;); library(mlbench); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages data(&quot;PimaIndiansDiabetes2&quot;) str(PimaIndiansDiabetes2) ## &#39;data.frame&#39;: 768 obs. of 9 variables: ## $ pregnant: num 6 1 8 1 0 5 3 10 2 8 ... ## $ glucose : num 148 85 183 89 137 116 78 115 197 125 ... ## $ pressure: num 72 66 64 66 40 74 50 NA 70 96 ... ## $ triceps : num 35 29 NA 23 35 NA 32 NA 45 NA ... ## $ insulin : num NA NA NA 94 168 NA 88 NA 543 NA ... ## $ mass : num 33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 NA ... ## $ pedigree: num 0.627 0.351 0.672 0.167 2.288 ... ## $ age : num 50 31 32 21 33 30 26 29 53 54 ... ## $ diabetes: Factor w/ 2 levels &quot;neg&quot;,&quot;pos&quot;: 2 1 2 1 2 1 2 1 2 2 ... # 결측치 제거하는 전처리 PimaIndiansDiabetes3 &lt;- na.omit(PimaIndiansDiabetes2) if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } set.seed(123) train.index &lt;- createDataPartition(y = PimaIndiansDiabetes3$diabetes, p = 0.7, list = F) diabetes.train &lt;- PimaIndiansDiabetes3[train.index, ] diabetes.test &lt;- PimaIndiansDiabetes3[-train.index, ] class.status &lt;- rbind( Train = prop.table(table(diabetes.train$diabetes)), Test = prop.table(table(diabetes.test$diabetes)) ); colnames(class.status) &lt;- c(&quot;Negative&quot;, &quot;Positive&quot;); class.status ## Negative Positive ## Train 0.6690909 0.3309091 ## Test 0.6666667 0.3333333 # 예측오차를 최소로 하는 최적의 lambda 계산 if(!require(glmnet)) { install.packages(&quot;glmnet&quot;); library(glmnet); } x &lt;- model.matrix(diabetes ~ ., diabetes.train)[, -1] y &lt;- ifelse(diabetes.train$diabetes == &quot;pos&quot;, 1, 0) test.x &lt;- model.matrix(diabetes ~ ., diabetes.test)[, -1] test.y &lt;- diabetes.test$diabetes diabetes.cv &lt;- cv.glmnet(x, y, family = &quot;binomial&quot;, alpha = 1) # lasso 회귀모델 diabetes.lambda &lt;- cbind(lambda.min = diabetes.cv$lambda.min, lambda.1se = diabetes.cv$lambda.1se) rownames(diabetes.lambda) &lt;- c(&quot;value&quot;); diabetes.lambda ## lambda.min lambda.1se ## value 0.01578334 0.05289948 cbind(lambda.min = coef(diabetes.cv, diabetes.cv$lambda.min), lambda.1se = coef(diabetes.cv, diabetes.cv$lambda.1se) ) ## 9 x 2 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 s1 ## (Intercept) -8.747546346 -5.9547905324 ## pregnant 0.001210911 . ## glucose 0.033473180 0.0281738015 ## pressure . . ## triceps 0.025187290 0.0149718685 ## insulin 0.001292712 0.0002823976 ## mass 0.038416287 0.0146328065 ## pedigree 1.025851784 0.3927570516 ## age 0.029786375 0.0153986132 예측 오차를 최소로 하는 lambda를 사용하여 모델을 생성한 후 성능을 평가한다. diabets.gnet.min &lt;- glmnet(x, y, family = &quot;binomial&quot;, alpha = 1, lambda = diabetes.cv$lambda.min) diabets.gnet.min.pred &lt;- predict(diabets.gnet.min, test.x, type=&quot;response&quot;) diabets.gnet.min.pred &lt;- ifelse(diabets.gnet.min.pred &gt; 0.5, &quot;pos&quot;, &quot;neg&quot;) table(test.y, diabets.gnet.min.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Predicted ## Actual neg pos ## neg 69 9 ## pos 20 19 mean(test.y == diabets.gnet.min.pred) ## [1] 0.7521368 간명도를 고려한 1se lambda를 사용하여 모델을 생성한 후 성능을 평가한다. diabets.gnet.1se &lt;- glmnet(x, y, family = &quot;binomial&quot;, alpha = 1, lambda = diabetes.cv$lambda.1se) diabets.gnet.1se.pred &lt;- predict(diabets.gnet.1se, test.x, type=&quot;response&quot;) diabets.gnet.1se.pred &lt;- ifelse(diabets.gnet.1se.pred &gt; 0.5, &quot;pos&quot;, &quot;neg&quot;) table(test.y, diabets.gnet.1se.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Predicted ## Actual neg pos ## neg 71 7 ## pos 21 18 mean(test.y == diabets.gnet.min.pred) ## [1] 0.7521368 모든 예측변수를 사용한 이항 로지스틱회귀모델을 생성하고 성능을 평가한다. diabetes.logit &lt;- glm(diabetes ~ ., data = diabetes.train, family = binomial(link = &quot;logit&quot;)) diabetes.logit.pred &lt;- predict(diabetes.logit, diabetes.test, type = &quot;response&quot;) diabetes.logit.pred &lt;- ifelse(diabetes.logit.pred &gt; 0.5, &quot;pos&quot;, &quot;neg&quot;) table(diabetes.test$diabetes, diabetes.logit.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Predicted ## Actual neg pos ## neg 66 12 ## pos 20 19 mean(diabetes.test$diabetes == diabetes.logit.pred) ## [1] 0.7264957 최종 모델별 예측정확도는 다음과 같고 간명도 관점에서 1se lambda를 이용한 모델을 선택하는 것이 바람직 하다. perf.stats &lt;- rbind( lambda.min = mean(test.y == diabets.gnet.min.pred), lambda.1se = mean(test.y == diabets.gnet.1se.pred), predictor.all = mean(diabetes.test$diabetes == diabetes.logit.pred) ); colnames(perf.stats) &lt;- c(&quot;Accuracy&quot;); perf.stats ## Accuracy ## lambda.min 0.7521368 ## lambda.1se 0.7606838 ## predictor.all 0.7264957 "],["til20220320.html", "3.20 TIL20220320", " 3.20 TIL20220320 3.20.1 다항 로지스틱회귀분석 세 개 이상의 범주를 갖는 결과변수의 사건발생확률을 예측한다. if(!require(EffectStars)) { install.packages(&quot;EffectStars&quot;); library(EffectStars); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages data(PID) str(PID) ## &#39;data.frame&#39;: 944 obs. of 6 variables: ## $ TVnews : int 7 1 7 4 7 3 7 1 7 0 ... ## $ PID : Factor w/ 3 levels &quot;Democrat&quot;,&quot;Independent&quot;,..: 3 1 1 1 1 1 1 2 2 1 ... ## $ Income : num 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 ... ## $ Education : Factor w/ 2 levels &quot;low&quot;,&quot;high&quot;: 1 2 2 2 2 2 2 2 2 1 ... ## $ Age : int 36 20 24 28 68 21 77 21 31 39 ... ## $ Population: int 0 190 31 83 640 110 100 31 180 2800 ... levels(PID$PID) ## [1] &quot;Democrat&quot; &quot;Independent&quot; &quot;Republican&quot; if(!require(VGAM)) { install.packages(&quot;VGAM&quot;); library(VGAM); } pid.mlogit &lt;- vglm(PID ~ ., family = multinomial(), data = PID) summary(pid.mlogit) ## ## Call: ## vglm(formula = PID ~ ., family = multinomial(), data = PID) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept):1 1.2296119 0.3031106 4.057 4.98e-05 *** ## (Intercept):2 0.1275830 0.3405777 0.375 0.70795 ## TVnews:1 0.0440935 0.0321897 1.370 0.17075 ## TVnews:2 0.0247123 0.0350497 0.705 0.48077 ## Income:1 -0.0165464 0.0027760 -5.960 2.51e-09 *** ## Income:2 -0.0002418 0.0027864 -0.087 0.93085 ## Educationhigh:1 -0.2886055 0.1759813 -1.640 0.10101 ## Educationhigh:2 -0.3530642 0.1971199 -1.791 0.07328 . ## Age:1 -0.0077751 0.0052743 -1.474 0.14044 ## Age:2 -0.0066722 0.0059864 -1.115 0.26503 ## Population:1 0.0002592 0.0000984 2.634 0.00844 ** ## Population:2 0.0002052 0.0001053 1.949 0.05135 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Names of linear predictors: log(mu[,1]/mu[,3]), log(mu[,2]/mu[,3]) ## ## Residual deviance: 1969.38 on 1876 degrees of freedom ## ## Log-likelihood: -984.6901 on 1876 degrees of freedom ## ## Number of Fisher scoring iterations: 4 ## ## No Hauck-Donner effect found in any of the estimates ## ## ## Reference group is level 3 of the response vglm() 함수는 마지막 범주를 기준범주로 사용한다. exp(coef(pid.mlogit)) ## (Intercept):1 (Intercept):2 TVnews:1 TVnews:2 Income:1 ## 3.4199020 1.1360792 1.0450800 1.0250202 0.9835898 ## Income:2 Educationhigh:1 Educationhigh:2 Age:1 Age:2 ## 0.9997582 0.7493078 0.7025321 0.9922550 0.9933500 ## Population:1 Population:2 ## 1.0002592 1.0002052 pid.mlogit.pred &lt;- fitted(pid.mlogit) head(pid.mlogit.pred) ## Democrat Independent Republican ## 1 0.6247928 0.1932306 0.1819766 ## 2 0.5739020 0.1817883 0.2443097 ## 3 0.6109039 0.1745194 0.2145766 ## 4 0.5843473 0.1772105 0.2384421 ## 5 0.5839453 0.1694467 0.2466080 ## 6 0.5856824 0.1794368 0.2348808 교육수준에 정치 성향에 미치는 영향을 보고 위해 교육수준은 변화시키고 나머지 예측변수는 고정된 데이터셋을 생성한다. testdata &lt;- data.frame( Education = c(&quot;low&quot;, &quot;high&quot;), TVnews = mean(PID$TVnews), Income = mean(PID$Income), Age = mean(PID$Age), Population = mean(PID$Population) ); testdata; ## Education TVnews Income Age Population ## 1 low 3.727754 46.57574 47.04343 306.3814 ## 2 high 3.727754 46.57574 47.04343 306.3814 pid.mlogit.pred &lt;- predict(pid.mlogit, newdata = testdata, type=&quot;response&quot;) cbind(testdata, pid.mlogit.pred) ## Education TVnews Income Age Population Democrat Independent ## 1 low 3.727754 46.57574 47.04343 306.3814 0.4169951 0.2852971 ## 2 high 3.727754 46.57574 47.04343 306.3814 0.3854667 0.2472630 ## Republican ## 1 0.2977078 ## 2 0.3672703 교육수준이 low -&gt; higt로 변화하면 Democrat일 확률이 감소하고, Republican일 확률이 증가하는 것을 볼 수 있다. 하지만 교육수준의 변화와 상관없이 항상 Democrate으로 예측할 확률이 가장 높기 때문에 교육수준과 성치성향과의 명확한 관계가 있다고 판단하기는 어렵다. 이는 교육수준의 회귀계수가 통계적으로 유의하지 않다는 것을 의미하기도 한다. 소득수준을 기준으로 같은 분석을 진행한다. range(PID$Income) ## [1] 1.5 115.0 testdata &lt;- data.frame( Education = rep(&quot;low&quot;, 5), TVnews = mean(PID$TVnews), Income = seq(20, 100, 20), Age = mean(PID$Age), Population = mean(PID$Population) ); testdata; ## Education TVnews Income Age Population ## 1 low 3.727754 20 47.04343 306.3814 ## 2 low 3.727754 40 47.04343 306.3814 ## 3 low 3.727754 60 47.04343 306.3814 ## 4 low 3.727754 80 47.04343 306.3814 ## 5 low 3.727754 100 47.04343 306.3814 pid.mlogit.pred &lt;- predict(pid.mlogit, newdata = testdata, type=&quot;response&quot;) cbind(testdata, pid.mlogit.pred) ## Education TVnews Income Age Population Democrat Independent ## 1 low 3.727754 20 47.04343 306.3814 0.5253435 0.2330383 ## 2 low 3.727754 40 47.04343 306.3814 0.4434690 0.2725630 ## 3 low 3.727754 60 47.04343 306.3814 0.3645531 0.3104445 ## 4 low 3.727754 80 47.04343 306.3814 0.2923033 0.3448868 ## 5 low 3.727754 100 47.04343 306.3814 0.2292065 0.3747050 ## Republican ## 1 0.2416182 ## 2 0.2839680 ## 3 0.3250024 ## 4 0.3628100 ## 5 0.3960885 소득의 수준에 따른 정치성향이 다른 것을 알 수 있다. if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } str(fgl) # 유리 조각에 대한 성분 ## &#39;data.frame&#39;: 214 obs. of 10 variables: ## $ RI : num 3.01 -0.39 -1.82 -0.34 -0.58 ... ## $ Na : num 13.6 13.9 13.5 13.2 13.3 ... ## $ Mg : num 4.49 3.6 3.55 3.69 3.62 3.61 3.6 3.61 3.58 3.6 ... ## $ Al : num 1.1 1.36 1.54 1.29 1.24 1.62 1.14 1.05 1.37 1.36 ... ## $ Si : num 71.8 72.7 73 72.6 73.1 ... ## $ K : num 0.06 0.48 0.39 0.57 0.55 0.64 0.58 0.57 0.56 0.57 ... ## $ Ca : num 8.75 7.83 7.78 8.22 8.07 8.07 8.17 8.24 8.3 8.4 ... ## $ Ba : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Fe : num 0 0 0 0 0 0.26 0 0 0 0.11 ... ## $ type: Factor w/ 6 levels &quot;WinF&quot;,&quot;WinNF&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... levels(fgl$type) # (6개의 유리 유형) ## [1] &quot;WinF&quot; &quot;WinNF&quot; &quot;Veh&quot; &quot;Con&quot; &quot;Tabl&quot; &quot;Head&quot; # 변수 값의 범위가 다양하여 표준화하는 전처리 진행 fgl.scaled &lt;- cbind(scale(fgl[, 1:9]), fgl[10]) set.seed(123) train &lt;- sample(nrow(fgl), 0.7*nrow(fgl)) fgl.train &lt;- fgl.scaled[train, ] fgl.test &lt;- fgl.scaled[-train, ] rbind(Train = table(fgl.train$type), Test = table(fgl.train$type)) ## WinF WinNF Veh Con Tabl Head ## Train 48 54 10 11 5 21 ## Test 48 54 10 11 5 21 if(!require(nnet)) { install.packages(&quot;nnet&quot;); library(nnet); } fgl.mlogit &lt;- multinom(type ~ ., data = fgl.train, trace = 0) summary(fgl.mlogit) ## Call: ## multinom(formula = type ~ ., data = fgl.train, trace = 0) ## ## Coefficients: ## (Intercept) RI Na Mg Al ## WinNF 9.355295e-02 -0.8953382 -4.063962 -9.048398 -0.5114149 ## Veh -1.133317e+03 -8.6962954 -5.829434 -7.471188 -3.8837185 ## Con -1.775676e+03 809.3073019 -1498.700239 -5267.689197 2633.0124594 ## Tabl -5.707417e+03 1503.0305126 3453.631583 402.083873 4796.9312894 ## Head -3.440740e+03 3973.2180820 2766.948337 -567.865018 6106.0668610 ## Si K Ca Ba Fe ## WinNF -4.762664 -5.224543 -7.036873 -6.887587 0.3130040 ## Veh -9.568647 -8.386972 -2.916572 -3210.962581 0.2369889 ## Con 411.127579 -2096.906955 -3215.489974 3890.713665 -1142.1918831 ## Tabl 2213.126389 -5318.320092 850.190517 356.705595 -4547.5583934 ## Head 5085.219769 463.552740 -641.047023 4867.920523 -1662.5175407 ## ## Std. Errors: ## (Intercept) RI Na Mg Al Si K ## WinNF 2.250252 1.199628 2.399749 4.300370 1.600933 2.240364 2.512023 ## Veh 1.639861 2.688003 3.037652 5.870651 2.192671 3.194121 3.509944 ## Con 13.950757 10.090718 4.104262 13.278437 15.332909 3.331481 62.182580 ## Tabl 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ## Head 5.158491 8.757124 2.576395 9.600709 16.273983 12.993265 45.186352 ## Ca Ba Fe ## WinNF 4.440853 6.3418754 0.2713187 ## Veh 5.911691 0.5773154 0.4929929 ## Con 12.352283 16.6950553 7.2049922 ## Tabl 0.000000 0.0000000 0.0000000 ## Head 7.347112 1.8160539 3.0181253 ## ## Residual Deviance: 140.2764 ## AIC: 240.2764 multinom() 함수는 첫 번째 범주를 기준 범주로 사용한다. 회귀계수에 대한 유의확률을 제공하지 않아 별도로 계산을 해야 한다. 회귀계수를 표준오차로 나눠서 z 값을 계산하고 이 z 값으로 유의확률을 계산한다. z &lt;- summary(fgl.mlogit)$coefficients/summary(fgl.mlogit)$standard.errors p &lt;- (1- pnorm(abs(z), 0, 1))*2 print(p, digit=3) ## (Intercept) RI Na Mg Al Si K Ca Ba Fe ## WinNF 0.967 0.45546 0.0904 0.0354 0.7494 0.03352 0.0375 0.113 0.277 0.249 ## Veh 0.000 0.00122 0.0550 0.2031 0.0765 0.00274 0.0169 0.622 0.000 0.631 ## Con 0.000 0.00000 0.0000 0.0000 0.0000 0.00000 0.0000 0.000 0.000 0.000 ## Tabl 0.000 0.00000 0.0000 0.0000 0.0000 0.00000 0.0000 0.000 0.000 0.000 ## Head 0.000 0.00000 0.0000 0.0000 0.0000 0.00000 0.0000 0.000 0.000 0.000 fgl.mlogit.pred &lt;- predict(fgl.mlogit, fgl.test, type = &quot;response&quot;) ## Error in match.arg(type): &#39;arg&#39; should be one of &quot;class&quot;, &quot;probs&quot; head(fgl.mlogit.pred) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;fgl.mlogit.pred&#39; not found cbind(round(fgl.mlogit.pred, 3), fgl.test[&quot;type&quot;]) ## Error in cbind(round(fgl.mlogit.pred, 3), fgl.test[&quot;type&quot;]): object &#39;fgl.mlogit.pred&#39; not found fgl.mlogit.pred &lt;- colnames(fgl.mlogit.pred)[max.col(fgl.mlogit.pred)] ## Error in is.data.frame(x): object &#39;fgl.mlogit.pred&#39; not found head(fgl.mlogit.pred) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;fgl.mlogit.pred&#39; not found table(fgl.test$type, fgl.mlogit.pred, dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Error in table(fgl.test$type, fgl.mlogit.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)): object &#39;fgl.mlogit.pred&#39; not found table(fgl.test$type, factor(fgl.mlogit.pred, levels=levels(fgl.test$type), labels=levels(fgl.test$type)), dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Error in factor(fgl.mlogit.pred, levels = levels(fgl.test$type), labels = levels(fgl.test$type)): object &#39;fgl.mlogit.pred&#39; not found mean(fgl.test$type == fgl.mlogit.pred) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;fgl.mlogit.pred&#39; not found 100번의 교차 검정을 통해 보다 안정적인 예측 정확도를 계산한다. fgl.mlogit.cv &lt;- numeric() for(i in 1:100) { train &lt;- sample(nrow(fgl), 0.7*nrow(fgl)) fgl.train &lt;- fgl.scaled[train, ] fgl.test &lt;- fgl.scaled[-train, ] fgl.mlogit &lt;- multinom(type ~ ., data = fgl.train, trace = 0) fgl.mlogit.pred &lt;- predict(fgl.mlogit, fgl.test, type = &quot;probs&quot;) fgl.mlogit.pred &lt;- colnames(fgl.mlogit.pred)[max.col(fgl.mlogit.pred)] fgl.mlogit.cv[i] &lt;- mean(fgl.test$type == fgl.mlogit.pred) } summary(fgl.mlogit.cv) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4308 0.5692 0.6000 0.6063 0.6346 0.7538 boxplot(fgl.mlogit.cv, horizontal = T, col=&quot;tomato&quot;, xlab=&quot;Accuracy&quot;, main = &quot;Accuracy for Forensic Glass (100 samples)&quot;) # fgl.mlogit &lt;- vglm(type ~ ., family = multinomial(), data = fgl.train) # fgl.mlogit.pred &lt;- predict(fgl.mlogit, newdata = fgl.test, type=&quot;response&quot;) # fgl.mlogit.pred &lt;- colnames(fgl.mlogit.pred)[max.col(fgl.mlogit.pred)] # mean(fgl.test$type == fgl.mlogit.pred) "],["til20220321.html", "3.21 TIL20220321", " 3.21 TIL20220321 3.21.1 가설검정 3.21.1.1 범주형 데이터 3.21.1.1.1 한 집단일 때 일원 카이 제곱 검정 one sample \\(x^2\\) test, 적합성 검정에활용 # 주사위를 60번 던져 때, 기대빈도와 관측빈도가 적합한지 검정 # 귀무가설: 기대빈도와 관측빈도는 차이가 없다 # 대립가설: 기대빈도와 관측빈도는 차이가 있다. chisq.test(c(4,6,17,15,9,9), p = rep(1/6, 6)) ## ## Chi-squared test for given probabilities ## ## data: c(4, 6, 17, 15, 9, 9) ## X-squared = 12.8, df = 5, p-value = 0.02533 p값에 따라 유의수준 0.05에서 귀무가설을 기각하고 대립가설을 채택한다. 즉 주사위의 기대빈도와 관측빈도에는 차이가 있다고 판단할 수 있다. # 통신 3사 점유율 차이 40%, 30%, 30%인지 검정 chisq.test(c(45, 30, 25), p = c(0.4, 0.3, 0.3)) ## ## Chi-squared test for given probabilities ## ## data: c(45, 30, 25) ## X-squared = 1.4583, df = 2, p-value = 0.4823 3.21.1.1.2 두 집단일 때 이원 카이 제곱 검정 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } chisq.test(x=penguins$species, y=penguins$island) ## ## Pearson&#39;s Chi-squared test ## ## data: penguins$species and penguins$island ## X-squared = 299.55, df = 4, p-value &lt; 2.2e-16 if(!require(gmodels)) { install.packages(&quot;gmodels&quot;); library(gmodels); } CrossTable(x=penguins$species, y=penguins$island, chisq = T) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 344 ## ## ## | penguins$island ## penguins$species | Biscoe | Dream | Torgersen | Row Total | ## -----------------|-----------|-----------|-----------|-----------| ## Adelie | 44 | 56 | 52 | 152 | ## | 12.313 | 0.027 | 36.661 | | ## | 0.289 | 0.368 | 0.342 | 0.442 | ## | 0.262 | 0.452 | 1.000 | | ## | 0.128 | 0.163 | 0.151 | | ## -----------------|-----------|-----------|-----------|-----------| ## Chinstrap | 0 | 68 | 0 | 68 | ## | 33.209 | 77.157 | 10.279 | | ## | 0.000 | 1.000 | 0.000 | 0.198 | ## | 0.000 | 0.548 | 0.000 | | ## | 0.000 | 0.198 | 0.000 | | ## -----------------|-----------|-----------|-----------|-----------| ## Gentoo | 124 | 0 | 0 | 124 | ## | 66.463 | 44.698 | 18.744 | | ## | 1.000 | 0.000 | 0.000 | 0.360 | ## | 0.738 | 0.000 | 0.000 | | ## | 0.360 | 0.000 | 0.000 | | ## -----------------|-----------|-----------|-----------|-----------| ## Column Total | 168 | 124 | 52 | 344 | ## | 0.488 | 0.360 | 0.151 | | ## -----------------|-----------|-----------|-----------|-----------| ## ## ## Statistics for All Table Factors ## ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 299.5503 d.f. = 4 p = 1.354574e-63 ## ## ## 3.21.1.1.3 피셔 정확 검정 분할표를 그린 뒤 카이 제곱을 적용할 때 표본 수가 적거나 표본이 분팔표의 셀에 매우 치우치게 분포되어 있다면 카이 제곱 검정의 결과가 부정확할 수 있다. 기대 빈도가 5 이하인 셀이 전체의 20% 수준일 때 표본의 수가 적다고 볼 수 있다. 이런 경우 Fisher’s Exact Test를 적용한다. if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } xtabs( ~ W.Hnd + Clap, data = survey) ## Clap ## W.Hnd Left Neither Right ## Left 9 5 4 ## Right 29 45 143 chisq.test(survey$W.Hnd, survey$Clap) ## ## Pearson&#39;s Chi-squared test ## ## data: survey$W.Hnd and survey$Clap ## X-squared = 19.252, df = 2, p-value = 6.598e-05 fisher.test(survey$W.Hnd, survey$Clap) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: survey$W.Hnd and survey$Clap ## p-value = 0.0001413 ## alternative hypothesis: two.sided 3.21.1.1.4 맥니마 검정 (McNemar Test) 사건 전후의 차이 검정에 활용된다. Performance &lt;- matrix(c(794, 86, 150, 570), nrow = 2, dimnames = list( &quot;1st Survey&quot; = c(&quot;Approve&quot;, &quot;Disapprove&quot;), &quot;2nd Survey&quot; = c(&quot;Approve&quot;, &quot;Disapprove&quot;))) Performance ## 2nd Survey ## 1st Survey Approve Disapprove ## Approve 794 150 ## Disapprove 86 570 mcnemar.test(Performance) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: Performance ## McNemar&#39;s chi-squared = 16.818, df = 1, p-value = 4.115e-05 p값에 따라 첫번째 조사와 두번째 조사 간에는 유의확률 0.05 하에서 통계적으로 유의미한 차이가 있다. 참고로, 사건 전후의 차이 검정은 b=c를 검토하여 변화 여부를 판단할 수 있다. \\[b \\sim B(b+c, \\frac{1}{2})\\] 따라서 위 예제의 경우 86 ~ B(86+150, 1/2)를 검토한다. binom.test(86, 86+150, 0.5) ## ## Exact binomial test ## ## data: 86 and 86 + 150 ## number of successes = 86, number of trials = 236, p-value = 3.716e-05 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.3029404 0.4293268 ## sample estimates: ## probability of success ## 0.3644068 3.21.1.2 연속형 데이터 3.21.1.2.1 정규성 검정 3.21.1.2.1.1 shapiro.test() shapiro.test(rnorm(1000)) ## ## Shapiro-Wilk normality test ## ## data: rnorm(1000) ## W = 0.99841, p-value = 0.4971 3.21.1.2.1.2 ks.test() 콜모고로프 스미르노프 검정(Kolmogorov-Smirnov Test), 두 숫자 벡터 간의 차이가 없는지를 검정한다. ks.test(rnorm(100), rnorm(100)) ## ## Asymptotic two-sample Kolmogorov-Smirnov test ## ## data: rnorm(100) and rnorm(100) ## D = 0.1, p-value = 0.6994 ## alternative hypothesis: two-sided ks.test(rnorm(100), runif(100)) ## ## Asymptotic two-sample Kolmogorov-Smirnov test ## ## data: rnorm(100) and runif(100) ## D = 0.54, p-value = 4.335e-13 ## alternative hypothesis: two-sided x를 정규분포에서 추출하였는지 검정을 할 수도 있다. ks.test(rnorm(1000), &quot;pnorm&quot;, 0 ,1) ## ## Asymptotic one-sample Kolmogorov-Smirnov test ## ## data: rnorm(1000) ## D = 0.037474, p-value = 0.1206 ## alternative hypothesis: two-sided ks.test(runif(1000), &quot;pnorm&quot;, c(0, 1)) ## ## Asymptotic one-sample Kolmogorov-Smirnov test ## ## data: runif(1000) ## D = 0.50021, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided 3.21.1.2.1.3 qqplot() x &lt;- rnorm(1000, mean = 10, sd = 1) qqnorm(x); qqline(x, lty=2, col = &quot;blue&quot;) x &lt;- runif(1000) qqnorm(x); qqline(x, lty=2, col = &quot;red&quot;) qqplot(runif(1000, min=1, max=10), 1:10) qqplot(rnorm(1000), 1:1000) 3.21.1.2.2 한 집단일 때 3.21.1.2.2.1 one sample t-test 3.21.1.2.2.1.1 정규성을 만족할 경우 t.test() 3.21.1.2.2.1.2 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon signed rank test 3.21.1.2.3 두 집단일 때 3.21.1.2.3.1 independent two sample t-test 3.21.1.2.3.1.1 정규성을 만족할 경우 t.test() 3.21.1.2.3.1.2 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon rank sum test 3.21.1.2.3.2 paired two sample t-test 3.21.1.2.3.2.1 정규성을 만족할 경우 t.test() 3.21.1.2.3.2.2 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon signed rank test with paired 3.21.1.2.4 세 집단 이상일 때 3.21.1.2.4.0.1 정규성을 만족할 경우 aov() 3.21.1.2.4.0.2 정규성을 만족하지 못할 경우 kruskal() 3.21.1.2.4.0.3 사후검정 Fisher’s LSD, Bonferroni, Shelf, Turkey, Duncan 등 3.21.2 비율검정 3.21.2.1 일표본 binom.test() 3.21.2.2 이표본 prop.test() 3.21.3 동질성 검사 3.21.3.1 이표본 var.test() 3.21.3.2 삼표본 이상 bartlett.test() "],["til20220322.html", "3.22 TIL20220322", " 3.22 TIL20220322 3.22.1 비모수 검정 if(!require(moonBook)) { install.packages(&quot;moonBook&quot;); library(moonBook); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } data &lt;- penguins densityplot(body_mass_g ~ sex, data = data) 정규성 검정 shapiro.test(data$body_mass_g) ## ## Shapiro-Wilk normality test ## ## data: data$body_mass_g ## W = 0.95921, p-value = 3.679e-08 Wilcoxon Rank Sum Test wilcox.result &lt;- wilcox.test(body_mass_g ~ sex, data); wilcox.result ## ## Wilcoxon rank sum test with continuity correction ## ## data: body_mass_g by sex ## W = 6874.5, p-value = 1.813e-15 ## alternative hypothesis: true location shift is not equal to 0 Kruskal-Wallis Rank Sun Test kruskal.result &lt;- kruskal.test(body_mass_g ~ species, data); kruskal.result ## ## Kruskal-Wallis rank sum test ## ## data: body_mass_g by species ## Kruskal-Wallis chi-squared = 217.6, df = 2, p-value &lt; 2.2e-16 다중비교 mctp in nparcomp package if(!require(nparcomp)) { install.packages(&quot;nparcomp&quot;); library(nparcomp); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages mctp(body_mass_g ~ species, data) ## ## #----------------Nonparametric Multiple Comparisons for relative effects---------------# ## ## - Alternative Hypothesis: True differences of relative effects are not equal to 0 ## - Estimation Method: Global Pseudo Ranks ## - Type of Contrast : Tukey ## - Confidence Level: 95 % ## - Method = Fisher with 143 DF ## ## #--------------------------------------------------------------------------------------# ## ## $Data.Info ## Sample Size Effect Lower Upper ## 1 Adelie 151 0.3306848 0.3079187 0.3542725 ## 2 Chinstrap 68 0.3483905 0.3252036 0.3723185 ## 3 Gentoo 123 0.8209247 0.8149834 0.8267158 ## ## $Contrast ## 1 2 3 ## 2 - 1 -1 1 0 ## 3 - 1 -1 0 1 ## 3 - 2 0 -1 1 ## ## $Analysis ## Estimator Lower Upper Statistic p.Value ## 2 - 1 0.018 -0.044 0.080 0.628 0.7107447 ## 3 - 1 0.490 0.457 0.522 27.622 0.0000000 ## 3 - 2 0.473 0.438 0.506 25.876 0.0000000 ## ## $Analysis.Inf ## Estimator Lower Upper Statistic p.Value ## 2 - 1 0.0177057 -0.04437702 0.0796522 0.627583 0.7107447 ## 3 - 1 0.4902399 0.45709074 0.5220290 27.621509 0.0000000 ## 3 - 2 0.4725342 0.43792131 0.5057482 25.875668 0.0000000 ## ## $Overall ## Quantile p.Value ## 1 2.201406 0 ## ## $input ## $input$formula ## body_mass_g ~ species ## ## $input$data ## # A tibble: 344 × 8 ## species island bill_length_mm bill_depth_mm flipper_…¹ body_…² sex year ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 male 2007 ## 2 Adelie Torgersen 39.5 17.4 186 3800 fema… 2007 ## 3 Adelie Torgersen 40.3 18 195 3250 fema… 2007 ## 4 Adelie Torgersen NA NA NA NA &lt;NA&gt; 2007 ## 5 Adelie Torgersen 36.7 19.3 193 3450 fema… 2007 ## 6 Adelie Torgersen 39.3 20.6 190 3650 male 2007 ## 7 Adelie Torgersen 38.9 17.8 181 3625 fema… 2007 ## 8 Adelie Torgersen 39.2 19.6 195 4675 male 2007 ## 9 Adelie Torgersen 34.1 18.1 193 3475 &lt;NA&gt; 2007 ## 10 Adelie Torgersen 42 20.2 190 4250 &lt;NA&gt; 2007 ## # … with 334 more rows, and abbreviated variable names ¹​flipper_length_mm, ## # ²​body_mass_g ## ## $input$type ## [1] &quot;Tukey&quot; ## ## $input$conf.level ## [1] 0.95 ## ## $input$alternative ## [1] &quot;two.sided&quot; ## ## $input$asy.method ## [1] &quot;fisher&quot; ## ## $input$plot.simci ## [1] FALSE ## ## $input$control ## NULL ## ## $input$info ## [1] TRUE ## ## $input$rounds ## [1] 3 ## ## $input$contrast.matrix ## NULL ## ## $input$correlation ## [1] FALSE ## ## $input$effect ## [1] &quot;unweighted&quot; ## ## $input$const ## [1] 0.5875441 ## ## ## $text.Output ## [1] &quot;True differences of relative effects are not equal to 0&quot; ## ## $text.output.W ## [1] &quot;Global Pseudo Ranks&quot; ## ## $connames ## [1] &quot;2 - 1&quot; &quot;3 - 1&quot; &quot;3 - 2&quot; ## ## $AsyMethod ## [1] &quot;Fisher with 143 DF&quot; ## ## attr(,&quot;class&quot;) ## [1] &quot;mctp&quot; 3.22.2 ANOVA in R 3.22.2.1 ANOVA 가정 점검 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } data &lt;- penguins %&gt;% select(body_mass_g, species, sex) %&gt;% na.omit() ggplot(data, aes(species, body_mass_g, col=sex)) + geom_boxplot() + theme_bw() 펭귄 종에 따른 몸무게의 유의한 차이가 있는지 ANOVA로 분석한다. 신뢰성 있는 결과 도출을 위해 아래의 가정을 확인한다. 변수 유형 독립변수 범주형, 종속변수 연속형 str(data) ## tibble [333 × 3] (S3: tbl_df/tbl/data.frame) ## $ body_mass_g: int [1:333] 3750 3800 3250 3450 3650 3625 4675 3200 3800 4400 ... ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 1 2 1 2 1 2 2 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:11] 4 9 10 11 12 48 179 219 257 269 ... ## ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;4&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; ... 독립성, durbinWatsonTest() 함수를 통해 통계적으로 검정 if(!require(car)) { install.packages(&quot;car&quot;); library(car); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages data.aov &lt;- aov(body_mass_g ~ species, data) durbinWatsonTest(data.aov) ## lag Autocorrelation D-W Statistic p-value ## 1 -0.4946035 2.989155 0 ## Alternative hypothesis: rho != 0 정규성 Shapiro-Wilk normality test Kolmogorov-Smirnov test QQPlot, Histogram # Shapiro-Wilk normality test shapiro.test(data.aov$residuals) ## ## Shapiro-Wilk normality test ## ## data: data.aov$residuals ## W = 0.9922, p-value = 0.07835 # Kolmogorov-Smirnov test ks.test(x = data$species, y = data$body_mass_g) ## ## Asymptotic two-sample Kolmogorov-Smirnov test ## ## data: data$species and data$body_mass_g ## D = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided # QQPlot, Histogram qqPlot(data.aov) ## [1] 164 186 등분산성 Levene’s test Bartlette test Boxplot leveneTest(body_mass_g ~ species, data) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 5.1349 0.006367 ** ## 330 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 leveneTest(body_mass_g ~ species*sex, data) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 5 1.3908 0.2272 ## 327 bartlett.test(body_mass_g ~ species, data) ## ## Bartlett test of homogeneity of variances ## ## data: body_mass_g by species ## Bartlett&#39;s K-squared = 5.692, df = 2, p-value = 0.05808 bartlett.test(body_mass_g ~ interaction(species,sex), data) ## ## Bartlett test of homogeneity of variances ## ## data: body_mass_g by interaction(species, sex) ## Bartlett&#39;s K-squared = 7.6908, df = 5, p-value = 0.1741 이상치 Boxplot, outlierTest() outlierTest(data.aov) ## No Studentized residuals with Bonferroni p &lt; 0.05 ## Largest |rstudent|: ## rstudent unadjusted p-value Bonferroni p ## 164 2.655717 0.0082993 NA range(data$body_mass_g); data[164,] ## [1] 2700 6300 ## # A tibble: 1 × 3 ## body_mass_g species sex ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; ## 1 6300 Gentoo male 3.22.2.2 ANOVA oneway.test(…, var.equal=) oneway.result &lt;- oneway.test(body_mass_g ~ species, data, var.equal = F); oneway.result ## ## One-way analysis of means (not assuming equal variances) ## ## data: body_mass_g and species ## F = 316.5, num df = 2.00, denom df = 187.68, p-value &lt; 2.2e-16 aov() aov.result &lt;- aov(body_mass_g ~ species, data) summary(aov.result) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## species 2 145190219 72595110 341.9 &lt;2e-16 *** ## Residuals 330 70069447 212332 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Kruskal-Wallis test (정규성 불만족 시) kruskal.test(body_mass_g ~ species, data) ## ## Kruskal-Wallis rank sum test ## ## data: body_mass_g by species ## Kruskal-Wallis chi-squared = 212.09, df = 2, p-value &lt; 2.2e-16 3.22.2.3 사후검정 Tukey HSD TukeyHSD(aov.result) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = body_mass_g ~ species, data = data) ## ## $species ## diff lwr upr p adj ## Chinstrap-Adelie 26.92385 -132.3528 186.2005 0.916431 ## Gentoo-Adelie 1386.27259 1252.2897 1520.2554 0.000000 ## Gentoo-Chinstrap 1359.34874 1194.4304 1524.2671 0.000000 if(!require(multcomp)) { install.packages(&quot;multcomp&quot;); library(multcomp); } tukey.result &lt;- glht(aov.result, linfct = mcp(species = &quot;Tukey&quot;)); tukey.result ## ## General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Linear Hypotheses: ## Estimate ## Chinstrap - Adelie == 0 26.92 ## Gentoo - Adelie == 0 1386.27 ## Gentoo - Chinstrap == 0 1359.35 plot(tukey.result, las=1) Dunnett if(!require(multcomp)) { install.packages(&quot;multcomp&quot;); library(multcomp); } dunnett.result &lt;- glht(aov.result, linfct = mcp(species = &quot;Dunnett&quot;)); dunnett.result ## ## General Linear Hypotheses ## ## Multiple Comparisons of Means: Dunnett Contrasts ## ## ## Linear Hypotheses: ## Estimate ## Chinstrap - Adelie == 0 26.92 ## Gentoo - Adelie == 0 1386.27 Bonferroni correction pairwise.t.test(data$body_mass_g, data$species, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: data$body_mass_g and data$species ## ## Adelie Chinstrap ## Chinstrap 1 - ## Gentoo &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: bonferroni "],["til20220323.html", "3.23 TIL20220323", " 3.23 TIL20220323 3.23.1 히트맵 in R if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } data &lt;- penguins data.matrix &lt;- as.matrix(cor(data[,3:6], use=&quot;complete.obs&quot;)) 3.23.1.1 heatmap() in base if(!require(reshape2)) { install.packages(&quot;reshape2&quot;); library(reshape2); } heatmap(data.matrix, Rowv = NA, Colv = NA) 3.23.1.2 heatmap.2() in gplots if(!require(gplots)) { install.packages(&quot;gplots&quot;); library(gplots); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages heatmap.2(data.matrix, Rowv = NA, Colv = NA, ) 3.23.1.3 geom_tile() in ggplot2 if(!require(reshape2)) { install.packages(&quot;reshape2&quot;); library(reshape2); } if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } data.melted &lt;- melt(data.matrix); head(data.melted) ## Var1 Var2 value ## 1 bill_length_mm bill_length_mm 1.0000000 ## 2 bill_depth_mm bill_length_mm -0.2350529 ## 3 flipper_length_mm bill_length_mm 0.6561813 ## 4 body_mass_g bill_length_mm 0.5951098 ## 5 bill_length_mm bill_depth_mm -0.2350529 ## 6 bill_depth_mm bill_depth_mm 1.0000000 ggplot(data.melted, aes(x=Var1, y=Var2, fill = value)) + geom_tile() + scale_fill_gradient2(low=&quot;red&quot;, mid = &quot;white&quot;, high=&quot;blue&quot;) + guides(fill = guide_colorbar(barwidth = .5, barheight = 15)) "],["til20220324.html", "3.24 TIL20220324", " 3.24 TIL20220324 3.24.1 기계학습 모델링 with Caret 데이터 준비 데이터 탐색 데이터 전처리 데이터 분할 모델 학습 예측 및 성능평가 모델 개선 # 데이터 준비 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } if(!require(mlbench)) { install.packages(&quot;mlbench&quot;); library(mlbench); } data &lt;- BreastCancer ## Error in eval(expr, envir, enclos): object &#39;BreastCancer&#39; not found # 데이터 탐색 str(data) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... summary(data) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 colSums(is.na(data)) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 table(data$Class) ## &lt; table of extent 0 &gt; # 데이터 전처리 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } data &lt;- data %&gt;% select(-Id) # 필요한 컬럼 제외 ## Error in `select()`: ## ! Can&#39;t subset columns that don&#39;t exist. ## ✖ Column `Id` doesn&#39;t exist. data &lt;- data %&gt;% na.omit() # 결측치 제외 (16/699이므로) # 데이터 분할 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } train.index &lt;- createDataPartition(data$Class, p=.7, list=F) ## Error in createDataPartition(data$Class, p = 0.7, list = F): y must have at least 2 data points data.train &lt;- data[train.index, ] data.test &lt;- data[-train.index, ] # 모델 학습 trCtrl.up &lt;- trainControl(sampling = &quot;up&quot;) trCtrl.down &lt;- trainControl(sampling = &quot;down&quot;) model.dt.up &lt;- train(Class ~ ., data = data.train, method = &quot;rpart&quot;, trControl = trCtrl.up) ## Error in eval(predvars, data, env): object &#39;Class&#39; not found model.dt.down &lt;- train(Class ~ ., data = data.train, method = &quot;rpart&quot;, trControl = trCtrl.down) ## Error in eval(predvars, data, env): object &#39;Class&#39; not found model.list &lt;- list(up = model.dt.up, down = model.dt.down) ## Error in eval(expr, envir, enclos): object &#39;model.dt.up&#39; not found model.resamples &lt;- resamples(model.list) ## Error in resamples(model.list): object &#39;model.list&#39; not found dotplot(model.resamples) ## Error in dotplot(model.resamples): object &#39;model.resamples&#39; not found # 예측 및 성능평가 model.dt.up.pred &lt;- predict(model.dt.up, data.test) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.up&#39; not found model.dt.down.pred &lt;- predict(model.dt.down, data.test) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.down&#39; not found rbind(up = mean(model.dt.up.pred == data.test$Class), down = mean(model.dt.down.pred == data.test$Class) ) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;model.dt.up.pred&#39; not found if(!require(pROC)) { install.packages(&quot;pROC&quot;); library(pROC); } model.dt.up.pred &lt;- predict(model.dt.up, data.test, type = &quot;prob&quot;) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.up&#39; not found model.dt.down.pred &lt;- predict(model.dt.down, data.test, type = &quot;prob&quot;) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.down&#39; not found roc(data.test$Class, model.dt.up.pred[,1], plot=T, print.auc=T, col=&quot;red&quot;) ## Error in roc.default(data.test$Class, model.dt.up.pred[, 1], plot = T, : No valid data provided. roc(data.test$Class, model.dt.down.pred[,1], plot=T, print.auc=T, add=T, col=&quot;blue&quot;, print.auc.adj=c(0,-1)) ## Error in roc.default(data.test$Class, model.dt.down.pred[, 1], plot = T, : No valid data provided. text(1.2, 0.8, &quot;Blue: Down sampling\\nRed: Up sampling&quot;) ## Error in text.default(1.2, 0.8, &quot;Blue: Down sampling\\nRed: Up sampling&quot;): plot.new has not been called yet 3.24.2 다중범주 ROC if(!require(rpart)) { install.packages(&quot;rpart&quot;); library(rpart); } data &lt;- penguins data &lt;- na.omit(data) set.seed(1234) train.index &lt;- sample(nrow(data), 0.7*nrow(data), replace=F) train &lt;- data[train.index,] test &lt;- data[-train.index,] model.dt &lt;- rpart(species ~ ., train) model.dt.pred &lt;- predict(model.dt, test, type=&quot;class&quot;) if(!require(pROC)) { install.packages(&quot;pROC&quot;); library(pROC); } mroc &lt;- multiclass.roc(test$species, as.numeric(model.dt.pred)) pROC::plot.roc(mroc$rocs[[1]], plot=T, col=1, print.auc=T) for(i in 2:3) { pROC::plot.roc(mroc$rocs[[i]], plot=T, col=i, print.auc=T, add=T, print.auc.adj = c(0,i)) } "],["til20220325.html", "3.25 TIL20220325", " 3.25 TIL20220325 아… 이날은 잊지 말자 🤮 "],["til20220326.html", "3.26 TIL20220326", " 3.26 TIL20220326 [Github] 깃허브 커밋 날짜를 조작하고 싶지 않으신가요?13 이게 되는구나… https://cindycho.tistory.com/71↩︎ "],["til20220327.html", "3.27 TIL20220327", " 3.27 TIL20220327 if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } x &lt;- seq(-4, 4, length=100) y3 &lt;- dt(x, df=3) y10 &lt;- dt(x, df=10) y50 &lt;- dt(x, df=50) ggplot(data.frame(x,y3), aes(x,y3)) + geom_line(col=1) + geom_line(aes(x, y10), col=2) + geom_line(aes(x, y50), col=3) + geom_text(aes(-3, 0.3, label=&quot;df=50&quot;), color=3) + geom_text(aes(-3, 0.25, label=&quot;df=10&quot;), col=2) + geom_text(aes(-3, 0.2, label=&quot;df=3&quot;), col=1) + theme_bw() str(cars) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ speed: num 4 4 7 7 8 9 10 10 10 11 ... ## $ dist : num 2 10 4 22 16 10 18 26 34 17 ... plot(cars$speed, cars$dist) x &lt;- seq(-4, 4, length=100) y1 &lt;- dnorm(x, sd=1) y2 &lt;- dnorm(x, sd=2) ggplot(data.frame(x,y1), aes(x,y1)) + geom_line() + geom_line(aes(y=y2), col=2) \\[CV, coefficient of variance = \\frac{s}{\\bar x}\\] if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } pa &lt;- subset(penguins[penguins$species==&quot;Adelie&quot;, ], select = c(&quot;species&quot;, &quot;body_mass_g&quot;)) pg &lt;- subset(penguins[penguins$species==&quot;Gentoo&quot;, ], select = c(&quot;species&quot;, &quot;body_mass_g&quot;)) pa.cv &lt;- sd(pa$body_mass_g, na.rm=T)/mean(pa$body_mass_g, na.rm = T) pg.cv &lt;- sd(pg$body_mass_g, na.rm=T)/mean(pg$body_mass_g, na.rm = T) cv &lt;- rbind(Adelie = pa.cv, Gentoo = pg.cv) colnames(cv) &lt;- c(&quot;CV&quot;); cv ## CV ## Adelie 0.12391461 ## Gentoo 0.09931336 Adelie가 Gentoo에 비해 변동성이 큰 것을 알 수 있다. boxplot(pa$body_mass_g, pg$body_mass_g) "],["til20220328.html", "3.28 TIL20220328", " 3.28 TIL20220328 베르누이 시행 p의 확률로 원하는 결과가 나타났을 때 성공으로 (1-p)의 확률로 그렇지 않은 결과가 나타났을 때 실패로 하는 두 가지 결과가 나타나는 확률실험을 베르누이 시행이라 한다. 이항 분포 성공 확률이 p로 동일한 베르누이 시행을 n번 반복해서 실험하는 경우, 실험이 n번 반복되더라도 성공 확률 p는 변하지 않고 동일한것으로 이는 앞의 실험이 뒤에 할 실험에 영향을 끼치지 않고 각 실험이 서로 독립적으로 실행될 때 이와 같은 실험에서 성공 횟수가 따르는 분포함수를 이항분포라 한다. 이항 계수 \\(p^x(1-p)^{n-x}\\) n &lt;- 6 p &lt;- 1/3 x &lt;- 0:n dbinom(2, size = n, prob = p) ## [1] 0.3292181 dbinom(4, size = n, prob = p) ## [1] 0.08230453 px &lt;- dbinom(x, size = n, prob = p) plot(x, px, type=&quot;s&quot;,xlab=&quot;성공횟수&quot;, ylab=&quot;확률&quot;, main=&quot;B(6, 1/3)&quot;) # B(6, 1/3)의 기댓값과 분산 n &lt;- 6 p &lt;- 1/3 x &lt;- 0:n px &lt;- dbinom(x, size = n, prob = p) ex &lt;- sum(x * px) ex2 &lt;- sum(x^2 * px) # V(X) = E(X^2) - {E(X)}^2 varx &lt;- ex2 - ex^2; varx ## [1] 1.333333 options(digits = 3) mu = 170 sigma &lt;- 6 ll &lt;- mu - 3*sigma ul &lt;- mu + 3*sigma x &lt;- seq(ll, ul, by=0.01) nd &lt;- dnorm(x, mean=mu, sd=sigma) plot(x, nd, type=&quot;l&quot;, xlab=&quot;x&quot;, ylab=&quot;P(X=x)&quot;, lwd=2, col=&quot;red&quot;); abline(v=mu) options(digis=5) set.seed(5) smp &lt;- rnorm(400, mean=mu, sd=sigma) c(mean(smp), sd(smp)) ## [1] 170.02 6.01 hist(smp, prob=T, main=&quot;N(170, 6^2)으로부터 추출한 표본의 분포(n=400)&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, border=&quot;black&quot;); lines(x, nd, lty=2) x &lt;- seq(ll, ul, length = 400) nd &lt;- dnorm(x, mean=mean(smp), sd=sd(smp)) plot(x, nd, type=&quot;l&quot;, xlab=&quot;x&quot;, ylab=&quot;P(X=x)&quot;, lwd=2, col=&quot;red&quot;);abline(v=mean(smp)) "],["til20220329.html", "3.29 TIL20220329", " 3.29 TIL20220329 v &lt;- c(1,4,5) for (i in v) { print(i) } ## [1] 1 ## [1] 4 ## [1] 5 모수 모집단의 특성을 나타내는 값, parameter 통계량 표본으로부터 관찰되는 표본의 특성, statistic 표본분포 표본 크기가 n으로 정해졌을 때 추출될 수 있는 모든 표본으로부터 구한 통계량들로 구성된 확률분포 # 모집단 100개 중 표본 크기 10이 되도록 하는 표본추출의 경우의 수 choose(100, 10) ## [1] 1.73e+13 # 카드 4장 중 2장 선택 choose(4, 2) ## [1] 6 표본평균 \\(\\bar{x}\\)의 분포 m10 &lt;- rep(NA, 1000) m40 &lt;- rep(NA, 1000) set.seed(9) for(i in 1:1000) { m10[i] &lt;- mean(rnorm(10)) m40[i] &lt;- mean(rnorm(40)) } options(digits = 4) c(mean(m10), sd(m10)) ## [1] -0.01214 0.30311 c(mean(m40), sd(m40)) ## [1] 0.004212 0.160942 par(mfrow = c(1,2)) hist(m10, xlim = c(-1.5, 1.5), main=&quot;&quot;, xlab=&quot;x&quot;, ylab=&quot;y&quot;, col=&quot;cyan&quot;, border = &quot;blue&quot;) hist(m40, xlim = c(-1.5, 1.5), main=&quot;&quot;, xlab=&quot;x&quot;, ylab=&quot;y&quot;, col=&quot;cyan&quot;, border = &quot;blue&quot;) par(mfrow = c(1,1)) 표본 크기가 클수록 기댓값 주변에 많이 몰려 있으며 자료가 분포하는 전체 폭이 줄어듦을 볼 수 있다. "],["til20220330.html", "3.30 TIL20220330", " 3.30 TIL20220330 3.30.1 정규분포에서 추출한 표본평균의 분포 set.seed(9) n &lt;- 1000 r.1.mean &lt;- rep(NA, n) r.2.mean &lt;- rep(NA, n) for(i in 1:n) { r.1.mean[i] &lt;- mean(rnorm(4, mean=3, sd=1)) r.2.mean[i] &lt;- mean(rnorm(4, mean=170, sd=6)) } options(digits = 4) c(mean(r.1.mean), sd(r.1.mean)) ## [1] 3.0214 0.5096 c(mean(r.2.mean), sd(r.2.mean)) ## [1] 170.032 2.835 {hist(r.1.mean, prob=T, xlab=&quot;표본평균&quot;, ylab=&quot;밀도&quot;, main=&quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x1 &lt;- seq(min(r.1.mean), max(r.1.mean), length=1000) y1 &lt;- dnorm(x=x1, mean=3, sd=(1/sqrt(4))) lines(x1, y1, lty=2, lwd=2, col=&quot;blue&quot;)} {hist(r.2.mean, prob=T, xlab=&quot;표본평균&quot;, ylab=&quot;밀도&quot;, main=&quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x2 &lt;- seq(min(r.2.mean), max(r.2.mean), length=1000) y2 &lt;- dnorm(x=x2, mean=170, sd=(6/sqrt(4))) lines(x2, y2, lty=2, lwd=2, col=&quot;blue&quot;)} 모집단이 정규분포를 다를 경우 표본평균의 분포가 정규분포와 유사함을 확인할 수 있다. \\[ \\bar{X} \\sim N(\\mu, (\\frac{\\sigma}{\\sqrt{n}})^2) \\] 3.30.2 모집단이 정규분포 이외의 분포를 따를 경우 시행횟수가 10회, 성공확률이 0.1인 이항분포 B(10, 0.1)의 평균 1, 표준편차 0.9487일 때, 표본 크기 2,4,32로 늘릴 경우 B(10, 01), E(X) = np, VAR(X) = np(1-p)이므로 t &lt;- 10; p &lt;- 0.1; x &lt;- 0:10; px &lt;- dbinom(0:10, 10, prob=0.1) names(px) &lt;- 0:10 barplot(px, col=&quot;orange&quot;, border=&quot;red&quot;) set.seed(9) t &lt;- 10 p &lt;- 0.1 x &lt;- 0:10 n &lt;- 1000 b.2.mean &lt;- rep(NA, n) b.4.mean &lt;- rep(NA, n) b.32.mean &lt;- rep(NA, n) for(i in 1:n) { b.2.mean[i] &lt;- mean(rbinom(2, size=t, prob=p)) b.4.mean[i] &lt;- mean(rbinom(4, size=t, prob=p)) b.32.mean[i] &lt;- mean(rbinom(32, size=t, prob=p)) } options(digits = 4) c(mean(b.2.mean), sd(b.2.mean)) ## [1] 1.0090 0.6763 c(mean(b.4.mean), sd(b.4.mean)) ## [1] 1.006 0.481 c(mean(b.32.mean), sd(b.32.mean)) ## [1] 0.9989 0.1624 {hist(b.2.mean, prob=T, xlim=c(0,4), main=&quot;표본크기: 2&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x1 &lt;- seq(min(b.2.mean), max(b.2.mean), length=1000) y1 &lt;- dnorm(x=x1, mean = 1, sd = sqrt(0.9)/sqrt(2)) lines(x1, y1, lty=2, lwd=2, col=&quot;blue&quot;)} {hist(b.4.mean, prob=T, xlim=c(0,4), main=&quot;표본크기: 8&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x2 &lt;- seq(min(b.4.mean), max(b.4.mean), length=1000) y2 &lt;- dnorm(x=x2, mean = 1, sd = sqrt(0.9)/sqrt(8)) lines(x2, y2, lty=2, lwd=2, col=&quot;blue&quot;)} {hist(b.32.mean, prob=T, xlim=c(0,4), main=&quot;표본크기: 32&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x3 &lt;- seq(min(b.32.mean), max(b.32.mean), length=1000) y3 &lt;- dnorm(x=x3, mean = 1, sd = sqrt(0.9)/sqrt(32)) lines(x3, y3, lty=2, lwd=2, col=&quot;blue&quot;)} "],["til20220331.html", "3.31 TIL20220331", " 3.31 TIL20220331 표본평균 \\(\\bar{x}\\)의 분포가 표본 크기 n이 커짐에 따라 모집단의 모양(분포)에 상관없이 모집단에 평균과 분산이 존재한다면 근사적으로 정규분포가 된다. 즉, 모집단의 분포와 상관없이 모집단의 평균 \\(\\mu\\)와 표준편자 \\(\\sigma\\)가 존재할 때 표본 크기 n이 충분히 크다면 표본평균의 분포는 근사적으로 정규분포를 따른다. 이를 중심극한정리(Central Limit Theorem)라 한다. 모수() 구분 추정량 \\(\\mu\\) 평균 \\(\\bar X\\) \\(\\sigma ^2\\) 분산 \\(s^2\\) \\(P\\) 비율 \\(\\hat p\\) 불편성 추정량이 갖춰야 할 가장 기본적인 성질로 한쪽으로 치우치지 않음을 의미한다 불편출정량 추정량의 기댓값이 모수와 같음을 의미하고 불편성을 맍고하는 추정량을 의미한다 \\[ E(\\hat \\theta) = \\theta \\] "],["년-04월.html", "4 2022년 04월 ", " 4 2022년 04월 "],["til20220401.html", "4.1 TIL20220401", " 4.1 TIL20220401 x &lt;- seq(-3, 3, by=0.01) y &lt;- dnorm(x) y.1 &lt;- dnorm(x, sd=sqrt(1/3)) y.2 &lt;- dnorm(x, sd=sqrt(7/18)) pnorm(0.1, sd=sqrt(1/3)) - pnorm(-0.1, sd=sqrt(1/3)) ## [1] 0.1375 pnorm(0.1, sd=sqrt(7/18)) - pnorm(-0.1, sd=sqrt(7/18)) ## [1] 0.1274 { plot(x, y , type=&quot;l&quot;, ylim = c(0, 0.8), axes = F, ylab = &quot;&quot;, lwd = 3, col = &quot;yellow&quot;) lines(x, y.1, col = &quot;red&quot;, lwd = 3) lines(x, y.2, col = &quot;green&quot;, lty=2, lwd = 3) axis(1) } "],["til20220402.html", "4.2 TIL20220402", " 4.2 TIL20220402 options(digits = 3) set.seed(1) mean.seq &lt;- function(x) { n &lt;- length(x) sum &lt;- 0 n2 &lt;- 0 for(i in 1:n) { newx &lt;- i * x[i] sum &lt;- sum + newx n2 &lt;- n2 + i } return (sum/n2) } y1 &lt;- rep(NA, 1000) y2 &lt;- rep(NA, 1000) for(i in 1:1000){ smp &lt;- rnorm(3) y1[i] &lt;- mean(smp) y2[i] &lt;- mean.seq(smp) } n1 &lt;- length(y1[(y1&gt;-0.1) &amp; (y1&lt;0.1)]) n2 &lt;- length(y2[(y2&gt;-0.1) &amp; (y2&lt;0.1)]) data.frame(mean=mean(y1), var=var(y1), n=n1) ## mean var n ## 1 -0.0042 0.36 134 data.frame(mean=mean(y2), var=var(y2), n=n2) ## mean var n ## 1 -0.0113 0.427 120 par(mfrow=c(1,2)) hist(y1, probability = T, xlim=c(-2,2), ylim=c(0,0.65), main = &quot;(x1 + x2 + x3)/3&quot;, xlab = &quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) hist(y2, probability = T, xlim=c(-2,2), ylim=c(0,0.65), main = &quot;(1*x1+ 2*x2 + 6*x3)/6&quot;, xlab = &quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) "],["til20220403.html", "4.3 TIL20220403", " 4.3 TIL20220403 4.3.1 데이터 결합 방법 # finance.yahoo.com: Samsung Electronics, KRW library(quantmod) sec &lt;- getSymbols(Symbols = &quot;005930.KS&quot;, from = &quot;2021-10-01&quot;, to = &quot;2021-12-31&quot;, auto.assign = FALSE) sec &lt;- as.data.frame(sec) str(sec) ## &#39;data.frame&#39;: 63 obs. of 6 variables: ## $ 005930.KS.Open : num 73900 73000 72600 71600 72300 70700 68700 69000 70200 70200 ... ## $ 005930.KS.High : num 74000 73000 72800 72100 72400 70900 69600 69800 71000 70300 ... ## $ 005930.KS.Low : num 72900 71400 71200 71300 71500 68700 68300 68800 70000 69200 ... ## $ 005930.KS.Close : num 73200 72200 71300 71600 71500 69000 68800 69400 70100 70200 ... ## $ 005930.KS.Volume : num 15803395 24013921 18956962 13683532 14043287 ... ## $ 005930.KS.Adjusted: num 72056 71071 70185 70481 70382 ... head(sec[c(&quot;005930.KS.Close&quot;, &quot;005930.KS.Volume&quot;)]) ## 005930.KS.Close 005930.KS.Volume ## 2021-10-01 73200 15803395 ## 2021-10-05 72200 24013921 ## 2021-10-06 71300 18956962 ## 2021-10-07 71600 13683532 ## 2021-10-08 71500 14043287 ## 2021-10-12 69000 31001484 sec &lt;- cbind(date=rownames(sec), symbod = &quot;005930.KS&quot;, sec[c(&quot;005930.KS.Close&quot;, &quot;005930.KS.Volume&quot;)]) rownames(sec) &lt;- NULL colnames(sec)[c(3,4)] &lt;- c(&quot;close&quot;, &quot;volume&quot;) head(sec) ## date symbod close volume ## 1 2021-10-01 005930.KS 73200 15803395 ## 2 2021-10-05 005930.KS 72200 24013921 ## 3 2021-10-06 005930.KS 71300 18956962 ## 4 2021-10-07 005930.KS 71600 13683532 ## 5 2021-10-08 005930.KS 71500 14043287 ## 6 2021-10-12 005930.KS 69000 31001484 hmc &lt;- getSymbols(Symbols = &quot;005387.KS&quot;, from = &quot;2021-10-01&quot;, to = &quot;2021-12-31&quot;, auto.assign = FALSE) hmc &lt;- as.data.frame(hmc) str(hmc) ## &#39;data.frame&#39;: 63 obs. of 6 variables: ## $ 005387.KS.Open : num 95100 92400 91700 93100 96400 96100 95900 98800 99700 100000 ... ## $ 005387.KS.High : num 95500 92400 93300 95900 98000 ... ## $ 005387.KS.Low : num 92600 90100 91000 93100 96100 95200 95900 98500 99200 98600 ... ## $ 005387.KS.Close : num 92800 91500 93100 95800 96100 95700 98500 99100 99700 100000 ... ## $ 005387.KS.Volume : num 108008 142854 85533 65835 80350 ... ## $ 005387.KS.Adjusted: num 88179 86944 88464 91029 91315 ... head(hmc[c(&quot;005387.KS.Close&quot;, &quot;005387.KS.Volume&quot;)]) ## 005387.KS.Close 005387.KS.Volume ## 2021-10-01 92800 108008 ## 2021-10-05 91500 142854 ## 2021-10-06 93100 85533 ## 2021-10-07 95800 65835 ## 2021-10-08 96100 80350 ## 2021-10-12 95700 52477 hmc &lt;- cbind(date=rownames(hmc), symbod = &quot;005387.KS&quot;, hmc[c(&quot;005387.KS.Close&quot;, &quot;005387.KS.Volume&quot;)]) rownames(hmc) &lt;- NULL colnames(hmc)[c(3,4)] &lt;- c(&quot;close&quot;, &quot;volume&quot;) head(hmc) ## date symbod close volume ## 1 2021-10-01 005387.KS 92800 108008 ## 2 2021-10-05 005387.KS 91500 142854 ## 3 2021-10-06 005387.KS 93100 85533 ## 4 2021-10-07 005387.KS 95800 65835 ## 5 2021-10-08 005387.KS 96100 80350 ## 6 2021-10-12 005387.KS 95700 52477 stock &lt;- rbind(sec, hmc); head(stock); ## date symbod close volume ## 1 2021-10-01 005930.KS 73200 15803395 ## 2 2021-10-05 005930.KS 72200 24013921 ## 3 2021-10-06 005930.KS 71300 18956962 ## 4 2021-10-07 005930.KS 71600 13683532 ## 5 2021-10-08 005930.KS 71500 14043287 ## 6 2021-10-12 005930.KS 69000 31001484 fx &lt;- getSymbols(Symbols = &quot;KRW=x&quot;, from = &quot;2021-10-01&quot;, to = &quot;2021-12-31&quot;, auto.assign = FALSE) fx &lt;- as.data.frame(fx) str(fx) ## &#39;data.frame&#39;: 66 obs. of 6 variables: ## $ KRW=X.Open : num 1184 1180 1185 1186 1190 ... ## $ KRW=X.High : num 1189 1185 1189 1197 1192 ... ## $ KRW=X.Low : num 1179 1177 1183 1186 1187 ... ## $ KRW=X.Close : num 1184 1180 1184 1187 1191 ... ## $ KRW=X.Volume : num 0 0 0 0 0 0 0 0 0 0 ... ## $ KRW=X.Adjusted: num 1184 1180 1184 1187 1191 ... head(fx[c(&quot;KRW=X.Close&quot;)]) ## KRW=X.Close ## 2021-10-01 1184 ## 2021-10-04 1180 ## 2021-10-05 1184 ## 2021-10-06 1187 ## 2021-10-07 1191 ## 2021-10-08 1191 fx &lt;- cbind(date=rownames(fx), fx[c(&quot;KRW=X.Close&quot;)]) rownames(fx) &lt;- NULL colnames(fx)[c(2)] &lt;- c(&quot;close&quot;) head(fx) ## date close ## 1 2021-10-01 1184 ## 2 2021-10-04 1180 ## 3 2021-10-05 1184 ## 4 2021-10-06 1187 ## 5 2021-10-07 1191 ## 6 2021-10-08 1191 intersect(names(sec), names(fx)) ## [1] &quot;date&quot; &quot;close&quot; report &lt;- merge(sec, fx, by=&quot;date&quot;); head(report); ## date symbod close.x volume close.y ## 1 2021-10-01 005930.KS 73200 15803395 1184 ## 2 2021-10-05 005930.KS 72200 24013921 1184 ## 3 2021-10-06 005930.KS 71300 18956962 1187 ## 4 2021-10-07 005930.KS 71600 13683532 1191 ## 5 2021-10-08 005930.KS 71500 14043287 1191 ## 6 2021-10-12 005930.KS 69000 31001484 1196 match() 함수를 이용한 데이터 결합 방법 v &lt;-c(10:1) match(7, v) ## [1] 4 match(c(11,5,3,1,0), v) ## [1] NA 6 8 10 NA head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 car &lt;- mtcars car$name &lt;- rownames(car) rownames(car) &lt;- NULL head(car) ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 1 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 ## 2 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Mazda RX4 Wag ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Datsun 710 ## 4 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet 4 Drive ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Hornet Sportabout ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 Valiant highhp.car &lt;- car[car$hp &gt; 145, ]; highhp.car; ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Hornet Sportabout ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 Duster 360 ## 12 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 Merc 450SE ## 13 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 Merc 450SL ## 14 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 Merc 450SLC ## 15 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 Cadillac Fleetwood ## 16 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 Lincoln Continental ## 17 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 Chrysler Imperial ## 22 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 Dodge Challenger ## 23 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 AMC Javelin ## 24 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 Camaro Z28 ## 25 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 Pontiac Firebird ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino ## 31 15.0 8 301 335 3.54 3.57 14.6 0 1 5 8 Maserati Bora lightwt.car &lt;- car[car$wt &lt; 3.2, ]; lightwt.car; ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 1 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 ## 2 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 Mazda RX4 Wag ## 3 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 Datsun 710 ## 8 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 Merc 240D ## 9 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 Merc 230 ## 18 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 Fiat 128 ## 19 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 Honda Civic ## 20 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 Toyota Corolla ## 21 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 Toyota Corona ## 26 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 Fiat X1-9 ## 27 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 Porsche 914-2 ## 28 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 Lotus Europa ## 29 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino ## 32 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 Volvo 142E index &lt;- match(highhp.car$name, lighthp.car$name); index; ## Error in match(highhp.car$name, lighthp.car$name): object &#39;lighthp.car&#39; not found ## function (x, ...) ## { ## UseMethod(&quot;index&quot;) ## } ## &lt;bytecode: 0x7f8a05486860&gt; ## &lt;environment: namespace:zoo&gt; lighthp.car[na.omit(index), ] ## Error in eval(expr, envir, enclos): object &#39;lighthp.car&#39; not found %in%를 이용한 데이터 결합 7 %in% v ## [1] TRUE c(11,5,3,1,0) %in% v ## [1] FALSE TRUE TRUE TRUE FALSE index &lt;- highhp.car$name %in% lightwt.car$name; index; ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] TRUE TRUE FALSE highhp.car[index,] ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino "],["til20220404.html", "4.4 TIL20220404", " 4.4 TIL20220404 4.4.1 일치성 일치성 표본의 크기와 관련이 있는 추정량의 성질로 이를 만족하는 추정량을 일치추정량이라고 한다. \\[ \\lim_{n \\to \\infty}P(|\\hat\\theta-\\theta|&gt;\\epsilon) = 0 \\] if(!require(prob)) { install.packages(&quot;prob&quot;); library(prob); } ## Error in library(prob): there is no package called &#39;prob&#39; n &lt;- 3 smps.all &lt;- rolldie(n) ## Error in rolldie(n): could not find function &quot;rolldie&quot; str(smps.all) ## Error in str(smps.all): object &#39;smps.all&#39; not found head(smps.all) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;smps.all&#39; not found is.even &lt;- function(x) return(!x%%2) var.p &lt;- function(x) { return(sum((x-mean(x))^2/length(x))) } p.even &lt;- function(x, s.size = 3) { return(sum(is.even(x))/s.size) } phat &lt;- apply(smps.all, 1, p.even) ## Error in apply(smps.all, 1, p.even): object &#39;smps.all&#39; not found mean(phat) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;phat&#39; not found (p.p &lt;- 0.5) ## [1] 0.5 var.p(phat) ## Error in var.p(phat): object &#39;phat&#39; not found (p.p*(1-p.p)/3) ## [1] 0.0833 sqrt(var.p(phat)) ## Error in var.p(phat): object &#39;phat&#39; not found "],["til20220405.html", "4.5 TIL20220405", " 4.5 TIL20220405 4.5.1 dplyr data &lt;- data.frame( x1 = 1:6, x2 = c(1,2,2,3,1,2), x3 = c(&quot;F&quot;, &quot;B&quot;, &quot;C&quot;, &quot;E&quot;, &quot;A&quot;, &quot;D&quot;) ); data; ## x1 x2 x3 ## 1 1 1 F ## 2 2 2 B ## 3 3 2 C ## 4 4 3 E ## 5 5 1 A ## 6 6 2 D if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } arrange(data, x3) ## x1 x2 x3 ## 1 5 1 A ## 2 2 2 B ## 3 3 2 C ## 4 6 2 D ## 5 4 3 E ## 6 1 1 F filter(data, x2 == 2) ## x1 x2 x3 ## 1 2 2 B ## 2 3 2 C ## 3 6 2 D mutate(data, x4 = x1 + x2) ## x1 x2 x3 x4 ## 1 1 1 F 2 ## 2 2 2 B 4 ## 3 3 2 C 5 ## 4 4 3 E 7 ## 5 5 1 A 6 ## 6 6 2 D 8 pull(data, x2); class(pull(data, x2)) ## [1] 1 2 2 3 1 2 ## [1] &quot;numeric&quot; rename(data, new_name = x3) ## x1 x2 new_name ## 1 1 1 F ## 2 2 2 B ## 3 3 2 C ## 4 4 3 E ## 5 5 1 A ## 6 6 2 D set.seed(765) sample_n(data, 3) ## x1 x2 x3 ## 1 4 3 E ## 2 6 2 D ## 3 3 2 C select(data, c(x2, x3)) ## x2 x3 ## 1 1 F ## 2 2 B ## 3 2 C ## 4 3 E ## 5 1 A ## 6 2 D 4.5.1.1 Join Data with dplyr 14 data1 &lt;- data.frame(ID = 1:2, x1 = c(&quot;a1&quot;, &quot;a2&quot;), stringsAsFactors = F); data1; ## ID x1 ## 1 1 a1 ## 2 2 a2 data2 &lt;- data.frame(ID = 2:3, x1 = c(&quot;b1&quot;, &quot;b2&quot;), stringsAsFactors = F); data2; ## ID x1 ## 1 2 b1 ## 2 3 b2 inner_join(data1, data2, by = &quot;ID&quot;) ## ID x1.x x1.y ## 1 2 a2 b1 left_join(data1, data2, by = &quot;ID&quot;) ## ID x1.x x1.y ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 b1 right_join(data1, data2, by = &quot;ID&quot;) ## ID x1.x x1.y ## 1 2 a2 b1 ## 2 3 &lt;NA&gt; b2 full_join(data1, data2, by = &quot;ID&quot;) ## ID x1.x x1.y ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 b1 ## 3 3 &lt;NA&gt; b2 semi_join(data1, data2, by = &quot;ID&quot;) ## ID x1 ## 1 2 a2 anti_join(data1, data2, by = &quot;ID&quot;) ## ID x1 ## 1 1 a1 data1 &lt;- data.frame(x1 = 1:5, x2 = letters[1:5]); data1; ## x1 x2 ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e data2 &lt;- data.frame(x1 = 0, x3 = 5:9); data2; ## x1 x3 ## 1 0 5 ## 2 0 6 ## 3 0 7 ## 4 0 8 ## 5 0 9 data3 &lt;- data.frame(x3 = 5:9, x4 = letters[5:9]); data3; ## x3 x4 ## 1 5 e ## 2 6 f ## 3 7 g ## 4 8 h ## 5 9 i bind_rows(data1, data2) ## x1 x2 x3 ## 1 1 a NA ## 2 2 b NA ## 3 3 c NA ## 4 4 d NA ## 5 5 e NA ## 6 0 &lt;NA&gt; 5 ## 7 0 &lt;NA&gt; 6 ## 8 0 &lt;NA&gt; 7 ## 9 0 &lt;NA&gt; 8 ## 10 0 &lt;NA&gt; 9 bind_cols(data1, data3) ## x1 x2 x3 x4 ## 1 1 a 5 e ## 2 2 b 6 f ## 3 3 c 7 g ## 4 4 d 8 h ## 5 5 e 9 i https://www.youtube.com/watch?v=Yg-pNqzDuN4&amp;list=PLu6UwBFCnlEddsED6LFhgrg1vH-X6e4Ah&amp;index=2↩︎ "],["til20220406.html", "4.6 TIL20220406", " 4.6 TIL20220406 4.6.1 R Shiny install.packages(&quot;shiny&quot;) library(shiny) https://shiny.rstudio.com/ # # This is a Shiny web application. You can run the application by clicking # the &#39;Run App&#39; button above. # # Find out more about building applications with Shiny here: # # http://shiny.rstudio.com/ # library(shiny) # Define UI for application that draws a histogram ui &lt;- fluidPage( # Application title titlePanel(&quot;Old Faithful Geyser Data&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( sliderInput(&quot;bins&quot;, &quot;Number of bins:&quot;, min = 1, max = 50, value = 30) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) ) ) # Define server logic required to draw a histogram server &lt;- function(input, output) { output$distPlot &lt;- renderPlot({ # generate bins based on input$bins from ui.R x &lt;- faithful[, 2] bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) # draw the histogram with the specified number of bins hist(x, breaks = bins, col = &#39;darkgray&#39;, border = &#39;white&#39;) }) } # Run the application shinyApp(ui = ui, server = server) "],["til20220407.html", "4.7 TIL20220407", " 4.7 TIL20220407 4.7.1 다중 그래프 in ggplot Use for loop to plot multiple lines in single plot with ggplot2 if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } y &lt;- matrix(rnorm(100), 10, 10) m &lt;- qplot(NULL) for(i in 1:10) { m &lt;- m + geom_line(aes(x = 1:10, y = y[,i])) } plot(m) plot(1,1,type=&#39;n&#39;, ylim=range(y), xlim=c(1,10)) for(i in 1:10) { lines(1:10, y[,i]) } y &lt;- matrix(rnorm(100), 10, 10) if(!require(reshape2)) { install.packages(&quot;reshape2&quot;); library(reshape2); } y_m &lt;- melt(y) ggplot() + geom_line(data = y_m, aes(x = Var1, y = value, group = Var2)) df &lt;- NULL for(i in 1:10){ temp_df &lt;- data.frame(x=1:10, y=y[,i], col=rep(i:i, each=10)) df &lt;- rbind(df,temp_df) } ggplot(df,aes(x=x,y=y,group=col,colour=factor(col))) + geom_smooth(method = &quot;lm&quot;) How to create a plot using ggplot2 with Multiple Lines in R ? gfg_data &lt;- data.frame(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), y1 = c(1.1, 2.4, 3.5, 4.1, 5.9, 6.7, 7.1, 8.3, 9.4, 10.0), y2 = c(7, 5, 1, 7, 4, 9, 2, 3, 1, 4), y3 = c(5, 6, 4, 5, 1, 8, 7, 4, 5, 4), y4 = c(1, 4, 8, 9, 6, 1, 1, 8, 9, 1), y5 = c(1, 1, 1, 3, 3, 7, 7, 10, 10, 10)) if(!require(reshape2)) { install.packages(&quot;reshape2&quot;); library(reshape2); } data.long &lt;- melt(gfg_data, id = &quot;x&quot;) gfg_plot &lt;- ggplot(data.long, aes(x = x, y = value, color = variable)) + geom_point() + geom_smooth(level=0.3, method = &quot;loess&quot;) + theme(legend.position = c(.3, .93), legend.direction = &#39;horizontal&#39;, legend.background = element_rect(fill = NA, color = NA), legend.key = element_rect(fill = &quot;white&quot;, color = NA)); gfg_plot "],["til20220408.html", "4.8 TIL20220408", " 4.8 TIL20220408 4.8.1 R shiny if(!require(shiny)) { install.packages(&quot;shiny&quot;); library(shiny); } runExample(&quot;01_hello&quot;) ui &lt;- fluidPage() server &lt;- function(input, output){} shinyApp(ui = ui, server = server) "],["til20220409.html", "4.9 TIL20220409", " 4.9 TIL20220409 4.9.1 R shiny (conti.) library(shiny) library(shinydashboard) library(palmerpenguins) library(dplyr) library(ggplot2) ui &lt;- dashboardPage( dashboardHeader(title = &quot;Basic dashboard&quot;), dashboardSidebar( sidebarMenu( menuItem(&quot;Dashboard&quot;, tabName = &quot;dashboard&quot;, icon = icon(&quot;dashboard&quot;)), selectInput(&quot;select1&quot;, label = h3(&quot;Select box&quot;), choices = list(&quot;Adelie&quot; = &quot;Adelie&quot;, &quot;Chinstrap&quot; = &quot;Chinstrap&quot;, &quot;Gentoo&quot; = &quot;Gentoo&quot;), selected = 1), sliderInput(&quot;slider2&quot;, &quot;Top N of Body Weight&quot;, 1, 10, 5), menuItem(&quot;Widgets&quot;, tabName = &quot;widgets&quot;, icon = icon(&quot;th&quot;)) ) ), dashboardBody( tabItems( # First tab content tabItem(tabName = &quot;dashboard&quot;, fluidRow( box(width=12, plotOutput(&quot;plot1&quot;, height = 250)) ), fluidRow( box(tableOutput(&quot;table1&quot;)) ) ), # Second tab content tabItem(tabName = &quot;widgets&quot;, h2(&quot;Widgets tab content&quot;) ) ) ) ) server &lt;- function(input, output) { data &lt;- penguins print(&quot;in Server()&quot;) output$plot1 &lt;- renderPlot({ print(input$select1) data.hist &lt;- t(data[data$species == input$select1, &quot;body_mass_g&quot;]) hist(data.hist, breaks=10, main = paste(&quot;Histogram of&quot;, input$select1)) }) output$table1 &lt;- renderTable({ data %&gt;% arrange(body_mass_g) %&gt;% head(input$slider2) }) } shinyApp(ui, server) image "],["til20220410.html", "4.10 TIL20220410", " 4.10 TIL20220410 4.10.1 신뢰구간 set.seed(9) n &lt;- 10 x &lt;- 1:100 y &lt;- seq(-3, 3, by=0.01) smps &lt;- matrix(rnorm(n*length(x)), ncol=n) xbar &lt;- apply(smps, 1, mean) se &lt;- 1 / sqrt(10) alpha &lt;- 0.05 z &lt;- qnorm(1 - alpha/2) ll &lt;- xbar - z*se ul &lt;- xbar + z*se plot(y, type = &quot;n&quot;, xlab = &quot;trial&quot;, ylab = &quot;z&quot;, main = &quot;95% Confidence Interval for Population mean&quot;, xlim = c(1,100), ylim = c(-1.5, 1.5), cex.lab = 1.8) abline(h=0, col=&quot;red&quot;, lty=2) l.c &lt;- rep(NA, length(x)) l.c &lt;- ifelse(ll*ul&gt;0, &quot;red&quot;, &quot;black&quot;) arrows(1:length(x), ll, 1:length(x), ul, code=3, angle = 90, length = 0.02, col = l.c, lwd = 1.5) "],["til20220411.html", "4.11 TIL20220411", " 4.11 TIL20220411 4.11.1 r shiny reactive # Load packages ---- library(shiny) library(quantmod) # Source helpers ---- source(&quot;helpers.R&quot;) # User interface ---- ui &lt;- fluidPage( titlePanel(&quot;stockVis&quot;), sidebarLayout( sidebarPanel( helpText(&quot;Select a stock to examine. Information will be collected from Yahoo finance.&quot;), textInput(&quot;symb&quot;, &quot;Symbol&quot;, &quot;SPY&quot;), dateRangeInput(&quot;dates&quot;, &quot;Date range&quot;, start = &quot;2013-01-01&quot;, end = as.character(Sys.Date())), br(), br(), checkboxInput(&quot;log&quot;, &quot;Plot y axis on log scale&quot;, value = FALSE), checkboxInput(&quot;adjust&quot;, &quot;Adjust prices for inflation&quot;, value = FALSE) ), mainPanel(plotOutput(&quot;plot&quot;)) ) ) # Server logic server &lt;- function(input, output) { dataInput &lt;- reactive({ getSymbols(input$symb, src = &quot;yahoo&quot;, from = input$dates[1], to = input$dates[2], auto.assign = FALSE) }) output$plot &lt;- renderPlot({ chartSeries(dataInput(), theme = chartTheme(&quot;white&quot;), type = &quot;line&quot;, log.scale = input$log, TA = NULL) }) } # Run the app shinyApp(ui, server) "],["til20220412.html", "4.12 TIL20220412", " 4.12 TIL20220412 4.12.1 qcc if(!require(qcc)) { install.packages(&quot;qcc&quot;); library(qcc); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages data(pistonrings) diameter = with(pistonrings, qcc.groups(diameter, sample)) head(diameter) ## [,1] [,2] [,3] [,4] [,5] ## 1 74 74 74 74 74 ## 2 74 74 74 74 74 ## 3 74 74 74 74 74 ## 4 74 74 74 74 74 ## 5 74 74 74 74 74 ## 6 74 74 74 74 74 q1 = qcc(diameter[1:25,], type=&quot;xbar&quot;, newdata=diameter[26:40,]) "],["til20220413.html", "4.13 TIL20220413", " 4.13 TIL20220413 4.13.1 모집단의 평균검정 data &lt;- read.table(&quot;http://jse.amstat.org/datasets/babyboom.dat.txt&quot;, header = F) str(data) ## &#39;data.frame&#39;: 44 obs. of 4 variables: ## $ V1: int 5 104 118 155 257 405 407 422 431 708 ... ## $ V2: int 1 1 2 2 2 1 1 2 2 2 ... ## $ V3: int 3837 3334 3554 3838 3625 2208 1745 2846 3166 3520 ... ## $ V4: int 5 64 78 115 177 245 247 262 271 428 ... names(data) &lt;- c(&quot;time&quot;, &quot;gender&quot;, &quot;weight&quot;, &quot;minutes&quot;) tmp &lt;- subset(data, gender==1) weight &lt;- tmp[[3]] barx &lt;- mean(weight) s &lt;- sd(weight) n &lt;- length(weight) h0 &lt;- 2800 #귀무가설: 여아 신생아의 몸무게 평균은 2800(g)보다 무겁다 (t.t &lt;- (barx - h0)/(s/sqrt(n))) ## [1] 2.23 alpha &lt;- 0.05 ( c.u &lt;- qt(1-alpha, df=n-1) ) ## [1] 1.74 ( p.value &lt;- 1 - pt(t.t, df=n-1) ) ## [1] 0.0196 t.test(weight, mu = 2800, alternative = &quot;greater&quot;) ## ## One Sample t-test ## ## data: weight ## t = 2, df = 17, p-value = 0.02 ## alternative hypothesis: true mean is greater than 2800 ## 95 percent confidence interval: ## 2873 Inf ## sample estimates: ## mean of x ## 3132 "],["til20220414.html", "4.14 TIL20220414", " 4.14 TIL20220414 4.14.1 aggregate() # aggregate(formula, data, FUN) # formula = 수치변수 ~ 카테고리 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } aggregate(body_mass_g ~ species, penguins, mean) ## species body_mass_g ## 1 Adelie 3701 ## 2 Chinstrap 3733 ## 3 Gentoo 5076 aggregate(body_mass_g ~ species + sex, penguins, mean) ## species sex body_mass_g ## 1 Adelie female 3369 ## 2 Chinstrap female 3527 ## 3 Gentoo female 4680 ## 4 Adelie male 4043 ## 5 Chinstrap male 3939 ## 6 Gentoo male 5485 aggregate(cbind(body=body_mass_g, bill=bill_length_mm) ~ species + sex, penguins, mean) ## species sex body bill ## 1 Adelie female 3369 37.3 ## 2 Chinstrap female 3527 46.6 ## 3 Gentoo female 4680 45.6 ## 4 Adelie male 4043 40.4 ## 5 Chinstrap male 3939 51.1 ## 6 Gentoo male 5485 49.5 aggregate(. ~ species + sex, penguins, mean) ## species sex island bill_length_mm bill_depth_mm flipper_length_mm ## 1 Adelie female 2.03 37.3 17.6 188 ## 2 Chinstrap female 2.00 46.6 17.6 192 ## 3 Gentoo female 1.00 45.6 14.2 213 ## 4 Adelie male 2.01 40.4 19.1 192 ## 5 Chinstrap male 2.00 51.1 19.3 200 ## 6 Gentoo male 1.00 49.5 15.7 222 ## body_mass_g year ## 1 3369 2008 ## 2 3527 2008 ## 3 4680 2008 ## 4 4043 2008 ## 5 3939 2008 ## 6 5485 2008 "],["til20220415.html", "4.15 TIL20220415", " 4.15 TIL20220415 4.15.1 집단별 함수 적용 http://ds.sumeun.org/?p=844 "],["til20220416.html", "4.16 TIL20220416", " 4.16 TIL20220416 4.16.1 "],["til20220417.html", "4.17 TIL20220417", " 4.17 TIL20220417 4.17.1 dplyr if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } data &lt;- penguins data %&gt;% glimpse() ## Rows: 344 ## Columns: 8 ## $ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, … ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, … ## $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186… ## $ body_mass_g &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, … ## $ sex &lt;fct&gt; male, female, female, NA, female, male, female, male… ## $ year &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… # filter data %&gt;% filter(body_mass_g &gt; 4500 &amp; species == &quot;Adelie&quot;) ## # A tibble: 7 × 8 ## species island bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex year ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 Adelie Torgersen 39.2 19.6 195 4675 male 2007 ## 2 Adelie Dream 39.8 19.1 184 4650 male 2007 ## 3 Adelie Dream 39.6 18.8 190 4600 male 2007 ## 4 Adelie Torgersen 42.9 17.6 196 4700 male 2008 ## 5 Adelie Biscoe 41 20 203 4725 male 2009 ## 6 Adelie Biscoe 43.2 19 197 4775 male 2009 ## 7 Adelie Biscoe 45.6 20.3 191 4600 male 2009 ## # … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g # select data %&gt;% select(island, everything()) ## # A tibble: 344 × 8 ## island species bill_length_mm bill_depth_mm flipper_…¹ body_…² sex year ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 Torgersen Adelie 39.1 18.7 181 3750 male 2007 ## 2 Torgersen Adelie 39.5 17.4 186 3800 fema… 2007 ## 3 Torgersen Adelie 40.3 18 195 3250 fema… 2007 ## 4 Torgersen Adelie NA NA NA NA &lt;NA&gt; 2007 ## 5 Torgersen Adelie 36.7 19.3 193 3450 fema… 2007 ## 6 Torgersen Adelie 39.3 20.6 190 3650 male 2007 ## 7 Torgersen Adelie 38.9 17.8 181 3625 fema… 2007 ## 8 Torgersen Adelie 39.2 19.6 195 4675 male 2007 ## 9 Torgersen Adelie 34.1 18.1 193 3475 &lt;NA&gt; 2007 ## 10 Torgersen Adelie 42 20.2 190 4250 &lt;NA&gt; 2007 ## # … with 334 more rows, and abbreviated variable names ¹​flipper_length_mm, ## # ²​body_mass_g data %&gt;% select(bill_length_mm:last_col()) ## # A tibble: 344 × 6 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 39.1 18.7 181 3750 male 2007 ## 2 39.5 17.4 186 3800 female 2007 ## 3 40.3 18 195 3250 female 2007 ## 4 NA NA NA NA &lt;NA&gt; 2007 ## 5 36.7 19.3 193 3450 female 2007 ## 6 39.3 20.6 190 3650 male 2007 ## 7 38.9 17.8 181 3625 female 2007 ## 8 39.2 19.6 195 4675 male 2007 ## 9 34.1 18.1 193 3475 &lt;NA&gt; 2007 ## 10 42 20.2 190 4250 &lt;NA&gt; 2007 ## # … with 334 more rows data %&gt;% mutate(body_mass_kg = as.numeric(substr(body_mass_g,1,2))/10) %&gt;% select(body_mass_g, body_mass_kg) ## # A tibble: 344 × 2 ## body_mass_g body_mass_kg ## &lt;int&gt; &lt;dbl&gt; ## 1 3750 3.7 ## 2 3800 3.8 ## 3 3250 3.2 ## 4 NA NA ## 5 3450 3.4 ## 6 3650 3.6 ## 7 3625 3.6 ## 8 4675 4.6 ## 9 3475 3.4 ## 10 4250 4.2 ## # … with 334 more rows "],["til20220418.html", "4.18 TIL20220418", " 4.18 TIL20220418 4.18.1 단축키 * %&gt;% : ctrl + shift + m * &lt;- : alt + - * multi cursor: ctrl + alt + 화살표위아래 * 줄 이동 : alt + 화살표위아래 * 줄 복사 : alt + shift + 화살표위아래 * shortcut 설정 : Panel 이동 ctrl + alt + 화살표좌우로 변경 * 소스코드 패널추가: ctrl + F7 "],["til20220419.html", "4.19 TIL20220419", " 4.19 TIL20220419 4.19.1 pdf 파일 처리 # 관련 패키지 if(!require(pdftools)) { install.packages(&quot;pdftools&quot;); library(pdftools); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages pdf &lt;- &quot;https://cran.r-project.org/doc/manuals/r-release/R-data.pdf&quot; pdf.text &lt;- pdf_text(pdf) head(pdf.text, 2) ## [1] &quot;R Data Import/Export\\n Version 4.2.1 (2022-06-23)\\n\\n\\n\\n\\nR Core Team\\n&quot; ## [2] &quot;This manual is for R, version 4.2.1 (2022-06-23).\\nCopyright c 2000–2022 R Core Team\\n Permission is granted to make and distribute verbatim copies of this manual provided\\n the copyright notice and this permission notice are preserved on all copies.\\n Permission is granted to copy and distribute modified versions of this manual under\\n the conditions for verbatim copying, provided that the entire resulting derived work\\n is distributed under the terms of a permission notice identical to this one.\\n Permission is granted to copy and distribute translations of this manual into an-\\n other language, under the above conditions for modified versions, except that this\\n permission notice may be stated in a translation approved by the R Core Team.\\n&quot; keyword &lt;- &quot;odbc&quot; result &lt;- grep(keyword, pdf.text); result; ## [1] 18 22 23 24 31 33 # pdf.text[result] "],["til20220420.html", "4.20 TIL20220420", " 4.20 TIL20220420 4.20.1 지도 그리기 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } world &lt;- map_data(map = &quot;world&quot;) ## Error in `map_data()`: ## ! The package `maps` is required for `map_data()` unique(world$region)[125] ## Error in unique(world$region): object &#39;world&#39; not found kr &lt;- map_data(&quot;world&quot;, &quot;South Korea&quot;) ## Error in `map_data()`: ## ! The package `maps` is required for `map_data()` ggplot(kr, aes(x=long, y=lat, group = group, fill=as.factor(group))) + geom_polygon() + coord_map() ## Error in ggplot(kr, aes(x = long, y = lat, group = group, fill = as.factor(group))): object &#39;kr&#39; not found "],["til20220421.html", "4.21 TIL20220421", " 4.21 TIL20220421 4.21.1 shiny server https://www.rstudio.com/products/shiny/shiny-server/ "],["til20220422.html", "4.22 TIL20220422", " 4.22 TIL20220422 4.22.1 내용 정리 중 "],["til20220423.html", "4.23 TIL20220423", " 4.23 TIL20220423 4.23.1 shiny app 배포 "],["til20220424.html", "4.24 TIL20220424", " 4.24 TIL20220424 4.24.1 shiny app 배포. 계속 -&gt; NFT 공부 메타마스크(MetaMask) 가입 및 지갑 만들기 image image image image 오픈씨(https://opensea.io) 연동 image image image image image 네트워크 이름 : Polygon Mainnet 새 RPC URL : https://polygon-rpc.com/ 체인 ID : 137 통화 기호 (옵션) : MATIC 블록 탐색기 URL (옵션) : https://polygonscan.com "],["til20220425.html", "4.25 TIL20220425", " 4.25 TIL20220425 4.25.1 휴가 중 로지스틱 회귀분석 다중공선성 "],["til20220426.html", "4.26 TIL20220426", " 4.26 TIL20220426 4.26.1 휴가 중 "],["til20220427.html", "4.27 TIL20220427", " 4.27 TIL20220427 4.27.1 휴가 중 "],["til20220428.html", "4.28 TIL20220428", " 4.28 TIL20220428 4.28.1 "],["til20220429.html", "4.29 TIL20220429", " 4.29 TIL20220429 4.29.1 오늘까지 휴가 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } df1 &lt;- data.frame(x=1:6,y=month.name[1:6]) df2 &lt;- data.frame(x=7:12,y=month.name[7:12]) df1; df2; ## x y ## 1 1 January ## 2 2 February ## 3 3 March ## 4 4 April ## 5 5 May ## 6 6 June ## x y ## 1 7 July ## 2 8 August ## 3 9 September ## 4 10 October ## 5 11 November ## 6 12 December df3 &lt;- bind_rows(df1, df2) df3 ## x y ## 1 1 January ## 2 2 February ## 3 3 March ## 4 4 April ## 5 5 May ## 6 6 June ## 7 7 July ## 8 8 August ## 9 9 September ## 10 10 October ## 11 11 November ## 12 12 December df4 &lt;- data.frame(z=month.abb) df4 ## z ## 1 Jan ## 2 Feb ## 3 Mar ## 4 Apr ## 5 May ## 6 Jun ## 7 Jul ## 8 Aug ## 9 Sep ## 10 Oct ## 11 Nov ## 12 Dec df5 &lt;- bind_cols(df3, df4); df5 ## x y z ## 1 1 January Jan ## 2 2 February Feb ## 3 3 March Mar ## 4 4 April Apr ## 5 5 May May ## 6 6 June Jun ## 7 7 July Jul ## 8 8 August Aug ## 9 9 September Sep ## 10 10 October Oct ## 11 11 November Nov ## 12 12 December Dec df5 &lt;- bind_cols(df3, df4) %&gt;% print() ## x y z ## 1 1 January Jan ## 2 2 February Feb ## 3 3 March Mar ## 4 4 April Apr ## 5 5 May May ## 6 6 June Jun ## 7 7 July Jul ## 8 8 August Aug ## 9 9 September Sep ## 10 10 October Oct ## 11 11 November Nov ## 12 12 December Dec band_members ## # A tibble: 3 × 2 ## name band ## &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones ## 2 John Beatles ## 3 Paul Beatles band_instruments ## # A tibble: 3 × 2 ## name plays ## &lt;chr&gt; &lt;chr&gt; ## 1 John guitar ## 2 Paul bass ## 3 Keith guitar inner_join(x=band_members, y=band_instruments, by=&quot;name&quot;) ## # A tibble: 2 × 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles guitar ## 2 Paul Beatles bass left_join(x=band_members, y=band_instruments, by=&quot;name&quot;) ## # A tibble: 3 × 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass right_join(x=band_members, y=band_instruments, by=&quot;name&quot;) ## # A tibble: 3 × 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles guitar ## 2 Paul Beatles bass ## 3 Keith &lt;NA&gt; guitar full_join(x=band_members, y=band_instruments, by=&quot;name&quot;) ## # A tibble: 4 × 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass ## 4 Keith &lt;NA&gt; guitar band_instruments2 ## # A tibble: 3 × 2 ## artist plays ## &lt;chr&gt; &lt;chr&gt; ## 1 John guitar ## 2 Paul bass ## 3 Keith guitar full_join(x=band_members, y=band_instruments2, by=c(&quot;name&quot;=&quot;artist&quot;)) ## # A tibble: 4 × 3 ## name band plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; ## 2 John Beatles guitar ## 3 Paul Beatles bass ## 4 Keith &lt;NA&gt; guitar full_join(x=band_members, y=band_instruments2, by=c(&quot;name&quot;=&quot;artist&quot;), keep=T) ## # A tibble: 4 × 4 ## name band artist plays ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones &lt;NA&gt; &lt;NA&gt; ## 2 John Beatles John guitar ## 3 Paul Beatles Paul bass ## 4 &lt;NA&gt; &lt;NA&gt; Keith guitar semi_join(x=band_members, y=band_instruments, by=&quot;name&quot;) ## # A tibble: 2 × 2 ## name band ## &lt;chr&gt; &lt;chr&gt; ## 1 John Beatles ## 2 Paul Beatles anti_join(x=band_members, y=band_instruments, by=&quot;name&quot;) ## # A tibble: 1 × 2 ## name band ## &lt;chr&gt; &lt;chr&gt; ## 1 Mick Stones "],["til20220430.html", "4.30 TIL20220430", " 4.30 TIL20220430 4.30.1 일기가 꼬인 듯, 29일에 작성완료 "],["년-05월.html", "5 2022년 05월 ", " 5 2022년 05월 "],["til20220501.html", "5.1 TIL20220501", " 5.1 TIL20220501 5.1.1 데이터 결합 방법 열 결합 cbind() 행 결합 rbind() 공통 열에 의한 결합 merge(), match(), %in% Tip. 아래 error 발생 시, 패키지 재설치 Error in new.session() : Could not establish session after 5 attempts. https://stackoverflow.com/questions/72057342/error-in-new-session-could-not-establish-session-after-5-attempts # finance.yahoo.com: Samsung Electronics, KRW if(!require(quantmod)) { install.packages(&quot;quantmod&quot;); library(quantmod); } sec &lt;- getSymbols(Symbols=&quot;005930.KS&quot;, from = &quot;2022-01-01&quot;, to = &quot;2022-03-31&quot;, auto.assign = FALSE) sec &lt;- as.data.frame(sec) head(sec[c(&quot;005930.KS.Close&quot;, &quot;005930.KS.Volume&quot;)]) ## 005930.KS.Close 005930.KS.Volume ## 2022-01-04 78700 12427416 ## 2022-01-05 77400 25470640 ## 2022-01-06 76900 12931954 ## 2022-01-07 78300 15163757 ## 2022-01-10 78000 9947422 ## 2022-01-11 78900 13221123 sec &lt;- cbind(date = rownames(sec), symbol = &quot;005930.KS&quot;, sec[c(&quot;005930.KS.Close&quot;, &quot;005930.KS.Volume&quot;)]) head(sec) ## date symbol 005930.KS.Close 005930.KS.Volume ## 2022-01-04 2022-01-04 005930.KS 78700 12427416 ## 2022-01-05 2022-01-05 005930.KS 77400 25470640 ## 2022-01-06 2022-01-06 005930.KS 76900 12931954 ## 2022-01-07 2022-01-07 005930.KS 78300 15163757 ## 2022-01-10 2022-01-10 005930.KS 78000 9947422 ## 2022-01-11 2022-01-11 005930.KS 78900 13221123 rownames(sec) &lt;- NULL colnames(sec)[c(3,4)] &lt;- c(&quot;close&quot;, &quot;volume&quot;) head(sec) ## date symbol close volume ## 1 2022-01-04 005930.KS 78700 12427416 ## 2 2022-01-05 005930.KS 77400 25470640 ## 3 2022-01-06 005930.KS 76900 12931954 ## 4 2022-01-07 005930.KS 78300 15163757 ## 5 2022-01-10 005930.KS 78000 9947422 ## 6 2022-01-11 005930.KS 78900 13221123 hmc &lt;- getSymbols(Symbols=&quot;005387.KS&quot;, from = &quot;2022-01-01&quot;, to = &quot;2022-03-31&quot;, auto.assign = FALSE) hmc &lt;- as.data.frame(hmc) hmc &lt;- cbind(date = rownames(hmc), symbol = &quot;005387.KS&quot;, hmc[c(&quot;005387.KS.Close&quot;, &quot;005387.KS.Volume&quot;)]) head(hmc) ## date symbol 005387.KS.Close 005387.KS.Volume ## 2022-01-04 2022-01-04 005387.KS 100500 63345 ## 2022-01-05 2022-01-05 005387.KS 102500 81498 ## 2022-01-06 2022-01-06 005387.KS 101000 90564 ## 2022-01-07 2022-01-07 005387.KS 101000 67106 ## 2022-01-10 2022-01-10 005387.KS 100500 51838 ## 2022-01-11 2022-01-11 005387.KS 101500 65582 rownames(hmc) &lt;- NULL colnames(hmc)[c(3,4)] &lt;- c(&quot;close&quot;, &quot;volume&quot;) head(hmc) ## date symbol close volume ## 1 2022-01-04 005387.KS 100500 63345 ## 2 2022-01-05 005387.KS 102500 81498 ## 3 2022-01-06 005387.KS 101000 90564 ## 4 2022-01-07 005387.KS 101000 67106 ## 5 2022-01-10 005387.KS 100500 51838 ## 6 2022-01-11 005387.KS 101500 65582 # 환률 데이터 fx &lt;- getSymbols(Symbols=&quot;KRW=x&quot;, from = &quot;2022-01-01&quot;, to = &quot;2022-03-31&quot;, auto.assign = FALSE) fx &lt;- as.data.frame(fx) str(fx) ## &#39;data.frame&#39;: 64 obs. of 6 variables: ## $ KRW=X.Open : num 1187 1196 1197 1199 1205 ... ## $ KRW=X.High : num 1195 1200 1200 1206 1205 ... ## $ KRW=X.Low : num 1187 1192 1193 1197 1200 ... ## $ KRW=X.Close : num 1188 1195 1196 1199 1206 ... ## $ KRW=X.Volume : num 0 0 0 0 0 0 0 0 0 0 ... ## $ KRW=X.Adjusted: num 1188 1195 1196 1199 1206 ... fx &lt;- cbind(date = rownames(fx), fx[c(&quot;KRW=X.Close&quot;)]) head(fx) ## date KRW=X.Close ## 2022-01-03 2022-01-03 1188 ## 2022-01-04 2022-01-04 1195 ## 2022-01-05 2022-01-05 1196 ## 2022-01-06 2022-01-06 1199 ## 2022-01-07 2022-01-07 1206 ## 2022-01-10 2022-01-10 1197 rownames(fx) &lt;- NULL colnames(fx)[c(2)] &lt;- c(&quot;close&quot;) head(fx) ## date close ## 1 2022-01-03 1188 ## 2 2022-01-04 1195 ## 3 2022-01-05 1196 ## 4 2022-01-06 1199 ## 5 2022-01-07 1206 ## 6 2022-01-10 1197 intersect(names(sec), names(fx)) ## [1] &quot;date&quot; &quot;close&quot; report &lt;- merge(sec, fx, by=&quot;date&quot;) head(report) ## date symbol close.x volume close.y ## 1 2022-01-04 005930.KS 78700 12427416 1195 ## 2 2022-01-05 005930.KS 77400 25470640 1196 ## 3 2022-01-06 005930.KS 76900 12931954 1199 ## 4 2022-01-07 005930.KS 78300 15163757 1206 ## 5 2022-01-10 005930.KS 78000 9947422 1197 ## 6 2022-01-11 005930.KS 78900 13221123 1198 v &lt;- c(10:1) match(7, v) # match(x y), x는 찾을 값, y는 대상, 반환값은 y에서의 인덱스 ## [1] 4 match(c(11, 10, 5), v) ## [1] NA 1 6 head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 car &lt;- mtcars car$name &lt;- rownames(car) rownames(car) &lt;- NULL head(car) ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 1 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 ## 2 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Mazda RX4 Wag ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Datsun 710 ## 4 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet 4 Drive ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Hornet Sportabout ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 Valiant # 2개의 데이터 서브셋 # 1. 힘 좋은 차량 # 2. 가벼운 차량 # 힘 좋고 가벼운 차량 검색 highhp.car &lt;- car[car$hp &gt; 145, ] lightwt.car &lt;- car[car$wt &lt; 3.2, ] index &lt;- match(highhp.car$name, lightwt.car$name) lightwt.car[na.omit(index), ] ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino v &lt;- c(10:1) 7 %in% v # 논리값 반환 ## [1] TRUE c(11, 10, 5) %in% v ## [1] FALSE TRUE TRUE index &lt;- highhp.car$name %in% lightwt.car$name index ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] TRUE TRUE FALSE lightwt.car[index, ] ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino highhp.car[index, ] ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino "],["til20220502.html", "5.2 TIL20220502", " 5.2 TIL20220502 5.2.1 정규성 검정 표본크기가 30개 이상일 경우, 정규성 검정 없이 표본 평균이 정규분포를 따른다고 가정(중심극한정리)한다. 표본크기 10~30: 정규성 검정 후 결정 표본크기 10 이하: 정규분포 가정 불가 정규성 검정방법 &gt;* Anderson-Darling test(AD test) * Cramer-von Mises test(CVM test) * Kolmogorov-Smirnov test(KS test) * Lilliefors test(LF test) * Shapiro-Wilk test(SW test) x = rnorm(20, 10, 2) if(!require(nortest)) { install.packages(&quot;nortest&quot;); library(nortest); } lillie.test(x) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: x ## D = 0.1, p-value = 0.5 shapiro.test(x) ## ## Shapiro-Wilk normality test ## ## data: x ## W = 1, p-value = 0.7 qqnorm(x); qqline(x, col=&quot;blue&quot;, lty=2) "],["til20220503.html", "5.3 TIL20220503", " 5.3 TIL20220503 5.3.1 shiny app example ## app.R ## library(shinydashboard) library(shiny) ui &lt;- dashboardPage( dashboardHeader(title = &quot;Basic dashboard&quot;), # Header title dashboardSidebar( sidebarMenu( menuItem(&quot;Dashboard&quot;, tabName = &quot;dashboard&quot;, icon = icon(&quot;dashboard&quot;)), menuItem(&quot;Widgets&quot;, tabName = &quot;widgets&quot;, icon = icon(&quot;th&quot;)) ) ), dashboardBody( tabItems( # First tab content tabItem(tabName = &quot;dashboard&quot;, # Boxes need to be put in a row (or column) fluidRow( box(width = 2, solidHeader = T, title=&quot;Select Version&quot;, selectInput(&quot;process1&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value1&quot;, placeholder=T) ), box(width = 2, solidHeader = T, title=&quot;Select Version&quot;, selectInput(&quot;process2&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.35, &quot;PGM 1.2&quot; = 0.37, &quot;PGM 1.3&quot; = 0.32), selected = 1), verbatimTextOutput(&quot;value2&quot;) ), box(width = 2, solidHeader = T, title=&quot;Select Version&quot;, selectInput(&quot;process3&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.45, &quot;PGM 1.2&quot; = 0.47, &quot;PGM 1.3&quot; = 0.42), selected = 1), verbatimTextOutput(&quot;value3&quot;) ), box(width = 2, solidHeader = T, title=&quot;Select Version&quot;, selectInput(&quot;process4&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.65, &quot;PGM 1.2&quot; = 0.67, &quot;PGM 1.3&quot; = 0.62), selected = 1), verbatimTextOutput(&quot;value4&quot;) ), box(width = 2, solidHeader = T, title=&quot;Select Version&quot;, selectInput(&quot;process5&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.75, &quot;PGM 1.2&quot; = 0.77, &quot;PGM 1.3&quot; = 0.72), selected = 1), verbatimTextOutput(&quot;value5&quot;) ), box(width = 2, solidHeader = T, title=&quot;Total TT&quot;, status = &quot;primary&quot;, verbatimTextOutput(&quot;value6&quot;) ), ), ), # Second tab content tabItem(tabName = &quot;widgets&quot;, h2(&quot;Widgets tab content&quot;) ) ) ) ) server &lt;- function(input, output) { output$value1 &lt;- renderText({ paste0(&quot;T/T:&quot;, input$process1) }) output$value2 &lt;- renderText({ paste0(&quot;T/T:&quot;, input$process2) }) output$value3 &lt;- renderText({ paste0(&quot;T/T:&quot;, input$process3) }) output$value4 &lt;- renderText({ paste0(&quot;T/T:&quot;, input$process4) }) output$value5 &lt;- renderText({ paste0(&quot;T/T:&quot;, input$process5) }) output$value6 &lt;- renderText({ as.numeric(input$process1) + as.numeric(input$process2) + as.numeric(input$process3) + as.numeric(input$process4) + as.numeric(input$process5) }) } shinyApp(ui, server) ## app.R ## library(shinydashboard) library(shiny) library(shinyjs) ui &lt;- dashboardPage( dashboardHeader(title = &quot;Basic dashboard&quot;), # Header title dashboardSidebar( sidebarMenu( menuItem(&quot;Dashboard&quot;, tabName = &quot;dashboard&quot;, icon = icon(&quot;dashboard&quot;)), # Tab 항목 추가 menuItem(&quot;Widgets&quot;, tabName = &quot;widgets&quot;, icon = icon(&quot;th&quot;)) ) ), dashboardBody( useShinyjs(), tabItems( # First tab content tabItem(tabName = &quot;dashboard&quot;, # 처음 Tab 항목에 box들 포함 # Boxes need to be put in a row (or column) box(width=10, column(2, selectInput(&quot;process0&quot;, label = NULL, choices = list(&quot;PGM Ver&quot; = &quot;T/T&quot;, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value0&quot;)), column(2, selectInput(&quot;process1&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value1&quot;) ), column(2, selectInput(&quot;process2&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value2&quot;) ), column(2, selectInput(&quot;process3&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value3&quot;) ), column(2, selectInput(&quot;process4&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value4&quot;) ), column(2, selectInput(&quot;process5&quot;, label = NULL, choices = list(&quot;PGM 1.1&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value5&quot;) ), ), box(width=2, selectInput(&quot;process6&quot;, label = NULL, choices = list(&quot;Total T/T&quot; = 0.55, &quot;PGM 1.2&quot; = 0.57, &quot;PGM 1.3&quot; = 0.52), selected = 1), verbatimTextOutput(&quot;value6&quot;) ), ), # Second tab content tabItem(tabName = &quot;widgets&quot;, h2(&quot;Widgets tab content&quot;) ) ) ) ) server &lt;- function(input, output) { shinyjs::disable(&quot;process0&quot;) output$value0 &lt;- renderText({ input$process0 }) output$value1 &lt;- renderText({ input$process1 }) output$value2 &lt;- renderText({ input$process2 }) output$value3 &lt;- renderText({ input$process3 }) output$value4 &lt;- renderText({ input$process4 }) output$value5 &lt;- renderText({ input$process5 }) shinyjs::disable(&quot;process6&quot;) output$value6 &lt;- renderText({ as.numeric(input$process1) + as.numeric(input$process2) + as.numeric(input$process3) + as.numeric(input$process4) + as.numeric(input$process5) }) } shinyApp(ui, server) "],["til20220504.html", "5.4 TIL20220504", " 5.4 TIL20220504 5.4.1 독립 t검정 male_h &lt;- rnorm(40, 170, 5) female_h &lt;- rnorm(40, 165, 5) df &lt;- data.frame( x = c(rep(&quot;M&quot;, length(male_h)), rep(&quot;F&quot;, length(female_h))), y = c(male_h, female_h) ) boxplot(male_h, female_h, names = c(&quot;M&quot;, &quot;F&quot;)) # fomula를 이용한 박스플랫 생성 # factor level은 알파벳순으로 정렬되어 순서 변경이 필요한 경우 재배치 필요 df$x &lt;- factor(df$x, levels = c(&quot;M&quot;, &quot;F&quot;)) boxplot(y~x, df, ann = F) title(main = &quot;상자 그래프 (남녀간 키 분포)&quot;, xlab = &quot;성별&quot;, ylab = &quot;키&quot;) # 등분산 검정 (레빈 검정) # 귀무가설: 두 집단의 분산은 같다 if(!require(lawstat)) { install.packages(&quot;lawstat&quot;); library(lawstat); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages levene.test(df$y, df$x, location = &quot;mean&quot;) ## ## Classical Levene&#39;s test based on the absolute deviations from the mean ## ( none not applied because the location is not set to median ) ## ## data: df$y ## Test Statistic = 3, p-value = 0.1 # t 검정 t.test(male_h, female_h, var.equal = T) ## ## Two Sample t-test ## ## data: male_h and female_h ## t = 4, df = 78, p-value = 7e-04 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 1.76 6.27 ## sample estimates: ## mean of x mean of y ## 171 167 t.test(y~x, df, var.equal=T) ## ## Two Sample t-test ## ## data: y by x ## t = 4, df = 78, p-value = 7e-04 ## alternative hypothesis: true difference in means between group M and group F is not equal to 0 ## 95 percent confidence interval: ## 1.76 6.27 ## sample estimates: ## mean in group M mean in group F ## 171 167 "],["til20220505.html", "5.5 TIL20220505", " 5.5 TIL20220505 5.5.1 shiny app 배포 https://www.shinyapps.io/ 가입 rsconnect 패키지 설치 #rsconnect 패키지 설치 install.packages(&quot;rsconnect&quot;) library(rsconnect) 토큰생성 rsconnect::setAccountInfo(name=&#39;yeonkyupark&#39;, token=&#39;&lt;token&gt;&#39;, secret=&#39;&lt;secret&gt;&#39;) R Studio에서 배포 배포 완료 5.5.2 "],["til20220506.html", "5.6 TIL20220506", " 5.6 TIL20220506 5.6.1 shinyapp, loop로 메뉴 구성 library(shiny) library(shinyjs) library(shinydashboard) VecNames=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;) ui &lt;- dashboardPage( dashboardHeader(title = &quot;My Page&quot;), dashboardSidebar(sidebarMenuOutput(&quot;sideBar_menu_UI&quot;)), dashboardBody( uiOutput(&quot;body_UI&quot;), uiOutput(&quot;test_UI&quot;) ) ) server &lt;- shinyServer(function(input, output, session) { output$sideBar_menu_UI &lt;- renderMenu({ sidebarMenu(id = &quot;sideBar_Menu&quot;, menuItem(&quot;Menu 1&quot;, tabName=&quot;menu1_tab&quot;, icon = icon(&quot;calendar&quot;), lapply(1:length(VecNames), function(i) { menuSubItem(VecNames[i], tabName = VecNames[i] ,icon = icon(&quot;angle-right&quot;)) }) ), menuItem(&quot;Menu 2&quot;, tabName=&quot;menu2_tab&quot;, icon = icon(&quot;database&quot;)) ) }) output$test_UI &lt;- renderUI ({ A=tabItems( tabItem(tabName = &quot;menu1_tab&quot;, uiOutput(&quot;menu1_UI&quot;)), output$test_UI &lt;- renderUI ({ items &lt;- c( list(tabItem(tabName = &quot;menu1_tab&quot;, uiOutput(&quot;menu1_UI&quot;))), lapply(1:5, function(i){ tabItem(tabName = VecNames[i], uiOutput(paste0(&quot;Menu&quot;,i))) }) ) do.call(tabItems, items) }), # tabItem(tabName = VecNames[1], uiOutput(paste0(&quot;Menu&quot;,1))), # tabItem(tabName = VecNames[2], uiOutput(paste0(&quot;Menu&quot;,2))), # tabItem(tabName = VecNames[3], uiOutput(paste0(&quot;Menu&quot;,3))), # tabItem(tabName = VecNames[4], uiOutput(paste0(&quot;Menu&quot;,4))), # tabItem(tabName = VecNames[5], uiOutput(paste0(&quot;Menu&quot;,5))), tabItem(tabName = &quot;menu2_tab&quot;, uiOutput(&quot;menu2_UI&quot;)) ) }) output$body_UI &lt;- renderUI ({ p(&quot;Default content in body outsite any sidebar menus.&quot;) }) output$menu1_UI &lt;- renderUI ({ box(&quot;Menu 1 Content&quot;) }) output$menu2_UI &lt;- renderUI ({ box(&quot;Menu 2 Content&quot;) }) lapply(1:5, function(i){ output[[paste0(&quot;Menu&quot;,i)]]&lt;- renderUI({ box(paste0(&quot;Menu&quot;,i)) }) }) }) runApp(list(ui= ui, server = server)) "],["til20220507.html", "5.7 TIL20220507", " 5.7 TIL20220507 5.7.1 lapply를 이용한 box 반복생성 library(shiny) library(shinydashboard) ui &lt;- fluidPage( titlePanel(&quot;Dynamic Boxes&quot;), fluidRow( uiOutput(&quot;boxes&quot;) ) ) proList &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) server &lt;- function(input, output) { output$boxes &lt;- renderUI({ lapply(1:length(proList), function(a) { x = 1:100 box(title = paste0(&quot;box_&quot;, a), renderPlot(plot(x = x, y = x^a, xlab=&quot;x&quot;, ylab=&quot;y&quot;))) }) }) } shinyApp(ui = ui, server = server) "],["til20220508.html", "5.8 TIL20220508", " 5.8 TIL20220508 5.8.1 상자그림 a &lt;- 1:3 b &lt;- 1:5 c &lt;- 1:8 { bp1 &lt;- boxplot(a,b,c, ylim=c(0,10), names=c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) # 원소 수 text(1:3, bp1$stats[5,]+.5, paste(&quot;n=&quot;, bp1$n)) # 표준편차 abc_sd &lt;- round(c(sd(a), sd(b), sd(c)), 2) text(1:3, bp1$stats[5,]+1.2, paste(&quot;sd=&quot;, abc_sd)) } 5.8.2 클라우드, MSP Tools Rules Schools, 도구가 바뀌며, 툴을 잘 사용하기위한 프로세스가 바뀌고, 전사적 교육을 통해 적용 "],["til20220509.html", "5.9 TIL20220509", " 5.9 TIL20220509 5.9.1 lapply # https://www.youtube.com/watch?v=zuBuRYIk0C4 exams &lt;- list(s20 = c(78,89,91,85,96,98), s21 = c(85,86,97,99,90), s22 = c(98,96,89,90,93,85,92), s23 = c(98,96,91,88,93,99)) exams ## $s20 ## [1] 78 89 91 85 96 98 ## ## $s21 ## [1] 85 86 97 99 90 ## ## $s22 ## [1] 98 96 89 90 93 85 92 ## ## $s23 ## [1] 98 96 91 88 93 99 lapply(exams, length) ## $s20 ## [1] 6 ## ## $s21 ## [1] 5 ## ## $s22 ## [1] 7 ## ## $s23 ## [1] 6 sapply(exams, length) ## s20 s21 s22 s23 ## 6 5 7 6 sapply(iris, function(x) ifelse(is.numeric(x), mean(x), NA)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 5.84 3.06 3.76 1.20 NA "],["til20220510.html", "5.10 TIL20220510", " 5.10 TIL20220510 5.10.1 svar 모형 if(!require(vars)) { install.packages(&quot;vars&quot;); library(vars); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } if(!require(tseries)) { install.packages(&quot;tseries&quot;); library(tseries); } data(&quot;Canada&quot;) summary(Canada) ## e prod rw U ## Min. :929 Min. :401 Min. :386 Min. : 6.70 ## 1st Qu.:935 1st Qu.:405 1st Qu.:424 1st Qu.: 7.78 ## Median :946 Median :406 Median :444 Median : 9.45 ## Mean :944 Mean :408 Mean :441 Mean : 9.32 ## 3rd Qu.:950 3rd Qu.:411 3rd Qu.:461 3rd Qu.:10.61 ## Max. :962 Max. :418 Max. :470 Max. :12.77 head(Canada) ## e prod rw U ## 1980 Q1 930 405 386 7.53 ## 1980 Q2 930 405 388 7.70 ## 1980 Q3 930 404 391 7.47 ## 1980 Q4 931 404 394 7.27 ## 1981 Q1 933 405 397 7.37 ## 1981 Q2 934 404 400 7.13 Canada2 &lt;- sapply(Canada, diff) summary(Canada2) ## e prod rw U ## Min. :-1.539 Min. :-2.160 Min. :-0.87 Min. :-0.660 ## 1st Qu.: 0.123 1st Qu.:-0.365 1st Qu.: 0.27 1st Qu.:-0.240 ## Median : 0.462 Median : 0.225 Median : 0.75 Median :-0.100 ## Mean : 0.387 Mean : 0.143 Mean : 1.01 Mean :-0.008 ## 3rd Qu.: 0.785 3rd Qu.: 0.614 3rd Qu.: 1.60 3rd Qu.: 0.165 ## Max. : 1.412 Max. : 1.852 Max. : 4.98 Max. : 1.770 head(Canada2) ## e prod rw U ## [1,] 0.1935 -0.727 2.00 0.17 ## [2,] 0.5144 -0.825 2.40 -0.23 ## [3,] 1.1093 0.401 3.42 -0.20 ## [4,] 1.2343 0.831 2.80 0.10 ## [5,] 0.8889 -0.630 3.26 -0.24 ## [6,] -0.0194 -1.598 0.73 0.27 colnames(Canada2) &lt;- c(&quot;de&quot;, &quot;dprod&quot;, &quot;drw&quot;, &quot;dU&quot;) aa &lt;- list() par(mfrow = c(2,2)) for(i in 1:4) { aa[i] &lt;- plot(Canada[, i], ylab = colnames(Canada)[i]) } par(mfrow = c(1,1)) bb &lt;- list() par(mfrow = c(2,2)) for(i in 1:4) { bb[i] &lt;- plot(Canada2[, i], ylab = colnames(Canada2)[i], type = &quot;l&quot;) } par(mfrow = c(1,1)) "],["til20220511.html", "5.11 TIL20220511", " 5.11 TIL20220511 5.11.1 출장중 "],["til20220512.html", "5.12 TIL20220512", " 5.12 TIL20220512 5.12.1 출장 중 MLOps "],["til20220513.html", "5.13 TIL20220513", " 5.13 TIL20220513 5.13.1 "],["til20220514.html", "5.14 TIL20220514", " 5.14 TIL20220514 5.14.1 MLOps MLOps ML(Machine Learning) + Ops(Operation) CI/CD + Data "],["til20220515.html", "5.15 TIL20220515", " 5.15 TIL20220515 5.15.1 ICC 급내상관계수, Interclass Correlation Coefficients 5.15.2 R 변수명 깨질 때 read.csv(fileEncoding=“UTF-8-BOM”) 출처: https://118k.tistory.com/863 [개발자로 살아남기] "],["til20220516.html", "5.16 TIL20220516", " 5.16 TIL20220516 5.16.1 모델 분석 절차 https://www.youtube.com/watch?v=c2hMvVJ-Qho&amp;list=PLEUKy_nwlzwEedTUqX7VeFRpx10_TxI7F&amp;index=21 "],["til20220517.html", "5.17 TIL20220517", " 5.17 TIL20220517 5.17.1 tidy model if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(tidymodels)) { install.packages(&quot;tidymodels&quot;); library(tidymodels); } if(!require(tidytext)) { install.packages(&quot;tidytext&quot;); library(tidytext); } if(!require(skimr)) { install.packages(&quot;skimr&quot;); library(skimr); } if(!require(vip)) { install.packages(&quot;vip&quot;); library(vip); } bank_tb &lt;- read_csv(&quot;UniversalBank.csv&quot;, col_names = T, locale = locale(&quot;ko&quot;, encoding = &quot;euc-kr&quot;), na = &quot;.&quot;) %&gt;% mutate_if(is.character, as.factor) str(bank_tb) head(bank_tb) # 변수명 점검 bank_tb &lt;- bank_tb %&gt;% rename(c(&quot;Personal_Loan&quot; = &quot;Personal Loan&quot;, &quot;CD_Account&quot; = &quot;CD Account&quot;, &quot;Securities_Account&quot; = &quot;Securities Account&quot;)) str(bank_tb) # 자료형 점검 bank_tb &lt;- bank_tb %&gt;% mutate(Personal_Loan = factor(Personal_Loan, levels = c(1, 0), labels = c(&quot;Yes&quot;, &quot;No&quot;))) %&gt;% mutate(Securities_Account = factor(Securities_Account, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(CD_Account = factor(CD_Account, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(Online = factor(Online, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(CreditCard = factor(CreditCard, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(Education = factor(Education, levels = c(1:3), labels = c(&quot;Undergrad&quot;, &quot;Graduate&quot;, &quot;Professonal&quot;))) str(bank_tb) # 변수 점검 (삭제, 변환 등) bank_tb &lt;- bank_tb %&gt;% select(-c(ID, &#39;ZIP Code&#39;)) str(bank_tb) # EDA skim(bank_tb) bank_tb %&gt;% group_by(Personal_Loan) %&gt;% skim() # base accuracy bank_tb %&gt;% count(Personal_Loan) %&gt;% mutate(prop = n / sum(n)) # 데이터셋 분할 set.seed(123) bank_split &lt;- bank_tb %&gt;% initial_split(strata = Personal_Loan) bank_split train_data &lt;- training(bank_split) test_data &lt;- testing(bank_split) "],["til20220518.html", "5.18 TIL20220518", " 5.18 TIL20220518 5.18.1 PostgreSQL + R PostgreSQL 설치 https://www.postgresql.org/ DBeaver 설치 https://dbeaver.io/download/ if(!require(DBI)) { install.packages(&quot;DBI&quot;); library(DBI); } if(!require(RPostgres)) { install.packages(&quot;RPostgres&quot;); library(RPostgres); } if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } db_postgre_con &lt;- {dbConnect( RPostgres::Postgres(), host = &quot;localhost&quot;, port = 5432, user = &quot;postgres&quot;, password = &quot;1234&quot;, dbname = &quot;postgres&quot; )} my_table &lt;- db_postgre_con %&gt;% dbGetQuery(&quot;select * from public.penguins&quot;) %&gt;% as_tibble() %&gt;% glimpse() "],["til20220519.html", "5.19 TIL20220519", " 5.19 TIL20220519 5.19.1 모델 만들기 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(tidymodels)) { install.packages(&quot;tidymodels&quot;); library(tidymodels); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(tidytext)) { install.packages(&quot;tidytext&quot;); library(tidytext); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(skimr)) { install.packages(&quot;skimr&quot;); library(skimr); } if(!require(vip)) { install.packages(&quot;vip&quot;); library(vip); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages bank_tb &lt;- read_csv(&quot;UniversalBank.csv&quot;, col_names = T, locale = locale(&quot;ko&quot;, encoding = &quot;euc-kr&quot;), na = &quot;.&quot;) %&gt;% mutate_if(is.character, as.factor) ## Error: &#39;UniversalBank.csv&#39; does not exist in current working directory (&#39;/Users/runner/work/TIL2022/TIL2022&#39;). str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found head(bank_tb) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;bank_tb&#39; not found # 변수명 점검 bank_tb &lt;- bank_tb %&gt;% rename(c(&quot;Personal_Loan&quot; = &quot;Personal Loan&quot;, &quot;CD_Account&quot; = &quot;CD Account&quot;, &quot;Securities_Account&quot; = &quot;Securities Account&quot;)) ## Error in rename(., c(Personal_Loan = &quot;Personal Loan&quot;, CD_Account = &quot;CD Account&quot;, : object &#39;bank_tb&#39; not found str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found # 자료형 점검 bank_tb &lt;- bank_tb %&gt;% mutate(Personal_Loan = factor(Personal_Loan, levels = c(1, 0), labels = c(&quot;Yes&quot;, &quot;No&quot;))) %&gt;% mutate(Securities_Account = factor(Securities_Account, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(CD_Account = factor(CD_Account, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(Online = factor(Online, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(CreditCard = factor(CreditCard, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(Education = factor(Education, levels = c(1:3), labels = c(&quot;Undergrad&quot;, &quot;Graduate&quot;, &quot;Professonal&quot;))) ## Error in mutate(., Personal_Loan = factor(Personal_Loan, levels = c(1, : object &#39;bank_tb&#39; not found str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found # 변수 점검 (삭제, 변환 등) bank_tb &lt;- bank_tb %&gt;% select(-c(ID, &#39;ZIP Code&#39;)) ## Error in select(., -c(ID, &quot;ZIP Code&quot;)): object &#39;bank_tb&#39; not found str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found # EDA skim(bank_tb) ## Error in skim(bank_tb): object &#39;bank_tb&#39; not found bank_tb %&gt;% group_by(Personal_Loan) %&gt;% skim() ## Error in group_by(., Personal_Loan): object &#39;bank_tb&#39; not found # base accuracy bank_tb %&gt;% count(Personal_Loan) %&gt;% mutate(prop = n / sum(n)) ## Error in count(., Personal_Loan): object &#39;bank_tb&#39; not found # 데이터셋 분할 set.seed(123) bank_split &lt;- bank_tb %&gt;% initial_split(strata = Personal_Loan) ## Error in eval_select_impl(NULL, .vars, expr(c(!!!dots)), include = .include, : object &#39;bank_tb&#39; not found bank_split ## Error in eval(expr, envir, enclos): object &#39;bank_split&#39; not found train_data &lt;- training(bank_split) ## Error in analysis(x): object &#39;bank_split&#39; not found test_data &lt;- testing(bank_split) ## Error in assessment(x): object &#39;bank_split&#39; not found args(decision_tree) ## function (mode = &quot;unknown&quot;, engine = &quot;rpart&quot;, cost_complexity = NULL, ## tree_depth = NULL, min_n = NULL) ## NULL # model tree_model &lt;- decision_tree() %&gt;% set_engine(&quot;rpart&quot;) %&gt;% set_mode(&quot;classification&quot;) tree_model ## Decision Tree Model Specification (classification) ## ## Computational engine: rpart # recipe tree_recipe &lt;- train_data %&gt;% recipe(Personal_Loan ~ .) %&gt;% step_dummy(all_nominal(), -all_outcomes()) ## Error in recipe(., Personal_Loan ~ .): object &#39;train_data&#39; not found summary(tree_recipe) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;tree_recipe&#39; not found # workflow tree_workflow &lt;- workflow() %&gt;% add_model(tree_model) %&gt;% add_recipe(tree_recipe) ## Error in is_recipe(recipe): object &#39;tree_recipe&#39; not found tree_workflow ## Error in eval(expr, envir, enclos): object &#39;tree_workflow&#39; not found # fit tree_train_fit &lt;- tree_workflow %&gt;% fit(data = train_data) ## Error in fit(., data = train_data): object &#39;tree_workflow&#39; not found tree_train_fit ## Error in eval(expr, envir, enclos): object &#39;tree_train_fit&#39; not found tree_train_pred &lt;- predict(tree_train_fit, train_data, type = &quot;prob&quot;) %&gt;% bind_cols(predict(tree_train_fit, train_data)) %&gt;% bind_cols(train_data %&gt;% select(Personal_Loan)) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;tree_train_fit&#39; not found tree_train_conf &lt;- tree_train_pred %&gt;% conf_mat(truth = Personal_Loan, estimate = .pred_class) ## Error in conf_mat(., truth = Personal_Loan, estimate = .pred_class): object &#39;tree_train_pred&#39; not found autoplot(tree_train_conf, type = &quot;heatmap&quot;) ## Error in autoplot(tree_train_conf, type = &quot;heatmap&quot;): object &#39;tree_train_conf&#39; not found autoplot(tree_train_conf, type = &quot;mosaic&quot;) ## Error in autoplot(tree_train_conf, type = &quot;mosaic&quot;): object &#39;tree_train_conf&#39; not found summary(tree_train_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;tree_train_conf&#39; not found tree_train_pred %&gt;% roc_auc(truth = Personal_Loan, .pred_Yes) ## Error in roc_auc(., truth = Personal_Loan, .pred_Yes): object &#39;tree_train_pred&#39; not found train_auc &lt;- tree_train_pred %&gt;% roc_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% mutate(model = &quot;train_auc&quot;) ## Error in roc_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_train_pred&#39; not found autoplot(train_auc) ## Error in autoplot(train_auc): object &#39;train_auc&#39; not found tree_train_pred %&gt;% lift_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% autoplot() ## Error in lift_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_train_pred&#39; not found tree_train_pred %&gt;% gain_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% autoplot() ## Error in gain_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_train_pred&#39; not found tree_train_fit %&gt;% pull_workflow_fit() %&gt;% vip() ## Error in is_workflow(x): object &#39;tree_train_fit&#39; not found tree_test_fit &lt;- tree_workflow %&gt;% last_fit(bank_split) ## Error in last_fit(., bank_split): object &#39;tree_workflow&#39; not found tree_test_fit ## Error in eval(expr, envir, enclos): object &#39;tree_test_fit&#39; not found tree_test_fit$.predictions ## Error in eval(expr, envir, enclos): object &#39;tree_test_fit&#39; not found tree_test_pred &lt;- tree_test_fit %&gt;% collect_predictions() ## Error in collect_predictions(.): object &#39;tree_test_fit&#39; not found tree_test_conf &lt;- tree_test_pred %&gt;% conf_mat(truth = Personal_Loan, estimate = .pred_class) ## Error in conf_mat(., truth = Personal_Loan, estimate = .pred_class): object &#39;tree_test_pred&#39; not found tree_test_conf ## Error in eval(expr, envir, enclos): object &#39;tree_test_conf&#39; not found tree_test_conf %&gt;% autoplot(type = &quot;heatmap&quot;) ## Error in autoplot(., type = &quot;heatmap&quot;): object &#39;tree_test_conf&#39; not found summary(tree_test_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;tree_test_conf&#39; not found tree_test_pred %&gt;% roc_auc(truth = Personal_Loan, estimate = .pred_Yes) ## Error in roc_auc(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_test_pred&#39; not found test_auc &lt;- tree_test_pred %&gt;% roc_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% mutate(model = &quot;test_auc&quot;) ## Error in roc_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_test_pred&#39; not found autoplot(test_auc) ## Error in autoplot(test_auc): object &#39;test_auc&#39; not found tree_test_pred %&gt;% lift_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% autoplot() ## Error in lift_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_test_pred&#39; not found tree_test_pred %&gt;% gain_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% autoplot() ## Error in gain_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;tree_test_pred&#39; not found tree_test_fit %&gt;% pluck(&quot;.workflow&quot;, 1) %&gt;% pull_workflow_fit() %&gt;% vip(num_features = 20) ## Error in pluck(., &quot;.workflow&quot;, 1): object &#39;tree_test_fit&#39; not found tree_train_conf ## Error in eval(expr, envir, enclos): object &#39;tree_train_conf&#39; not found tree_test_conf ## Error in eval(expr, envir, enclos): object &#39;tree_test_conf&#39; not found summary(tree_train_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;tree_train_conf&#39; not found summary(tree_test_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;tree_test_conf&#39; not found bind_rows(train_auc, test_auc) %&gt;% ggplot(mapping = aes(x = 1-specificity, y = sensitivity, color = model)) + geom_path(lwd = 1.5) + geom_abline(lty = 3) + coord_equal() ## Error in list2(...): object &#39;train_auc&#39; not found if(!require(rpart.plot)) { install.packages(&quot;rpart.plot&quot;); library(rpart.plot); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages rpart_fit &lt;- tree_train_fit %&gt;% pull_workflow_fit() ## Error in is_workflow(x): object &#39;tree_train_fit&#39; not found rpart.plot(x = rpart_fit$fit, yesno = 2, type = 2, extra = 1, split.font = 1, varlen = -10) ## Error in rpart.plot(x = rpart_fit$fit, yesno = 2, type = 2, extra = 1, : object &#39;rpart_fit&#39; not found prp(x = rpart_fit$fit, type = 1, extra = 1, under = T, split.font = 1, varlen = -10, box.col = ifelse(rpart_fit$fit$frame$var == &quot;&lt;leaf&gt;&quot;, &quot;gray&quot;, &quot;white&quot;) ) ## Error in prp(x = rpart_fit$fit, type = 1, extra = 1, under = T, split.font = 1, : object &#39;rpart_fit&#39; not found "],["til20220520.html", "5.20 TIL20220520", " 5.20 TIL20220520 5.20.1 출장 "],["til20220521.html", "5.21 TIL20220521", " 5.21 TIL20220521 5.21.1 19일 참고 "],["til20220522.html", "5.22 TIL20220522", " 5.22 TIL20220522 5.22.1 최적 모델 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(tidymodels)) { install.packages(&quot;tidymodels&quot;); library(tidymodels); } if(!require(tidytext)) { install.packages(&quot;tidytext&quot;); library(tidytext); } if(!require(skimr)) { install.packages(&quot;skimr&quot;); library(skimr); } if(!require(vip)) { install.packages(&quot;vip&quot;); library(vip); } bank_tb &lt;- read_csv(&quot;UniversalBank.csv&quot;, col_names = T, locale = locale(&quot;ko&quot;, encoding = &quot;euc-kr&quot;), na = &quot;.&quot;) %&gt;% mutate_if(is.character, as.factor) ## Error: &#39;UniversalBank.csv&#39; does not exist in current working directory (&#39;/Users/runner/work/TIL2022/TIL2022&#39;). str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found head(bank_tb) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;bank_tb&#39; not found # 변수명 점검 bank_tb &lt;- bank_tb %&gt;% rename(c(&quot;Personal_Loan&quot; = &quot;Personal Loan&quot;, &quot;CD_Account&quot; = &quot;CD Account&quot;, &quot;Securities_Account&quot; = &quot;Securities Account&quot;)) ## Error in rename(., c(Personal_Loan = &quot;Personal Loan&quot;, CD_Account = &quot;CD Account&quot;, : object &#39;bank_tb&#39; not found str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found # 자료형 점검 bank_tb &lt;- bank_tb %&gt;% mutate(Personal_Loan = factor(Personal_Loan, levels = c(1, 0), labels = c(&quot;Yes&quot;, &quot;No&quot;))) %&gt;% mutate(Securities_Account = factor(Securities_Account, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(CD_Account = factor(CD_Account, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(Online = factor(Online, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(CreditCard = factor(CreditCard, levels = c(0,1), labels = c(&quot;No&quot;, &quot;Yes&quot;))) %&gt;% mutate(Education = factor(Education, levels = c(1:3), labels = c(&quot;Undergrad&quot;, &quot;Graduate&quot;, &quot;Professonal&quot;))) ## Error in mutate(., Personal_Loan = factor(Personal_Loan, levels = c(1, : object &#39;bank_tb&#39; not found str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found # 변수 점검 (삭제, 변환 등) bank_tb &lt;- bank_tb %&gt;% select(-c(ID, &#39;ZIP Code&#39;)) ## Error in select(., -c(ID, &quot;ZIP Code&quot;)): object &#39;bank_tb&#39; not found str(bank_tb) ## Error in str(bank_tb): object &#39;bank_tb&#39; not found # EDA skim(bank_tb) ## Error in skim(bank_tb): object &#39;bank_tb&#39; not found bank_tb %&gt;% group_by(Personal_Loan) %&gt;% skim() ## Error in group_by(., Personal_Loan): object &#39;bank_tb&#39; not found # base accuracy bank_tb %&gt;% count(Personal_Loan) %&gt;% mutate(prop = n / sum(n)) ## Error in count(., Personal_Loan): object &#39;bank_tb&#39; not found # 데이터셋 분할 set.seed(123) bank_split &lt;- bank_tb %&gt;% initial_split(strata = Personal_Loan) ## Error in eval_select_impl(NULL, .vars, expr(c(!!!dots)), include = .include, : object &#39;bank_tb&#39; not found bank_split ## Error in eval(expr, envir, enclos): object &#39;bank_split&#39; not found train_data &lt;- training(bank_split) ## Error in analysis(x): object &#39;bank_split&#39; not found test_data &lt;- testing(bank_split) ## Error in assessment(x): object &#39;bank_split&#39; not found tree_model &lt;- decision_tree( cost_complexity = tune(), tree_depth = tune()) %&gt;% set_engine(&quot;rpart&quot;) %&gt;% set_mode(&quot;classification&quot;) tree_model ## Decision Tree Model Specification (classification) ## ## Main Arguments: ## cost_complexity = tune() ## tree_depth = tune() ## ## Computational engine: rpart tree_grid &lt;- grid_regular( cost_complexity(), tree_depth(), levels = 5 ) tree_grid ## # A tibble: 25 × 2 ## cost_complexity tree_depth ## &lt;dbl&gt; &lt;int&gt; ## 1 0.0000000001 1 ## 2 0.0000000178 1 ## 3 0.00000316 1 ## 4 0.000562 1 ## 5 0.1 1 ## 6 0.0000000001 4 ## 7 0.0000000178 4 ## 8 0.00000316 4 ## 9 0.000562 4 ## 10 0.1 4 ## # … with 15 more rows set.seed(123) bank_folds &lt;- vfold_cv(train_data, v=3) ## Error in nrow(data): object &#39;train_data&#39; not found bank_folds ## Error in eval(expr, envir, enclos): object &#39;bank_folds&#39; not found # recipe tree_recipe &lt;- train_data %&gt;% recipe(Personal_Loan ~ .) %&gt;% step_dummy(all_nominal(), -all_outcomes()) ## Error in recipe(., Personal_Loan ~ .): object &#39;train_data&#39; not found summary(tree_recipe) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;tree_recipe&#39; not found # workflow tree_workflow &lt;- workflow() %&gt;% add_model(tree_model) %&gt;% add_recipe(tree_recipe) ## Error in is_recipe(recipe): object &#39;tree_recipe&#39; not found tree_workflow ## Error in eval(expr, envir, enclos): object &#39;tree_workflow&#39; not found tree_results &lt;- tree_workflow %&gt;% tune_grid(resamples = bank_folds, grid = tree_grid, control = control_grid(save_pred = T), metrics = metric_set(roc_auc, accuracy)) ## Error in tune_grid(., resamples = bank_folds, grid = tree_grid, control = control_grid(save_pred = T), : object &#39;tree_workflow&#39; not found tree_results ## Error in eval(expr, envir, enclos): object &#39;tree_results&#39; not found tree_results %&gt;% collect_metrics() ## Error in collect_metrics(.): object &#39;tree_results&#39; not found tree_results %&gt;% collect_metrics() %&gt;% mutate(tree_depth = factor(tree_depth)) %&gt;% ggplot(mapping = aes(x=cost_complexity, y = mean, col = tree_depth)) + geom_line(size = 1.5, alpha = 0.6) + geom_point(size = 2) + facet_wrap(~.metric, scales = &quot;free&quot;, nrow = 2) + scale_x_log10(labels = scales::label_number()) + scale_color_viridis_d(option = &quot;plasma&quot;, begin = 0.9, end = 0) ## Error in collect_metrics(.): object &#39;tree_results&#39; not found tree_results %&gt;% show_best(&quot;roc_auc&quot;, n=10) %&gt;% arrange(desc(mean)) ## Error in show_best(., &quot;roc_auc&quot;, n = 10): object &#39;tree_results&#39; not found best_tree &lt;- tree_results %&gt;% select_best(&quot;roc_auc&quot;) ## Error in select_best(., &quot;roc_auc&quot;): object &#39;tree_results&#39; not found best_tree ## Error in eval(expr, envir, enclos): object &#39;best_tree&#39; not found final_workflow &lt;- tree_workflow %&gt;% finalize_workflow(best_tree) ## Error in finalize_workflow(., best_tree): object &#39;tree_workflow&#39; not found final_workflow ## Error in eval(expr, envir, enclos): object &#39;final_workflow&#39; not found final_train_fit &lt;- final_workflow %&gt;% fit(data = train_data) ## Error in fit(., data = train_data): object &#39;final_workflow&#39; not found final_train_fit ## Error in eval(expr, envir, enclos): object &#39;final_train_fit&#39; not found final_train_fit %&gt;% pull_workflow_fit() ## Error in is_workflow(x): object &#39;final_train_fit&#39; not found final_train_pred &lt;- predict(final_train_fit, train_data, type = &quot;prob&quot;) %&gt;% bind_cols(predict(final_train_fit, train_data)) %&gt;% bind_cols(train_data %&gt;% select(Personal_Loan)) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;final_train_fit&#39; not found final_train_pred ## Error in eval(expr, envir, enclos): object &#39;final_train_pred&#39; not found final_train_conf &lt;- final_train_pred %&gt;% conf_mat(truth = Personal_Loan, estimate = .pred_class) ## Error in conf_mat(., truth = Personal_Loan, estimate = .pred_class): object &#39;final_train_pred&#39; not found final_train_conf ## Error in eval(expr, envir, enclos): object &#39;final_train_conf&#39; not found autoplot(final_train_conf, type = &quot;heatmap&quot;) ## Error in autoplot(final_train_conf, type = &quot;heatmap&quot;): object &#39;final_train_conf&#39; not found summary(final_train_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;final_train_conf&#39; not found train_auc &lt;- final_train_pred %&gt;% roc_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% mutate(model = &quot;train_auc&quot;) ## Error in roc_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;final_train_pred&#39; not found autoplot(train_auc) ## Error in autoplot(train_auc): object &#39;train_auc&#39; not found final_train_pred %&gt;% gain_curve(Personal_Loan, .pred_Yes) %&gt;% autoplot ## Error in gain_curve(., Personal_Loan, .pred_Yes): object &#39;final_train_pred&#39; not found final_train_pred %&gt;% lift_curve(Personal_Loan, .pred_Yes) %&gt;% autoplot ## Error in lift_curve(., Personal_Loan, .pred_Yes): object &#39;final_train_pred&#39; not found final_train_fit %&gt;% pull_workflow_fit() %&gt;% vip() ## Error in is_workflow(x): object &#39;final_train_fit&#39; not found final_test_fit &lt;- final_workflow %&gt;% last_fit(bank_split) ## Error in last_fit(., bank_split): object &#39;final_workflow&#39; not found final_test_fit ## Error in eval(expr, envir, enclos): object &#39;final_test_fit&#39; not found final_test_pred &lt;- final_test_fit %&gt;% collect_predictions() ## Error in collect_predictions(.): object &#39;final_test_fit&#39; not found final_test_pred ## Error in eval(expr, envir, enclos): object &#39;final_test_pred&#39; not found final_test_conf &lt;- final_test_pred %&gt;% conf_mat(truth = Personal_Loan, estimate = .pred_class) ## Error in conf_mat(., truth = Personal_Loan, estimate = .pred_class): object &#39;final_test_pred&#39; not found final_test_conf ## Error in eval(expr, envir, enclos): object &#39;final_test_conf&#39; not found autoplot(final_test_conf, type = &quot;heatmap&quot;) ## Error in autoplot(final_test_conf, type = &quot;heatmap&quot;): object &#39;final_test_conf&#39; not found summary(final_test_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;final_test_conf&#39; not found test_auc &lt;- final_test_pred %&gt;% roc_curve(truth = Personal_Loan, estimate = .pred_Yes) %&gt;% mutate(model = &quot;test_auc&quot;) ## Error in roc_curve(., truth = Personal_Loan, estimate = .pred_Yes): object &#39;final_test_pred&#39; not found autoplot(test_auc) ## Error in autoplot(test_auc): object &#39;test_auc&#39; not found final_test_pred %&gt;% gain_curve(Personal_Loan, .pred_Yes) %&gt;% autoplot ## Error in gain_curve(., Personal_Loan, .pred_Yes): object &#39;final_test_pred&#39; not found final_test_pred %&gt;% lift_curve(Personal_Loan, .pred_Yes) %&gt;% autoplot ## Error in lift_curve(., Personal_Loan, .pred_Yes): object &#39;final_test_pred&#39; not found final_test_fit %&gt;% pluck(&quot;.workflow&quot;, 1) %&gt;% pull_workflow_fit() %&gt;% vip(num_features = 20) ## Error in pluck(., &quot;.workflow&quot;, 1): object &#39;final_test_fit&#39; not found final_train_conf ## Error in eval(expr, envir, enclos): object &#39;final_train_conf&#39; not found final_test_conf ## Error in eval(expr, envir, enclos): object &#39;final_test_conf&#39; not found summary(final_train_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;final_train_conf&#39; not found summary(final_test_conf) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;final_test_conf&#39; not found bind_rows(train_auc, test_auc) %&gt;% ggplot(mapping = aes(x = 1 - specificity, y = sensitivity, color = model)) + geom_path(lwd = 1.5) + geom_abline(lty = 3) + coord_equal() ## Error in list2(...): object &#39;train_auc&#39; not found if(!require(rpart.plot)) { install.packages(&quot;rpart.plot&quot;); library(rpart.plot); } rpart_fit &lt;- final_train_fit %&gt;% pull_workflow_fit() ## Error in is_workflow(x): object &#39;final_train_fit&#39; not found rpart.plot(x = rpart_fit$fit, yesno = 2, type = 2, extra = 1, split.font = 1, varlen = -10) ## Error in rpart.plot(x = rpart_fit$fit, yesno = 2, type = 2, extra = 1, : object &#39;rpart_fit&#39; not found prp(x = rpart_fit$fit, type = 1, extra = 1, under = T, split.font = 1, varlen = -10, box.col = ifelse(rpart_fit$fit$frame$var == &quot;&lt;leaf&gt;&quot;, &quot;gray&quot;, &quot;white&quot;) ) ## Error in prp(x = rpart_fit$fit, type = 1, extra = 1, under = T, split.font = 1, : object &#39;rpart_fit&#39; not found "],["til20220523.html", "5.23 TIL20220523", " 5.23 TIL20220523 5.23.1 histogram data &lt;- sample(160:190, 50, replace = T) hg &lt;- hist(data) text(hg$mids, hg$counts, adj=c(0.5, -0.5)) mh &lt;- rnorm(500, 170, 5) fh &lt;- rnorm(500, 160, 5) x_range &lt;- seq(130, 200, by = 2) mh_hist &lt;- hist(mh, breaks = x_range, plot = F) fh_hist &lt;- hist(fh, breaks = x_range, plot = F) ymax &lt;- max(max(mh_hist$counts), max(fh_hist$counts)) { plot(mh_hist, col=adjustcolor(&quot;blue&quot;, alpha=.5), ann = F, axes = F) plot(fh_hist, col=adjustcolor(&quot;red&quot;, alpha=.5), ann = F, axes = F, add = T) title(main = &quot;Hight of Man and Female&quot;) x_axis_tick &lt;- x_range axis(side=1, at=x_axis_tick) y_axis_tick &lt;- seq(0, ymax, by = 10) axis(side=2, at=y_axis_tick) legend(&quot;topright&quot;, c(&quot;male&quot;, &quot;female&quot;), fill = c(&quot;blue&quot;, &quot;red&quot;)) box(&quot;figure&quot;, col=&quot;gray&quot;) } "],["til20220524.html", "5.24 TIL20220524", " 5.24 TIL20220524 5.24.1 "],["til20220525.html", "5.25 TIL20220525", " 5.25 TIL20220525 5.25.1 "],["til20220526.html", "5.26 TIL20220526", " 5.26 TIL20220526 5.26.1 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } data &lt;- penguins str(data) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... data.lm &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, data = data) summary(data.lm) ## ## Call: ## lm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, ## data = data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1054.9 -290.3 -21.9 239.0 1276.6 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -6424.76 561.47 -11.44 &lt;2e-16 *** ## bill_length_mm 4.16 5.33 0.78 0.44 ## bill_depth_mm 20.05 13.69 1.46 0.14 ## flipper_length_mm 50.27 2.48 20.29 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 393 on 338 degrees of freedom ## (2 observations deleted due to missingness) ## Multiple R-squared: 0.761, Adjusted R-squared: 0.759 ## F-statistic: 360 on 3 and 338 DF, p-value: &lt;2e-16 # t_value = Estimate / Std.Error 50.269/2.477 ## [1] 20.3 "],["til20220527.html", "5.27 TIL20220527", " 5.27 TIL20220527 5.27.1 factor형 label변경 data &lt;- data.frame( x = factor(&quot;A&quot;), y = 1 ) data ## x y ## 1 A 1 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } new_data &lt;- data %&gt;% mutate(x = fct_recode(x, &quot;B&quot; = &quot;A&quot;)) new_data ## x y ## 1 B 1 "],["til20220528.html", "5.28 TIL20220528", " 5.28 TIL20220528 5.28.1 BCR BCR BCR BCR (Balanced Classification Rate) = 1/2* (TP / (TP + FN) + TN / (TN + FP)) 출처 "],["til20220529.html", "5.29 TIL20220529", " 5.29 TIL20220529 5.29.1 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } str(msleep) ## tibble [83 × 11] (S3: tbl_df/tbl/data.frame) ## $ name : chr [1:83] &quot;Cheetah&quot; &quot;Owl monkey&quot; &quot;Mountain beaver&quot; &quot;Greater short-tailed shrew&quot; ... ## $ genus : chr [1:83] &quot;Acinonyx&quot; &quot;Aotus&quot; &quot;Aplodontia&quot; &quot;Blarina&quot; ... ## $ vore : chr [1:83] &quot;carni&quot; &quot;omni&quot; &quot;herbi&quot; &quot;omni&quot; ... ## $ order : chr [1:83] &quot;Carnivora&quot; &quot;Primates&quot; &quot;Rodentia&quot; &quot;Soricomorpha&quot; ... ## $ conservation: chr [1:83] &quot;lc&quot; NA &quot;nt&quot; &quot;lc&quot; ... ## $ sleep_total : num [1:83] 12.1 17 14.4 14.9 4 14.4 8.7 7 10.1 3 ... ## $ sleep_rem : num [1:83] NA 1.8 2.4 2.3 0.7 2.2 1.4 NA 2.9 NA ... ## $ sleep_cycle : num [1:83] NA NA NA 0.133 0.667 ... ## $ awake : num [1:83] 11.9 7 9.6 9.1 20 9.6 15.3 17 13.9 21 ... ## $ brainwt : num [1:83] NA 0.0155 NA 0.00029 0.423 NA NA NA 0.07 0.0982 ... ## $ bodywt : num [1:83] 50 0.48 1.35 0.019 600 ... my_data &lt;- msleep %&gt;% select(name, sleep_total) "],["til20220530.html", "5.30 TIL20220530", " 5.30 TIL20220530 5.30.1 회귀분석 가정 선형성(linearity) 종속변수와 독립변수 간의 관계는 선형이다. 정규성(normality) 독립변수 값에 대해 대응되는 종속변수 값들의 분포는 정규분포이다. 등분산성(homoscedasticity, equality of variance) 독립변수 값에 대해 대응되는 종속변수 값들의 분포는 모두 동일한 분산을 갖는다. 독립성(independence) 모든 관측값은 서로 독립이다. 하나의 관측값은 다른 관측값에 영향을 미치지 않는다. str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... mtcars.lm &lt;- lm(mpg ~ hp + wt + disp + drat, data = mtcars) plot(mtcars.lm) 도표 순서대로 1) 선형성, 2) 정규성, 3) 등분산성, 4) 주의를 요하는 관측값 정보를 출력해 준다. 다중공선성(multicollinearity) 독립변수 간의 강한 선형관계, VIF(variance inflation factor, 분산팽창지수)가 4를 넘으면 다중공선성이 존재하는지 점검이 필요, 10을 초과하면 존재할 가능성이 높다고 판단 \\[VIF = \\frac{1}{1-R_i^2}\\] library(car) vif(mtcars.lm) ## hp wt disp drat ## 2.89 5.10 8.21 2.28 회귀모델 수정 관측값 제거, 변수 변환, 변수 추가/제거를 통해 회귀모델을 수정한다. 이상점(outlier)/영향점(influential point) -&gt; 관측값 제거 선형성, 정규성, 등분산성 가정 미충족 -&gt; 변수 변환 선형성의 가정을 위배하면 독립변수를 변환 정규성/등분산성의 가정을 위배하면 종속변수를 변환 다중공선성 -&gt; 변수 제거 정규성 미충족 시 변수변환을 통해 회귀모델을 수정한다. # 종속변수의 람다값을 추정한다. car::powerTransform(mtcars$mpg) ## Estimated transformation parameter ## mtcars$mpg ## 0.0296 # 귀무가설: 변환을 하지 않는다 summary(car::powerTransform(mtcars$mpg)) ## bcPower Transformation to Normality ## Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd ## mtcars$mpg 0.0296 1 -1.01 1.07 ## ## Likelihood ratio test that transformation parameter is equal to 0 ## (log transformation) ## LRT df pval ## LR test, lambda = (0) 0.00311 1 1 ## ## Likelihood ratio test that no transformation is needed ## LRT df pval ## LR test, lambda = (1) 3.21 1 0.07 # 독립변수의 람다값을 추정한다. car::boxTidwell(mpg ~ hp + wt, data = mtcars) ## MLE of lambda Score Statistic (z) Pr(&gt;|z|) ## hp -0.6 2 0.018 * ## wt -0.4 3 0.006 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## iterations = 6 # 등분산 위배 시 종속변수 변환 # 등분산성을 개선하기 위한 람다 계산 car::spreadLevelPlot(lm(mpg ~ hp + wt, data = mtcars)) ## ## Suggested power transformation: 0.585 "],["til20220531.html", "5.31 TIL20220531", " 5.31 TIL20220531 5.31.1 다변량 분산분석 if(!require(heplots)) { install.packages(&quot;heplots&quot;); library(heplots); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages str(Skulls) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ epoch: Ord.factor w/ 5 levels &quot;c4000BC&quot;&lt;&quot;c3300BC&quot;&lt;..: 1 1 1 1 1 1 1 1 1 1 ... ## $ mb : num 131 125 131 119 136 138 139 125 131 134 ... ## $ bh : num 138 131 132 132 143 137 130 136 134 134 ... ## $ bl : num 89 92 99 96 100 89 108 93 102 99 ... ## $ nh : num 49 48 50 44 54 56 48 48 51 51 ... data &lt;- Skulls if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } sample_n(data, 10) ## epoch mb bh bl nh ## 46 c3300BC 131 128 98 45 ## 51 c3300BC 137 136 106 49 ## 32 c3300BC 133 134 97 48 ## 129 cAD150 132 132 99 55 ## 10 c4000BC 134 134 99 51 ## 69 c1850BC 136 131 92 46 ## 5 c4000BC 136 143 100 54 ## 122 cAD150 136 131 95 49 ## 114 c200BC 130 131 98 53 ## 130 cAD150 139 135 92 54 data %&gt;% group_by(epoch) %&gt;% summarise_all( list( Mean = mean, Meidan = median, SD = sd ) ) ## # A tibble: 5 × 13 ## epoch mb_Mean bh_Mean bl_Mean nh_Mean mb_Mei…¹ bh_Me…² bl_Me…³ nh_Me…⁴ mb_SD ## &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c4000BC 131. 134. 99.2 50.5 131 134 100 50 5.13 ## 2 c3300BC 132. 133. 99.1 50.2 132 133 98.5 50.5 4.81 ## 3 c1850BC 134. 134. 96.0 50.6 136 134. 96 50 3.48 ## 4 c200BC 136. 132. 94.5 52.0 135 132 94.5 52 3.92 ## 5 cAD150 136. 130. 93.5 51.4 137 130 94 52 5.35 ## # … with 3 more variables: bh_SD &lt;dbl&gt;, bl_SD &lt;dbl&gt;, nh_SD &lt;dbl&gt;, and ## # abbreviated variable names ¹​mb_Meidan, ²​bh_Meidan, ³​bl_Meidan, ⁴​nh_Meidan data %&gt;% group_by(epoch) %&gt;% summarise_if(is.numeric, list(mean, sd), na.rm = T) ## # A tibble: 5 × 9 ## epoch mb_fn1 bh_fn1 bl_fn1 nh_fn1 mb_fn2 bh_fn2 bl_fn2 nh_fn2 ## &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c4000BC 131. 134. 99.2 50.5 5.13 4.47 5.88 2.76 ## 2 c3300BC 132. 133. 99.1 50.2 4.81 4.65 4.35 2.96 ## 3 c1850BC 134. 134. 96.0 50.6 3.48 4.98 4.55 3.55 ## 4 c200BC 136. 132. 94.5 52.0 3.92 5.13 4.59 2.82 ## 5 cAD150 136. 130. 93.5 51.4 5.35 4.97 5.06 3.72 data %&gt;% group_by(epoch) %&gt;% summarise_if(is.numeric, list(Min = min, Max = max), na.rm = T) ## # A tibble: 5 × 9 ## epoch mb_Min bh_Min bl_Min nh_Min mb_Max bh_Max bl_Max nh_Max ## &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c4000BC 119 121 89 44 141 143 114 56 ## 2 c3300BC 123 124 90 45 148 145 107 56 ## 3 c1850BC 126 123 87 45 140 145 106 60 ## 4 c200BC 129 120 86 46 144 142 107 60 ## 5 cAD150 126 120 81 44 147 138 103 58 head(data) ## epoch mb bh bl nh ## 1 c4000BC 131 138 89 49 ## 2 c4000BC 125 131 92 48 ## 3 c4000BC 131 132 99 50 ## 4 c4000BC 119 132 96 44 ## 5 c4000BC 136 143 100 54 ## 6 c4000BC 138 137 89 56 y &lt;- data[, -1]; head(y) ## mb bh bl nh ## 1 131 138 89 49 ## 2 125 131 92 48 ## 3 131 132 99 50 ## 4 119 132 96 44 ## 5 136 143 100 54 ## 6 138 137 89 56 data %&gt;% group_by(epoch) %&gt;% summarise_all(list(Mean = mean)) ## # A tibble: 5 × 5 ## epoch mb_Mean bh_Mean bl_Mean nh_Mean ## &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c4000BC 131. 134. 99.2 50.5 ## 2 c3300BC 132. 133. 99.1 50.2 ## 3 c1850BC 134. 134. 96.0 50.6 ## 4 c200BC 136. 132. 94.5 52.0 ## 5 cAD150 136. 130. 93.5 51.4 data.manova &lt;- manova(cbind(mb,bh,bl,nh) ~ epoch, data) summary(data.manova) ## Df Pillai approx F num Df den Df Pr(&gt;F) ## epoch 4 0.353 3.51 16 580 4.7e-06 *** ## Residuals 145 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary.aov(data.manova) ## Response mb : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## epoch 4 503 125.7 5.95 0.00018 *** ## Residuals 145 3061 21.1 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Response bh : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## epoch 4 230 57.5 2.45 0.049 * ## Residuals 145 3405 23.5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Response bl : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## epoch 4 803 200.8 8.31 4.6e-06 *** ## Residuals 145 3506 24.2 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Response nh : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## epoch 4 61 15.3 1.51 0.2 ## Residuals 145 1472 10.2 "],["년-06월.html", "6 2022년 06월 ", " 6 2022년 06월 "],["til20220601.html", "6.1 TIL20220601", " 6.1 TIL20220601 6.1.1 데이터 분석 절차 데이터 수집 데이터 정제 데이터 가공 데이터 분할 모델 학습 예측 및 평가 성능개선 결과 활용 6.1.1.1 데이터 수집 UCL에서 데이터셋 불러 오기 wine dataset - http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data wine.fl &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot; wine &lt;- read.csv(wine.fl,header = F) wine.names &lt;- c(&quot;Alcohol&quot;, &quot;Malic acid&quot;, &quot;Ash&quot;, &quot;Alcalinity of ash&quot;, &quot;Magnesium&quot;, &quot;Total phenols&quot;, &quot;Flavanoids&quot;, &quot;Nonflavanoid phenols&quot;, &quot;Proanthocyanins&quot;, &quot;Color intensity&quot;, &quot;Hue&quot;, &quot;OD280/OD315 of diluted wines&quot;, &quot;Proline&quot;) colnames(wine)[2:14] &lt;- wine.names colnames(wine)[1] &lt;- &quot;Class&quot; str(wine) ## &#39;data.frame&#39;: 178 obs. of 14 variables: ## $ Class : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Alcohol : num 14.2 13.2 13.2 14.4 13.2 ... ## $ Malic acid : num 1.71 1.78 2.36 1.95 2.59 1.76 1.87 2.15 1.64 1.35 ... ## $ Ash : num 2.43 2.14 2.67 2.5 2.87 2.45 2.45 2.61 2.17 2.27 ... ## $ Alcalinity of ash : num 15.6 11.2 18.6 16.8 21 15.2 14.6 17.6 14 16 ... ## $ Magnesium : int 127 100 101 113 118 112 96 121 97 98 ... ## $ Total phenols : num 2.8 2.65 2.8 3.85 2.8 3.27 2.5 2.6 2.8 2.98 ... ## $ Flavanoids : num 3.06 2.76 3.24 3.49 2.69 3.39 2.52 2.51 2.98 3.15 ... ## $ Nonflavanoid phenols : num 0.28 0.26 0.3 0.24 0.39 0.34 0.3 0.31 0.29 0.22 ... ## $ Proanthocyanins : num 2.29 1.28 2.81 2.18 1.82 1.97 1.98 1.25 1.98 1.85 ... ## $ Color intensity : num 5.64 4.38 5.68 7.8 4.32 6.75 5.25 5.05 5.2 7.22 ... ## $ Hue : num 1.04 1.05 1.03 0.86 1.04 1.05 1.02 1.06 1.08 1.01 ... ## $ OD280/OD315 of diluted wines: num 3.92 3.4 3.17 3.45 2.93 2.85 3.58 3.58 2.85 3.55 ... ## $ Proline : int 1065 1050 1185 1480 735 1450 1290 1295 1045 1045 ... 6.1.1.2 데이터 정제 6.1.1.2.1 결측치 처리 # 결측치 확인 wine_na &lt;- colSums(is.na(wine)) as.matrix(wine_na) ## [,1] ## Class 0 ## Alcohol 0 ## Malic acid 0 ## Ash 0 ## Alcalinity of ash 0 ## Magnesium 0 ## Total phenols 0 ## Flavanoids 0 ## Nonflavanoid phenols 0 ## Proanthocyanins 0 ## Color intensity 0 ## Hue 0 ## OD280/OD315 of diluted wines 0 ## Proline 0 if(!require(naniar)) { install.packages(&quot;naniar&quot;); library(naniar); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages n_miss(wine) ## [1] 0 miss_case_summary(wine) ## # A tibble: 178 × 3 ## case n_miss pct_miss ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 0 0 ## 2 2 0 0 ## 3 3 0 0 ## 4 4 0 0 ## 5 5 0 0 ## 6 6 0 0 ## 7 7 0 0 ## 8 8 0 0 ## 9 9 0 0 ## 10 10 0 0 ## # … with 168 more rows vis_miss(wine) table(wine$Class, useNA=&quot;ifany&quot;) ## ## 1 2 3 ## 59 71 48 결측치 처리 방법 결측치 제거 단순대체 다중대체 x &lt;- c(1,2,3,4,NA,6,7,8,NA,10) summary(x) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 1.00 2.75 5.00 5.12 7.25 10.00 2 # 1. 결측치 제거 x_1 &lt;- na.omit(x) summary(x_1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 2.75 5.00 5.12 7.25 10.00 # 2. 단순대체 x_mean &lt;- mean(x, na.rm = T); x_mean ## [1] 5.12 x_2 &lt;- x x_2[is.na(x)] &lt;- x_mean round(x_2,2) ## [1] 1.00 2.00 3.00 4.00 5.12 6.00 7.00 8.00 5.12 10.00 6.1.1.2.2 이상치 처리 if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } ggplot(wine, aes(x=as.factor(Class), y=Alcohol)) + geom_boxplot() ggplot(wine, aes(x=as.factor(Class), y=wine$Proline)) + geom_boxplot() 6.1.1.3 데이터 가공 6.1.1.4 데이터 분할 6.1.1.5 모델 학습 6.1.1.6 예측 및 평가 6.1.1.7 성능개선 6.1.1.8 결과 활용 "],["til20220602.html", "6.2 TIL20220602", " 6.2 TIL20220602 6.2.1 wine.fl &lt;- &quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot; wine &lt;- read.csv(wine.fl,header = F) wine.names &lt;- c(&quot;Alcohol&quot;, &quot;Malic acid&quot;, &quot;Ash&quot;, &quot;Alcalinity of ash&quot;, &quot;Magnesium&quot;, &quot;Total phenols&quot;, &quot;Flavanoids&quot;, &quot;Nonflavanoid phenols&quot;, &quot;Proanthocyanins&quot;, &quot;Color intensity&quot;, &quot;Hue&quot;, &quot;OD280/OD315 of diluted wines&quot;, &quot;Proline&quot;) colnames(wine)[2:14] &lt;- wine.names colnames(wine)[1] &lt;- &quot;Class&quot; str(wine) ## &#39;data.frame&#39;: 178 obs. of 14 variables: ## $ Class : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Alcohol : num 14.2 13.2 13.2 14.4 13.2 ... ## $ Malic acid : num 1.71 1.78 2.36 1.95 2.59 1.76 1.87 2.15 1.64 1.35 ... ## $ Ash : num 2.43 2.14 2.67 2.5 2.87 2.45 2.45 2.61 2.17 2.27 ... ## $ Alcalinity of ash : num 15.6 11.2 18.6 16.8 21 15.2 14.6 17.6 14 16 ... ## $ Magnesium : int 127 100 101 113 118 112 96 121 97 98 ... ## $ Total phenols : num 2.8 2.65 2.8 3.85 2.8 3.27 2.5 2.6 2.8 2.98 ... ## $ Flavanoids : num 3.06 2.76 3.24 3.49 2.69 3.39 2.52 2.51 2.98 3.15 ... ## $ Nonflavanoid phenols : num 0.28 0.26 0.3 0.24 0.39 0.34 0.3 0.31 0.29 0.22 ... ## $ Proanthocyanins : num 2.29 1.28 2.81 2.18 1.82 1.97 1.98 1.25 1.98 1.85 ... ## $ Color intensity : num 5.64 4.38 5.68 7.8 4.32 6.75 5.25 5.05 5.2 7.22 ... ## $ Hue : num 1.04 1.05 1.03 0.86 1.04 1.05 1.02 1.06 1.08 1.01 ... ## $ OD280/OD315 of diluted wines: num 3.92 3.4 3.17 3.45 2.93 2.85 3.58 3.58 2.85 3.55 ... ## $ Proline : int 1065 1050 1185 1480 735 1450 1290 1295 1045 1045 ... as.matrix(colSums(is.na(wine))) ## [,1] ## Class 0 ## Alcohol 0 ## Malic acid 0 ## Ash 0 ## Alcalinity of ash 0 ## Magnesium 0 ## Total phenols 0 ## Flavanoids 0 ## Nonflavanoid phenols 0 ## Proanthocyanins 0 ## Color intensity 0 ## Hue 0 ## OD280/OD315 of diluted wines 0 ## Proline 0 # 데이터 전처리 wine$Class &lt;- as.factor(wine$Class) table(wine$Class, dnn = c(&quot;Wine Type&quot;)) ## Wine Type ## 1 2 3 ## 59 71 48 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } wine &lt;- wine %&gt;% janitor::clean_names() ## Error in loadNamespace(x): there is no package called &#39;janitor&#39; str(wine) ## &#39;data.frame&#39;: 178 obs. of 14 variables: ## $ Class : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Alcohol : num 14.2 13.2 13.2 14.4 13.2 ... ## $ Malic acid : num 1.71 1.78 2.36 1.95 2.59 1.76 1.87 2.15 1.64 1.35 ... ## $ Ash : num 2.43 2.14 2.67 2.5 2.87 2.45 2.45 2.61 2.17 2.27 ... ## $ Alcalinity of ash : num 15.6 11.2 18.6 16.8 21 15.2 14.6 17.6 14 16 ... ## $ Magnesium : int 127 100 101 113 118 112 96 121 97 98 ... ## $ Total phenols : num 2.8 2.65 2.8 3.85 2.8 3.27 2.5 2.6 2.8 2.98 ... ## $ Flavanoids : num 3.06 2.76 3.24 3.49 2.69 3.39 2.52 2.51 2.98 3.15 ... ## $ Nonflavanoid phenols : num 0.28 0.26 0.3 0.24 0.39 0.34 0.3 0.31 0.29 0.22 ... ## $ Proanthocyanins : num 2.29 1.28 2.81 2.18 1.82 1.97 1.98 1.25 1.98 1.85 ... ## $ Color intensity : num 5.64 4.38 5.68 7.8 4.32 6.75 5.25 5.05 5.2 7.22 ... ## $ Hue : num 1.04 1.05 1.03 0.86 1.04 1.05 1.02 1.06 1.08 1.01 ... ## $ OD280/OD315 of diluted wines: num 3.92 3.4 3.17 3.45 2.93 2.85 3.58 3.58 2.85 3.55 ... ## $ Proline : int 1065 1050 1185 1480 735 1450 1290 1295 1045 1045 ... wine_pp &lt;- preProcess(wine[, -1], method = c(&quot;center&quot;, &quot;scale&quot;, &quot;YeoJohnson&quot;)) wine_pp ## Created from 178 samples and 13 variables ## ## Pre-processing: ## - centered (13) ## - ignored (0) ## - scaled (13) ## - Yeo-Johnson transformation (13) ## ## Lambda estimates for Yeo-Johnson transformation: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -1.596 -0.117 0.616 0.275 0.864 1.658 wine_tx &lt;- predict(wine_pp, newdata = wine[, -1]) head(wine_tx) ## Alcohol Malic acid Ash Alcalinity of ash Magnesium Total phenols ## 1 1.526 -0.434 0.210 -1.177 1.686 0.818 ## 2 0.238 -0.338 -0.837 -2.656 0.188 0.590 ## 3 0.188 0.317 1.116 -0.243 0.261 0.818 ## 4 1.703 -0.121 0.470 -0.797 1.018 2.324 ## 5 0.287 0.522 1.898 0.471 1.278 0.818 ## 6 1.488 -0.365 0.284 -1.306 0.962 1.510 ## Flavanoids Nonflavanoid phenols Proanthocyanins Color intensity Hue ## 1 1.024 -0.6081 1.199 0.450 0.368 ## 2 0.746 -0.8041 -0.489 -0.111 0.411 ## 3 1.189 -0.4200 1.920 0.466 0.324 ## 4 1.415 -1.0083 1.036 1.180 -0.420 ## 5 0.680 0.3411 0.470 -0.141 0.368 ## 6 1.325 -0.0653 0.712 0.853 0.411 ## OD280/OD315 of diluted wines Proline ## 1 2.031 1.060 ## 2 1.147 1.027 ## 3 0.777 1.304 ## 4 1.229 1.805 ## 5 0.405 0.188 ## 6 0.284 1.759 summary(wine_tx) ## Alcohol Malic acid Ash Alcalinity of ash ## Min. :-2.385 Min. :-2.493 Min. :-3.37 Min. :-2.870 ## 1st Qu.:-0.790 1st Qu.:-0.592 1st Qu.:-0.59 1st Qu.:-0.672 ## Median : 0.052 Median :-0.226 Median :-0.05 Median : 0.028 ## Mean : 0.000 Mean : 0.000 Mean : 0.00 Mean : 0.000 ## 3rd Qu.: 0.832 3rd Qu.: 0.889 3rd Qu.: 0.69 3rd Qu.: 0.617 ## Max. : 2.289 Max. : 2.005 Max. : 3.37 Max. : 2.950 ## Magnesium Total phenols Flavanoids Nonflavanoid phenols ## Min. :-3.25 Min. :-2.255 Min. :-1.785 Min. :-2.303 ## 1st Qu.:-0.85 1st Qu.:-0.873 1st Qu.:-0.805 1st Qu.:-0.705 ## Median : 0.04 Median : 0.131 Median : 0.146 Median :-0.065 ## Mean : 0.00 Mean : 0.000 Mean : 0.000 Mean : 0.000 ## 3rd Qu.: 0.66 3rd Qu.: 0.818 3rd Qu.: 0.853 3rd Qu.: 0.693 ## Max. : 2.77 Max. : 2.366 Max. : 2.788 Max. : 2.007 ## Proanthocyanins Color intensity Hue OD280/OD315 of diluted wines ## Min. :-2.477 Min. :-2.547 Min. :-2.12 Min. :-1.749 ## 1st Qu.:-0.547 1st Qu.:-0.775 1st Qu.:-0.76 1st Qu.:-0.975 ## Median : 0.018 Median : 0.040 Median : 0.04 Median : 0.179 ## Mean : 0.000 Mean : 0.000 Mean : 0.00 Mean : 0.000 ## 3rd Qu.: 0.681 3rd Qu.: 0.662 3rd Qu.: 0.71 3rd Qu.: 0.777 ## Max. : 2.863 Max. : 2.331 Max. : 3.22 Max. : 2.173 ## Proline ## Min. :-2.259 ## 1st Qu.:-0.750 ## Median :-0.022 ## Mean : 0.000 ## 3rd Qu.: 0.879 ## Max. : 2.085 "],["til20220603.html", "6.3 TIL20220603", " 6.3 TIL20220603 6.3.1 PCA 변환 모델 성능 비교 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } if(!require(mlbench)) { install.packages(&quot;mlbench&quot;); library(mlbench); } data(&quot;BostonHousing&quot;) bh &lt;- BostonHousing # EDA colSums(is.na(bh)) ## crim zn indus chas nox rm age dis rad tax ## 0 0 0 0 0 0 0 0 0 0 ## ptratio b lstat medv ## 0 0 0 0 summary(bh) ## crim zn indus chas nox ## Min. : 0.0 Min. : 0.0 Min. : 0.46 0:471 Min. :0.385 ## 1st Qu.: 0.1 1st Qu.: 0.0 1st Qu.: 5.19 1: 35 1st Qu.:0.449 ## Median : 0.3 Median : 0.0 Median : 9.69 Median :0.538 ## Mean : 3.6 Mean : 11.4 Mean :11.14 Mean :0.555 ## 3rd Qu.: 3.7 3rd Qu.: 12.5 3rd Qu.:18.10 3rd Qu.:0.624 ## Max. :89.0 Max. :100.0 Max. :27.74 Max. :0.871 ## rm age dis rad tax ## Min. :3.56 Min. : 2.9 Min. : 1.13 Min. : 1.00 Min. :187 ## 1st Qu.:5.89 1st Qu.: 45.0 1st Qu.: 2.10 1st Qu.: 4.00 1st Qu.:279 ## Median :6.21 Median : 77.5 Median : 3.21 Median : 5.00 Median :330 ## Mean :6.28 Mean : 68.6 Mean : 3.80 Mean : 9.55 Mean :408 ## 3rd Qu.:6.62 3rd Qu.: 94.1 3rd Qu.: 5.19 3rd Qu.:24.00 3rd Qu.:666 ## Max. :8.78 Max. :100.0 Max. :12.13 Max. :24.00 Max. :711 ## ptratio b lstat medv ## Min. :12.6 Min. : 0 Min. : 1.7 Min. : 5.0 ## 1st Qu.:17.4 1st Qu.:375 1st Qu.: 7.0 1st Qu.:17.0 ## Median :19.1 Median :391 Median :11.4 Median :21.2 ## Mean :18.5 Mean :357 Mean :12.7 Mean :22.5 ## 3rd Qu.:20.2 3rd Qu.:396 3rd Qu.:17.0 3rd Qu.:25.0 ## Max. :22.0 Max. :397 Max. :38.0 Max. :50.0 trainIndex &lt;- createDataPartition(bh$medv, p=.75, list=F) bhTrain &lt;- bh[ trainIndex, ] bhTest &lt;- bh[-trainIndex, ] bhTrainPP &lt;- preProcess(bhTrain[, -14], method = c(&quot;center&quot;, &quot;scale&quot;, &quot;pca&quot;)) newbhTrain &lt;- predict(bhTrainPP, bhTrain[, -14]) newbhTrain &lt;- cbind(newbhTrain, medv = bhTrain[, 14]) fitControl &lt;- trainControl(method = &quot;cv&quot;) rfFit &lt;- train(medv ~ ., data = newbhTrain, method = &quot;rf&quot;, trControl = fitControl, verbose = F) ## Error: Required packages are missing: randomForest bhTestPP &lt;- preProcess(bhTest[, -14], method = c(&quot;center&quot;, &quot;scale&quot;, &quot;pca&quot;)) newbhTest &lt;- predict(bhTestPP, bhTest[, -14]) newbhTest &lt;- cbind(newbhTest, medv = bhTest[, 14]) bhPred &lt;- predict(rfFit, newbhTest) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;rfFit&#39; not found caret::RMSE(bhPred, newbhTest$medv) ## Error in mean((pred - obs)^2, na.rm = na.rm): object &#39;bhPred&#39; not found "],["til20220604.html", "6.4 TIL20220604", " 6.4 TIL20220604 6.4.1 변수명으로 특정 컬럼 제거하기 df &lt;- data.frame( sex = c(&quot;M&quot;, &quot;F&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;), score = c(5,4,3,4,NA,5,4,NA,4,5) ); df$sex &lt;- as.factor(df$sex) df df2 &lt;- df[, -&quot;score&quot;] df2 &lt;- df[, -c(&quot;score&quot;)] # 01 colnames(df) df2 &lt;- df[, !(colnames(df) %in% &quot;score&quot;)] # 02 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } colIndex &lt;- which(colnames(df) %in% &quot;score&quot;) df2 &lt;- df %&gt;% select(-all_of(colIndex)) df2 6.4.2 결측치 처리 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } if(!require(RANN)) { install.packages(&quot;RANN&quot;); library(RANN); } df_nomiss &lt;- df %&gt;% filter(!is.na(score)) df_mean &lt;- mean(df_nomiss$score) df_nomiss2 &lt;- na.omit(df) df$sex &lt;- as.integer(df$sex) df_naknn &lt;- preProcess(df, method = &quot;knnImpute&quot;, k=3) df_new &lt;- predict(df_naknn, df); df_new "],["til20220605.html", "6.5 TIL20220605", " 6.5 TIL20220605 6.5.1 여러 패키지 한번에 읽어 오기 packages &lt;- c(&quot;dplyr&quot;, &quot;ggplot2&quot;) invisible( lapply(packages, require, character.only = T) ) 6.5.2 반복측정 분산분석 data &lt;- CO2 str(data) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 84 obs. of 5 variables: ## $ Plant : Ord.factor w/ 12 levels &quot;Qn1&quot;&lt;&quot;Qn2&quot;&lt;&quot;Qn3&quot;&lt;..: 1 1 1 1 1 1 1 2 2 2 ... ## $ Type : Factor w/ 2 levels &quot;Quebec&quot;,&quot;Mississippi&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Treatment: Factor w/ 2 levels &quot;nonchilled&quot;,&quot;chilled&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ conc : num 95 175 250 350 500 675 1000 95 175 250 ... ## $ uptake : num 16 30.4 34.8 37.2 35.3 39.2 39.7 13.6 27.3 37.1 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language uptake ~ conc | Plant ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Treatment * Type ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Ambient carbon dioxide concentration&quot; ## ..$ y: chr &quot;CO2 uptake rate&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(uL/L)&quot; ## ..$ y: chr &quot;(umol/m^2 s)&quot; data &lt;- subset(data, Treatment == &quot;chilled&quot;) data$conc &lt;- factor(data$conc) str(data) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 42 obs. of 5 variables: ## $ Plant : Ord.factor w/ 6 levels &quot;Qc1&quot;&lt;&quot;Qc3&quot;&lt;&quot;Qc2&quot;&lt;..: 1 1 1 1 1 1 1 3 3 3 ... ## $ Type : Factor w/ 2 levels &quot;Quebec&quot;,&quot;Mississippi&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Treatment: Factor w/ 1 level &quot;chilled&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ conc : Factor w/ 7 levels &quot;95&quot;,&quot;175&quot;,&quot;250&quot;,..: 1 2 3 4 5 6 7 1 2 3 ... ## $ uptake : num 14.2 24.1 30.3 34.6 32.5 35.4 38.7 9.3 27.3 35 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language uptake ~ conc | Plant ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Ambient carbon dioxide concentration&quot; ## ..$ y: chr &quot;CO2 uptake rate&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(uL/L)&quot; ## ..$ y: chr &quot;(umol/m^2 s)&quot; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Treatment * Type ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;FUN&quot;)=function (x) ## - attr(*, &quot;order.groups&quot;)= logi TRUE head(data) ## Grouped Data: uptake ~ conc | Plant ## Plant Type Treatment conc uptake ## 22 Qc1 Quebec chilled 95 14.2 ## 23 Qc1 Quebec chilled 175 24.1 ## 24 Qc1 Quebec chilled 250 30.3 ## 25 Qc1 Quebec chilled 350 34.6 ## 26 Qc1 Quebec chilled 500 32.5 ## 27 Qc1 Quebec chilled 675 35.4 data.aov &lt;- aov(uptake ~ Type * conc + Error(Plant/conc), data) summary(data.aov) ## ## Error: Plant ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Type 1 2667 2667 60.4 0.0015 ** ## Residuals 4 177 44 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Error: Plant:conc ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 6 1472 245.4 52.5 1.3e-12 *** ## Type:conc 6 429 71.5 15.3 3.7e-07 *** ## Residuals 24 112 4.7 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 boxplot(uptake ~ Type * conc, data, col = c(&quot;deepskyblue&quot;, &quot;violet&quot;), las = 2, cex.axis=0.7, xlab = &quot;&quot;, ylab = &quot;Carbon dioxide uptake rate&quot;) if(!require(HH)) { install.packages(&quot;HH&quot;); library(HH); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages interaction2wt(uptake ~ Type * conc, data) "],["til20220606.html", "6.6 TIL20220606", " 6.6 TIL20220606 6.6.1 이원분산분석 str(ToothGrowth) ## &#39;data.frame&#39;: 60 obs. of 3 variables: ## $ len : num 4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ... ## $ supp: Factor w/ 2 levels &quot;OJ&quot;,&quot;VC&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ dose: num 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ... data &lt;- ToothGrowth # 연속형 종속변수 ~ 범주형 독립변수 * 범주형 독립변수 data$dose &lt;- factor(data$dose, levels = c(0.5, 1.0, 2.0), labels = c(&quot;Low&quot;, &quot;Mid&quot;, &quot;High&quot;)) str(data) ## &#39;data.frame&#39;: 60 obs. of 3 variables: ## $ len : num 4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ... ## $ supp: Factor w/ 2 levels &quot;OJ&quot;,&quot;VC&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ dose: Factor w/ 3 levels &quot;Low&quot;,&quot;Mid&quot;,&quot;High&quot;: 1 1 1 1 1 1 1 1 1 1 ... if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } data %&gt;% group_by(supp, dose) %&gt;% summarise(Length = n(), Mean = mean(len), SD = round(sd(len),2)) ## # A tibble: 6 × 5 ## # Groups: supp [2] ## supp dose Length Mean SD ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 OJ Low 10 13.2 4.46 ## 2 OJ Mid 10 22.7 3.91 ## 3 OJ High 10 26.1 2.66 ## 4 VC Low 10 7.98 2.75 ## 5 VC Mid 10 16.8 2.52 ## 6 VC High 10 26.1 4.8 boxplot(data$len ~ data$supp) boxplot(data$len ~ data$dose) data.aov &lt;- aov(len ~ supp * dose, data = data) summary(data.aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## supp 1 205 205 15.57 0.00023 *** ## dose 2 2426 1213 92.00 &lt; 2e-16 *** ## supp:dose 2 108 54 4.11 0.02186 * ## Residuals 54 712 13 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 model.tables(data.aov, type = &quot;means&quot;) ## Tables of means ## Grand mean ## ## 18.8 ## ## supp ## supp ## OJ VC ## 20.7 17.0 ## ## dose ## dose ## Low Mid High ## 10.6 19.7 26.1 ## ## supp:dose ## dose ## supp Low Mid High ## OJ 13.23 22.70 26.06 ## VC 7.98 16.77 26.14 boxplot(len ~ supp * dose, data = data, col = c(&quot;deeppink&quot;, &quot;yellowgreen&quot;), las = 1, xlab = &quot;Vitamin C type&quot;, ylab = &quot;Tooth Growth&quot;) interaction.plot(x.factor = data$dose, trace.factor = data$supp, response = data$len, trace.label = &quot;Supplement&quot;, las = 1, type = &quot;b&quot;, pch = c(1, 19), col = c(&quot;blue&quot;, &quot;red&quot;), xlab = &quot;Vitamin C type&quot;, ylab = &quot;Tooth Growth&quot;) if(!require(gplots)) { install.packages(&quot;gplots&quot;); library(gplots); } interaction(data$supp, data$dose, sep = &quot; &quot;) ## [1] VC Low VC Low VC Low VC Low VC Low VC Low VC Low VC Low VC Low ## [10] VC Low VC Mid VC Mid VC Mid VC Mid VC Mid VC Mid VC Mid VC Mid ## [19] VC Mid VC Mid VC High VC High VC High VC High VC High VC High VC High ## [28] VC High VC High VC High OJ Low OJ Low OJ Low OJ Low OJ Low OJ Low ## [37] OJ Low OJ Low OJ Low OJ Low OJ Mid OJ Mid OJ Mid OJ Mid OJ Mid ## [46] OJ Mid OJ Mid OJ Mid OJ Mid OJ Mid OJ High OJ High OJ High OJ High ## [55] OJ High OJ High OJ High OJ High OJ High OJ High ## Levels: OJ Low VC Low OJ Mid VC Mid OJ High VC High plotmeans(len ~ interaction(supp, dose, sep = &quot; &quot;), data, col = c(&quot;red&quot;, &quot;green3&quot;), connect = list(c(1,3,5), c(2,4,6))) coplot(len ~ dose | supp, data, col = &quot;steelblue&quot;, pch = 19, panel = panel.smooth, lwd = 2, col.smooth = &quot;darkorange&quot;) if(!require(HH)) { install.packages(&quot;HH&quot;); library(HH); } interaction2wt(len ~ supp * dose, data = data) TukeyHSD(data.aov) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = len ~ supp * dose, data = data) ## ## $supp ## diff lwr upr p adj ## VC-OJ -3.7 -5.58 -1.82 0 ## ## $dose ## diff lwr upr p adj ## Mid-Low 9.13 6.36 11.90 0 ## High-Low 15.50 12.73 18.26 0 ## High-Mid 6.37 3.60 9.13 0 ## ## $`supp:dose` ## diff lwr upr p adj ## VC:Low-OJ:Low -5.25 -10.05 -0.452 0.024 ## OJ:Mid-OJ:Low 9.47 4.67 14.268 0.000 ## VC:Mid-OJ:Low 3.54 -1.26 8.338 0.264 ## OJ:High-OJ:Low 12.83 8.03 17.628 0.000 ## VC:High-OJ:Low 12.91 8.11 17.708 0.000 ## OJ:Mid-VC:Low 14.72 9.92 19.518 0.000 ## VC:Mid-VC:Low 8.79 3.99 13.588 0.000 ## OJ:High-VC:Low 18.08 13.28 22.878 0.000 ## VC:High-VC:Low 18.16 13.36 22.958 0.000 ## VC:Mid-OJ:Mid -5.93 -10.73 -1.132 0.007 ## OJ:High-OJ:Mid 3.36 -1.44 8.158 0.319 ## VC:High-OJ:Mid 3.44 -1.36 8.238 0.294 ## OJ:High-VC:Mid 9.29 4.49 14.088 0.000 ## VC:High-VC:Mid 9.37 4.57 14.168 0.000 ## VC:High-OJ:High 0.08 -4.72 4.878 1.000 "],["til20220607.html", "6.7 TIL20220607", " 6.7 TIL20220607 6.7.1 일표본 평균 검정 하나의 표본 데이터를 이용하여 모집단의 평균이 특정 값과 같은지를 검정한다. 표본집단이 특정 모집단과 일치하는지 혹은 그렇지 않을지를 알고 싶을 때 이용한다. if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } data &lt;- cats str(data) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ Sex: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Bwt: num 2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ... ## $ Hwt: num 7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ... # H0: 고양이의 몸무게는 2.6kg이다. data.mu &lt;- 2.6 data.mean &lt;- mean(data$Bwt) data.sd &lt;- sd(data$Bwt) 고양이의 모집단의 몸무게는 2.6kg이고, 표본집단의 평균은 2.724이고 표본편차는 0.485이다. t.test(x=data$Bwt, mu=2.6) ## ## One Sample t-test ## ## data: data$Bwt ## t = 3, df = 143, p-value = 0.003 ## alternative hypothesis: true mean is not equal to 2.6 ## 95 percent confidence interval: ## 2.64 2.80 ## sample estimates: ## mean of x ## 2.72 t &lt;- (data.mean - data.mu)/(data.sd/sqrt(length(data$Bwt))); t ## [1] 3.06 2*pt(t, length(data$Bwt)-1, lower.tail = F) ## [1] 0.00267 6.7.2 일원 분산 분석 data &lt;- InsectSprays str(data) ## &#39;data.frame&#39;: 72 obs. of 2 variables: ## $ count: num 10 7 20 14 14 12 10 23 17 20 ... ## $ spray: Factor w/ 6 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... data_aov &lt;- aov(count ~ spray, data) summary(data_aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## spray 5 2669 534 34.7 &lt;2e-16 *** ## Residuals 66 1015 15 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 집단간 통계적으로 유의한 차이가 있음을 확인, 어느 집단 간에 차이가 있는지는 사후 분석을 통해 확인한다. data_tukeyhsd &lt;- TukeyHSD(data_aov) plot(data_tukeyhsd, col = &quot;blue&quot;, las = 1) if(!require(multcomp)) { install.packages(&quot;multcomp&quot;); library(multcomp); } data_tukeyhsd &lt;- glht(model = data_aov, linfct = mcp(spray = &quot;Tukey&quot;)) cld(data_tukeyhsd, level = 0.05) ## A B C D E F ## &quot;b&quot; &quot;b&quot; &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;b&quot; plot(cld(data_tukeyhsd, level = 0.05), col=&quot;orange&quot;, las=1) "],["til20220608.html", "6.8 TIL20220608", " 6.8 TIL20220608 6.8.1 qcc if(!require(qcc)) { install.packages(&quot;qcc&quot;); library(qcc); } library(qcc) data(pistonrings) diameter &lt;- qcc.groups(pistonrings$diameter, pistonrings$sample) head(diameter) ## [,1] [,2] [,3] [,4] [,5] ## 1 74 74 74 74 74 ## 2 74 74 74 74 74 ## 3 74 74 74 74 74 ## 4 74 74 74 74 74 ## 5 74 74 74 74 74 ## 6 74 74 74 74 74 qcc(diameter[1:25,], type = &quot;xbar&quot;) ## List of 11 ## $ call : language qcc(data = diameter[1:25, ], type = &quot;xbar&quot;) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;diameter[1:25, ]&quot; ## $ data : num [1:25, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:25] 74 74 74 74 74 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 74 ## $ std.dev : num 0.00979 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 74 74 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; plot(q1, fill = FALSE) "],["til20220609.html", "6.9 TIL20220609", " 6.9 TIL20220609 6.9.1 결측치 대체 from Impute Missing Data - The Basics if(!require(imputeMissings)) { install.packages(&quot;imputeMissings&quot;); library(imputeMissings); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } #Make up some data income &lt;- round(runif(100, min = 35000, max = 350000), 0) age &lt;- round(runif(100, min=18, max=72), 0) myData &lt;- data.frame(age, income) noise &lt;- round(runif(100, min = 1500, max = 15000), 0) myData$income &lt;- myData$income + noise myData &lt;- arrange(myData, desc(income)) myData$education &lt;- as.factor(sample(c(&quot;High School&quot;, &quot;Bachelors&quot;, &quot;Masters&quot;, &quot;Doctorate&quot;), 100, replace = TRUE, prob =c(0.7, 0.15, 0.12, 0.03) )) head(myData, 5) ## age income education ## 1 45 360560 High School ## 2 48 353179 Masters ## 3 51 351269 High School ## 4 58 349628 High School ## 5 42 346662 High School #add some missing data this time myData$age[sample(1:nrow(myData),15)] &lt;- NA myData$income[sample(1:nrow(myData),10)] &lt;- NA myData$education[sample(1:nrow(myData),10)] &lt;- NA summary(myData) ## age income education ## Min. :18.0 Min. : 48512 Bachelors :10 ## 1st Qu.:30.0 1st Qu.:127780 Doctorate : 3 ## Median :41.0 Median :179634 High School:67 ## Mean :42.7 Mean :187404 Masters :10 ## 3rd Qu.:53.0 3rd Qu.:244028 NA&#39;s :10 ## Max. :72.0 Max. :360560 ## NA&#39;s :15 NA&#39;s :10 myDataImputed1 &lt;- impute(myData, method = &quot;median/mode&quot;) summary(myDataImputed1) ## age income education ## Min. :18.0 Min. : 48512 Bachelors :10 ## 1st Qu.:33.0 1st Qu.:133674 Doctorate : 3 ## Median :41.0 Median :179634 High School:77 ## Mean :42.4 Mean :186627 Masters :10 ## 3rd Qu.:51.0 3rd Qu.:237576 ## Max. :72.0 Max. :360560 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } myDataImputed2 &lt;- preProcess(myData[, c(&quot;income&quot;, &quot;age&quot;)], method = &quot;medianImpute&quot;) myDataImputed2 &lt;- predict(myDataImputed2, myData[, c(&quot;income&quot;, &quot;age&quot;)]) summary(myDataImputed2) ## income age ## Min. : 48512 Min. :18.0 ## 1st Qu.:133674 1st Qu.:33.0 ## Median :179634 Median :41.0 ## Mean :186627 Mean :42.4 ## 3rd Qu.:237576 3rd Qu.:51.0 ## Max. :360560 Max. :72.0 myDataImputed3 &lt;- preProcess(myData[, c(&quot;income&quot;, &quot;age&quot;)], method = &quot;knnImpute&quot;, k=2) myDataImputed3 &lt;- predict(myDataImputed3, myData[, c(&quot;income&quot;, &quot;age&quot;)]) Error in FUN(newX[, i], …) : cannot impute when all predictors are missing in the new data point 두 컬럼 모두 NA인 행이 있는 경우 위와 같은 에러가 발생한다. myBadDataRows &lt;- which(is.na(myData$income) &amp; is.na(myData$age)) myDataImputed3 &lt;- preProcess(myData[-myBadDataRows, c(&quot;income&quot;, &quot;age&quot;)],method = &quot;knnImpute&quot;, k=2) myDataImputed3 &lt;- predict(myDataImputed3,myData[-myBadDataRows, c(&quot;income&quot;, &quot;age&quot;)]) ## Error: package RANN is required summary(myDataImputed3) ## Length Class Mode ## dim 2 -none- numeric ## bc 0 -none- NULL ## yj 0 -none- NULL ## et 0 -none- NULL ## invHyperbolicSine 0 -none- NULL ## mean 2 -none- numeric ## std 2 -none- numeric ## ranges 0 -none- NULL ## rotation 0 -none- NULL ## method 4 -none- list ## thresh 1 -none- numeric ## pcaComp 0 -none- NULL ## numComp 0 -none- NULL ## ica 0 -none- NULL ## wildcards 2 -none- list ## k 1 -none- numeric ## knnSummary 1 -none- function ## bagImp 0 -none- NULL ## median 0 -none- NULL ## data 2 data.frame list ## rangeBounds 2 -none- numeric MICE (Multivariate Imputation via Chained Equations)를 이용해 결측치를 제거할 수 있다. if(!require(mice)) { install.packages(&quot;mice&quot;); library(mice); } myDataImputed4 &lt;- myData DataMICE &lt;- mice(myData) ## ## iter imp variable ## 1 1 age income education ## 1 2 age income education ## 1 3 age income education ## 1 4 age income education ## 1 5 age income education ## 2 1 age income education ## 2 2 age income education ## 2 3 age income education ## 2 4 age income education ## 2 5 age income education ## 3 1 age income education ## 3 2 age income education ## 3 3 age income education ## 3 4 age income education ## 3 5 age income education ## 4 1 age income education ## 4 2 age income education ## 4 3 age income education ## 4 4 age income education ## 4 5 age income education ## 5 1 age income education ## 5 2 age income education ## 5 3 age income education ## 5 4 age income education ## 5 5 age income education myDataImputed4 &lt;- complete(DataMICE) summary(myDataImputed4) ## age income education ## Min. :18.0 Min. : 48512 Bachelors :14 ## 1st Qu.:31.5 1st Qu.:126502 Doctorate : 3 ## Median :42.5 Median :179634 High School:73 ## Mean :42.8 Mean :185703 Masters :10 ## 3rd Qu.:53.0 3rd Qu.:240824 ## Max. :72.0 Max. :360560 "],["til20220610.html", "6.10 TIL20220610", " 6.10 TIL20220610 6.10.1 caret 기본 # 0. load data and packages needed ---- if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } data &lt;- penguins # 1. do eda ---- dim(data) ## [1] 344 8 str(data) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... summary(data) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.1 Min. :13.1 ## Chinstrap: 68 Dream :124 1st Qu.:39.2 1st Qu.:15.6 ## Gentoo :124 Torgersen: 52 Median :44.5 Median :17.3 ## Mean :43.9 Mean :17.1 ## 3rd Qu.:48.5 3rd Qu.:18.7 ## Max. :59.6 Max. :21.5 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :201 Mean :4202 Mean :2008 ## 3rd Qu.:213 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 # 2. split data set ---- trainIndex &lt;- createDataPartition(data$species, p =.7, list = F) trainSet &lt;- data[trainIndex,] testSet &lt;- data[-trainIndex,] # 3. preprocess data set # 3-1 handle NAs if(!require(imputeMissings)) { install.packages(&quot;imputeMissings&quot;); library(imputeMissings); } colSums(is.na(trainSet)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex year ## 0 0 9 0 trainSetPp &lt;- impute(trainSet) ## Error: ## ! Assigned data `object[[i]]` must be compatible with existing data. ## ℹ Error occurred for column `flipper_length_mm`. ## ✖ Can&#39;t convert from &lt;double&gt; to &lt;integer&gt; due to loss of precision. ## • Locations: 1. colSums(is.na(trainSetPp)) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;colSums&#39;: object &#39;trainSetPp&#39; not found trainSet %&gt;% summarise_if(is.numeric, mean, na.rm = T) %&gt;% print ## # A tibble: 1 × 5 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g year ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 43.9 17.2 200. 4196. 2008. trainSetPp %&gt;% summarise_if(is.numeric, mean, na.rm = T) %&gt;% print ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;print&#39;: object &#39;trainSetPp&#39; not found # 4. fit model ---- fitControl &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 5, repeats = 1) modelRF &lt;- train(species ~ ., trainSetPp, method = &quot;rf&quot;, trControl = fitControl, verbose = F) ## Error in eval(expr, p): object &#39;trainSetPp&#39; not found # 5. evaluate model testSetPp &lt;- impute(testSet) ## Error: ## ! Assigned data `object[[i]]` must be compatible with existing data. ## ℹ Error occurred for column `flipper_length_mm`. ## ✖ Can&#39;t convert from &lt;double&gt; to &lt;integer&gt; due to loss of precision. ## • Locations: 1. modelPred &lt;- predict(modelRF, testSetPp) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;modelRF&#39; not found confusionMatrix(modelPred, testSetPp$species) ## Error in confusionMatrix(modelPred, testSetPp$species): object &#39;modelPred&#39; not found "],["til20220611.html", "6.11 TIL20220611", " 6.11 TIL20220611 6.11.1 데이터프레임에서 컬럼 벡터로 추출 rm(list = ls()) if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } airquality %&gt;% select(Ozone) ## Ozone ## 1 41 ## 2 36 ## 3 12 ## 4 18 ## 5 NA ## 6 28 ## 7 23 ## 8 19 ## 9 8 ## 10 NA ## 11 7 ## 12 16 ## 13 11 ## 14 14 ## 15 18 ## 16 14 ## 17 34 ## 18 6 ## 19 30 ## 20 11 ## 21 1 ## 22 11 ## 23 4 ## 24 32 ## 25 NA ## 26 NA ## 27 NA ## 28 23 ## 29 45 ## 30 115 ## 31 37 ## 32 NA ## 33 NA ## 34 NA ## 35 NA ## 36 NA ## 37 NA ## 38 29 ## 39 NA ## 40 71 ## 41 39 ## 42 NA ## 43 NA ## 44 23 ## 45 NA ## 46 NA ## 47 21 ## 48 37 ## 49 20 ## 50 12 ## 51 13 ## 52 NA ## 53 NA ## 54 NA ## 55 NA ## 56 NA ## 57 NA ## 58 NA ## 59 NA ## 60 NA ## 61 NA ## 62 135 ## 63 49 ## 64 32 ## 65 NA ## 66 64 ## 67 40 ## 68 77 ## 69 97 ## 70 97 ## 71 85 ## 72 NA ## 73 10 ## 74 27 ## 75 NA ## 76 7 ## 77 48 ## 78 35 ## 79 61 ## 80 79 ## 81 63 ## 82 16 ## 83 NA ## 84 NA ## 85 80 ## 86 108 ## 87 20 ## 88 52 ## 89 82 ## 90 50 ## 91 64 ## 92 59 ## 93 39 ## 94 9 ## 95 16 ## 96 78 ## 97 35 ## 98 66 ## 99 122 ## 100 89 ## 101 110 ## 102 NA ## 103 NA ## 104 44 ## 105 28 ## 106 65 ## 107 NA ## 108 22 ## 109 59 ## 110 23 ## 111 31 ## 112 44 ## 113 21 ## 114 9 ## 115 NA ## 116 45 ## 117 168 ## 118 73 ## 119 NA ## 120 76 ## 121 118 ## 122 84 ## 123 85 ## 124 96 ## 125 78 ## 126 73 ## 127 91 ## 128 47 ## 129 32 ## 130 20 ## 131 23 ## 132 21 ## 133 24 ## 134 44 ## 135 21 ## 136 28 ## 137 9 ## 138 13 ## 139 46 ## 140 18 ## 141 13 ## 142 24 ## 143 16 ## 144 13 ## 145 23 ## 146 36 ## 147 7 ## 148 14 ## 149 30 ## 150 NA ## 151 14 ## 152 18 ## 153 20 airquality %&gt;% pull(Ozone) ## [1] 41 36 12 18 NA 28 23 19 8 NA 7 16 11 14 18 14 34 6 ## [19] 30 11 1 11 4 32 NA NA NA 23 45 115 37 NA NA NA NA NA ## [37] NA 29 NA 71 39 NA NA 23 NA NA 21 37 20 12 13 NA NA NA ## [55] NA NA NA NA NA NA NA 135 49 32 NA 64 40 77 97 97 85 NA ## [73] 10 27 NA 7 48 35 61 79 63 16 NA NA 80 108 20 52 82 50 ## [91] 64 59 39 9 16 78 35 66 122 89 110 NA NA 44 28 65 NA 22 ## [109] 59 23 31 44 21 9 NA 45 168 73 NA 76 118 84 85 96 78 73 ## [127] 91 47 32 20 23 21 24 44 21 28 9 13 46 18 13 24 16 13 ## [145] 23 36 7 14 30 NA 14 18 20 "],["til20220612.html", "6.12 TIL20220612", " 6.12 TIL20220612 6.12.1 분류 모델 비교 rm(list = ls()) packages &lt;- list(&quot;tidyverse&quot;, &quot;caret&quot;, &quot;palmerpenguins&quot;, &quot;imputeMissings&quot;) invisible( lapply(packages, require, character.only = T) ) data &lt;- penguins train_index &lt;- createDataPartition(data$sex, p = 0.75, list = F) train_set &lt;- data[train_index, ] test_set &lt;- data[-train_index, ] colSums(is.na(train_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex ## 2 2 9 train_set &lt;- impute(train_set) colSums(is.na(train_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex ## 0 0 0 model_list &lt;- c(&quot;rf&quot;, &quot;svmRadial&quot;, &quot;lda&quot;) model_fit &lt;- list() model_pred &lt;- list() colSums(is.na(test_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex ## 0 0 2 test_set &lt;- impute(test_set) colSums(is.na(test_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex ## 0 0 0 for(i in 1:length(model_list)) { model_fit[[i]] &lt;- train( species ~ ., train_set, method = model_list[i], verbose = F, ) model_pred[[i]] &lt;- predict(model_fit[[i]], test_set) } ## Error: Required packages are missing: kernlab resamps &lt;- resamples(list(RF = model_fit[[1]], SVM = model_fit[[2]], LDA = model_fit[[3]])) ## Error in model_fit[[2]]: subscript out of bounds summary(resamps) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;summary&#39;: object &#39;resamps&#39; not found for(i in 1:3) { print(confusionMatrix(model_pred[[i]], test_set$species)) } ## Confusion Matrix and Statistics ## ## Reference ## Prediction Adelie Chinstrap Gentoo ## Adelie 33 0 0 ## Chinstrap 0 21 0 ## Gentoo 1 0 30 ## ## Overall Statistics ## ## Accuracy : 0.988 ## 95% CI : (0.936, 1) ## No Information Rate : 0.4 ## P-Value [Acc &gt; NIR] : &lt;2e-16 ## ## Kappa : 0.982 ## ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: Adelie Class: Chinstrap Class: Gentoo ## Sensitivity 0.971 1.000 1.000 ## Specificity 1.000 1.000 0.982 ## Pos Pred Value 1.000 1.000 0.968 ## Neg Pred Value 0.981 1.000 1.000 ## Prevalence 0.400 0.247 0.353 ## Detection Rate 0.388 0.247 0.353 ## Detection Prevalence 0.388 0.247 0.365 ## Balanced Accuracy 0.985 1.000 0.991 ## Error in (function (cond) : error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;print&#39;: subscript out of bounds "],["til20220613.html", "6.13 TIL20220613", " 6.13 TIL20220613 6.13.1 ROC curve rm(list = ls()) packages &lt;- list(&quot;tidyverse&quot;, &quot;caret&quot;, &quot;palmerpenguins&quot;, &quot;imputeMissings&quot;) invisible( lapply(packages, require, character.only = T) ) data &lt;- penguins train_index &lt;- createDataPartition(data$species, p = 0.75, list = F) train_set &lt;- data[train_index, ] test_set &lt;- data[-train_index, ] colSums(is.na(train_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex ## 2 2 9 train_set &lt;- impute(train_set) colSums(is.na(train_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex ## 0 0 0 model_list &lt;- c(&quot;rf&quot;) model_fit &lt;- list() model_pred &lt;- list() colSums(is.na(test_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex ## 0 0 2 test_set &lt;- impute(test_set) ## Error: ## ! Assigned data `object[[i]]` must be compatible with existing data. ## ℹ Error occurred for column `flipper_length_mm`. ## ✖ Can&#39;t convert from &lt;double&gt; to &lt;integer&gt; due to loss of precision. ## • Locations: 1. colSums(is.na(test_set)) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex ## 0 0 2 model_fit &lt;- train( species ~ ., train_set, method = model_list, verbose = F, ) model_pred &lt;- predict(model_fit, test_set) confusionMatrix(model_pred, test_set$species) ## Error in table(data, reference, dnn = dnn, ...): all arguments must have the same length if(!require(ROCR)) { install.packages(&quot;ROCR&quot;); library(ROCR); } roc_pred_rf &lt;- prediction(as.numeric(model_pred), as.numeric(test_set$species)) "],["til20220614.html", "6.14 TIL20220614", " 6.14 TIL20220614 6.14.1 caret package를 이용한 시계열 데이터 분석 if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } 6.14.1.1 시계열 데이터 분석 정상성 시계열 데이터의 변화 패턴이 평균값을 중심으로 일정한 변동폭을 갖는 시계열 시간의 추이와 상관없이 평균과 분산이 일정한 데이터 비정상성 시계열 시간의 추이에 따라서 점진적으로 증가하는 추세 분산이 일정하지 않은 경우 6.14.1.2 시계열 분석 절차 시계열 자료 특성 분석 정상성 시계열 변환 차분과 변환을 통해 정상 시계열로 변환 모형 생성 미래 예측(forecasting) 6.14.1.3 정상성 평가 if(!require(tseries)) { install.packages(&quot;tseries&quot;); library(tseries); } adf.test(AirPassengers, k=12) ## ## Augmented Dickey-Fuller Test ## ## data: AirPassengers ## Dickey-Fuller = -2, Lag order = 12, p-value = 0.8 ## alternative hypothesis: stationary p값에 따라 귀무가설을 기각하지 못한다. 따라서 해당 데이터는 lag 12에서 정상성을 만족하지 못한다고 판단할 수 있다. "],["til20220615.html", "6.15 TIL20220615", " 6.15 TIL20220615 6.15.1 … "],["til20220616.html", "6.16 TIL20220616", " 6.16 TIL20220616 6.16.1 … "],["til20220617.html", "6.17 TIL20220617", " 6.17 TIL20220617 6.17.1 … "],["til20220618.html", "6.18 TIL20220618", " 6.18 TIL20220618 6.18.1 여기까지 "],["til20220619.html", "6.19 TIL20220619", " 6.19 TIL20220619 6.19.1 … "],["til20220620.html", "6.20 TIL20220620", " 6.20 TIL20220620 6.20.1 다시 시작 \\[ AOQ = \\frac{(N-m)\\times P \\times P_a}{N} \\] AOQ는 출하검사 이후 고객에게 전달되는 불량률를 나타낸다. "],["til20220621.html", "6.21 TIL20220621", " 6.21 TIL20220621 6.21.1 … "],["til20220622.html", "6.22 TIL20220622", " 6.22 TIL20220622 6.22.1 MBTI INFP https://namu.wiki/w/INFP 6.22.2 Cp, Cpk, Pp, Ppk \\[ Cp = \\frac{USL-LSL}{6\\sigma} \\] USL - LSL = 규격공차(Tolerance)라고 한다. \\({6\\sigma} = \\mu \\pm 3\\sigma\\) = 공정산포의 크기(Process variation)이라고 한다. 위 식은 정규분포를 따른다는 가정하에 계산된다. "],["til20220623.html", "6.23 TIL20220623", " 6.23 TIL20220623 ###… "],["til20220624.html", "6.24 TIL20220624", " 6.24 TIL20220624 6.24.1 액셀에서 화살표 동작 안할 때 Scroll Lock 키 눌러 졌는지 확인 할 것 "],["til20220625.html", "6.25 TIL20220625", " 6.25 TIL20220625 6.25.1 Anaconda | Data science technology for a better world https://www.anaconda.com/ 6.25.2 jupyter notebook 홈 디렉토리 변경 image "],["til20220626.html", "6.26 TIL20220626", " 6.26 TIL20220626 6.26.1 … "],["til20220627.html", "6.27 TIL20220627", " 6.27 TIL20220627 6.27.1 … "],["til20220628.html", "6.28 TIL20220628", " 6.28 TIL20220628 6.28.1 주피터 노트북 주요 단축키 주피터 노트북 주요 단축키 "],["til20220629.html", "6.29 TIL20220629", " 6.29 TIL20220629 6.29.1 구글 프레젠테이션 서식 복사 Ctrl + Alt + c 서식 복사 Ctrl + Alt + v 서식 붙여넣기 6.29.2 Rstudio + Python "],["til20220630.html", "6.30 TIL20220630", " 6.30 TIL20220630 ###… "],["년-07월.html", "7 2022년 07월 ", " 7 2022년 07월 "],["til20220701.html", "7.1 TIL20220701", " 7.1 TIL20220701 7.1.1 … "],["til20220702.html", "7.2 TIL20220702", " 7.2 TIL20220702 7.2.1 … "],["til20220703.html", "7.3 TIL20220703", " 7.3 TIL20220703 7.3.1 … "],["til20220704.html", "7.4 TIL20220704", " 7.4 TIL20220704 7.4.1 … "],["til20220705.html", "7.5 TIL20220705", " 7.5 TIL20220705 7.5.1 방황 중 … "],["til20220706.html", "7.6 TIL20220706", " 7.6 TIL20220706 7.6.1 Powershell conda miniconda 삭제 후 파워셀에서 에러 출력될 때 https://stackoverflow.com/questions/65133472/after-removing-anaconda3-i-still-get-these-errors-in-powershell "],["til20220707.html", "7.7 TIL20220707", " 7.7 TIL20220707 7.7.1 크롬 전체 화면 주소창에 커서 두고 F11 "],["til20220708.html", "7.8 TIL20220708", " 7.8 TIL20220708 7.8.1 주피터 랩에서 이미지 결과 복사 Shift + 우측버튼 + 이미지 복사 "],["til20220709.html", "7.9 TIL20220709", " 7.9 TIL20220709 7.9.1 … "],["til20220710.html", "7.10 TIL20220710", " 7.10 TIL20220710 7.10.1 … "],["til20220711.html", "7.11 TIL20220711", " 7.11 TIL20220711 7.11.1 통계학 라이팅게일, 장미도표 리터러리 다이제스트, 표본추출의 편중현상(selection bias) 7.11.2 통계자료 질적 변수 (qualitative variable) 명목형 자료 (nominal data) 순서형 자료 (ordinal data) 양적 변수 (quantitative variable) 이산형 자료 (discrete data) 연속형 자료 (continous data) "],["til20220712.html", "7.12 TIL20220712", " 7.12 TIL20220712 7.12.1 "],["til20220713.html", "7.13 TIL20220713", " 7.13 TIL20220713 7.13.1 R에서 숫자 콤파(,), 자리수 지정하기 # 콤마 찍기, big.interval로 간격 조절 format(567890, big.mark = &#39;,&#39;) ## [1] &quot;567,890&quot; format(567890, big.mark = &#39;,&#39;, big.interval = 2) ## [1] &quot;56,78,90&quot; # 자리수 지정 format(1:10) ## [1] &quot; 1&quot; &quot; 2&quot; &quot; 3&quot; &quot; 4&quot; &quot; 5&quot; &quot; 6&quot; &quot; 7&quot; &quot; 8&quot; &quot; 9&quot; &quot;10&quot; format(1:10, width = 4) ## [1] &quot; 1&quot; &quot; 2&quot; &quot; 3&quot; &quot; 4&quot; &quot; 5&quot; &quot; 6&quot; &quot; 7&quot; &quot; 8&quot; &quot; 9&quot; &quot; 10&quot; # digits 전체 자릿수, nsmall 소수점 이하 자릿수 format(c(7, 15.8), digits = 2, nsmall = 2) ## [1] &quot; 7.00&quot; &quot;15.80&quot; 7.13.2 rmarkdown, 폰트 색깔 지정 &lt;span style = &quot;color: red;&quot;&gt;**_DANGER_**: This is a warning.&lt;/span&gt; DANGER: This is a warning. 7.13.3 YAML에 오늘 날짜 지정하기 date: &quot;2022-09-01&quot; "],["til20220714.html", "7.14 TIL20220714", " 7.14 TIL20220714 7.14.1 … https://teachablemachine.withgoogle.com/ "],["til20220715.html", "7.15 TIL20220715", " 7.15 TIL20220715 7.15.1 … "],["til20220716.html", "7.16 TIL20220716", " 7.16 TIL20220716 7.16.1 … "],["til20220717.html", "7.17 TIL20220717", " 7.17 TIL20220717 7.17.1 digilog "],["til20220718.html", "7.18 TIL20220718", " 7.18 TIL20220718 7.18.1 R 그래프에서 축과 그래프 사이 마진 줄이는 법 x &lt;- 1:5 y &lt;- 1:5 plot(x,y) plot(x,y, xaxs = &quot;i&quot;, yaxs = &quot;i&quot;) "],["til20220719.html", "7.19 TIL20220719", " 7.19 TIL20220719 7.19.1 … "],["til20220720.html", "7.20 TIL20220720", " 7.20 TIL20220720 7.20.1 … "],["til20220721.html", "7.21 TIL20220721", " 7.21 TIL20220721 7.21.1 … "],["til20220722.html", "7.22 TIL20220722", " 7.22 TIL20220722 7.22.1 … "],["til20220723.html", "7.23 TIL20220723", " 7.23 TIL20220723 7.23.1 t 통계량 \\[ t = \\frac{\\bar X - \\mu}{\\frac{S}{\\sqrt n}} \\] "],["til20220724.html", "7.24 TIL20220724", " 7.24 TIL20220724 7.24.1 … "],["til20220725.html", "7.25 TIL20220725", " 7.25 TIL20220725 7.25.1 … "],["til20220726.html", "7.26 TIL20220726", " 7.26 TIL20220726 7.26.1 … "],["til20220726-1.html", "7.27 TIL20220726", " 7.27 TIL20220726 7.27.1 Shiny app 공유 방법 7.27.1.1 스크립트로 공유 runApp(“app-name”) runUrl(“url-address”) runGitHub(“repository-name”, “user-name”) runGist(“gist-number”) 7.27.1.2 web page로 공유 shinyapps.io Shiny Server RStudio Connect "],["til20220728.html", "7.28 TIL20220728", " 7.28 TIL20220728 7.28.1 … "],["til20220728-1.html", "7.29 TIL20220728", " 7.29 TIL20220728 7.29.1 … "],["til20220730.html", "7.30 TIL20220730", " 7.30 TIL20220730 7.30.1 … "],["til20220731.html", "7.31 TIL20220731", " 7.31 TIL20220731 7.31.1 … "],["년-08월.html", "8 2022년 08월 ", " 8 2022년 08월 "],["til20220801.html", "8.1 TIL20220801", " 8.1 TIL20220801 8.1.1 … "],["til20220802.html", "8.2 TIL20220802", " 8.2 TIL20220802 8.2.1 shinyjs, 10초마다 페이지 자동 갱신 shinyjs::runjs( &quot;function reload_page() { window.location.reload(); setTimeout(reload_page, 10000); } setTimeout(reload_page, 10000); &quot;) "],["til20220803.html", "8.3 TIL20220803", " 8.3 TIL20220803 8.3.1 … "],["til20220804.html", "8.4 TIL20220804", " 8.4 TIL20220804 8.4.1 … "],["til20220805.html", "8.5 TIL20220805", " 8.5 TIL20220805 8.5.1 … "],["til20220806.html", "8.6 TIL20220806", " 8.6 TIL20220806 8.6.1 … "],["til20220807.html", "8.7 TIL20220807", " 8.7 TIL20220807 8.7.1 … "],["til20220808.html", "8.8 TIL20220808", " 8.8 TIL20220808 8.8.1 … "],["til20220809.html", "8.9 TIL20220809", " 8.9 TIL20220809 8.9.1 TIL 파일 일년치 만들기 months = [&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;] last_day = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31] for month in months: for i in range(1, last_day[months.index(month)]+1): filename = &quot;%02d-%s-%02d.Rmd&quot; % (months.index(month)+1, month, i) with open(filename, &quot;w&quot;, encoding=&quot;utf8&quot;) as Rmd_file: Rmd_file.write(&quot;## TIL2022%02d%02d\\n&quot; % (months.index(month)+1, i)) Rmd_file.write(&quot;\\n### ...\\n&quot;) "],["til20220810.html", "8.10 TIL20220810", " 8.10 TIL20220810 8.10.1 Polynomila data fit https://arachnoid.com/polysolve/ "],["til20220811.html", "8.11 TIL20220811", " 8.11 TIL20220811 8.11.1 train test split in python from sklearn.model_selection import train_test_split # load sample dataset = load_data() data = dataset[&#39;data&#39;] target = dataset[&#39;target&#39;] # train_test_split x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, shuffle=True, stratify=target, random_state=34) "],["til20220812.html", "8.12 TIL20220812", " 8.12 TIL20220812 8.12.1 R : How to detect and fix abnormal values on plot? https://stackoverflow.com/questions/44713124/r-how-to-detect-and-fix-abnormal-values-on-plot # df &lt;- read.csv(url(&quot;https://raw.githubusercontent.com/ieatbaozi/R-Practicing/master/example.csv&quot;),header = TRUE,stringsAsFactors = FALSE) # df$DateTime &lt;- as.POSIXct(df$DateTime) # if(!require(AnomalyDetection)) { install.packages(&quot;AnomalyDetection&quot;); # library(AnomalyDetection); } # # ADtest &lt;- AnomalyDetectionTs(df, max_anoms=0.1, direction=&#39;both&#39;, plot=TRUE) # ADtest$plot "],["til20220813.html", "8.13 TIL20220813", " 8.13 TIL20220813 8.13.1 Tidy Anomaly Detection using R (1/2) source : https://towardsdatascience.com/tidy-anomaly-detection-using-r-82a0c776d523 if(!require(anomalize)) { install.packages(&quot;anomalize&quot;); library(anomalize); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(quantmod)) { install.packages(&quot;quantmod&quot;); library(quantmod); } Samsung &lt;- getSymbols(Symbols = &quot;005930.KS&quot;, src = &quot;yahoo&quot;, from = Sys.Date() - 180, to = Sys.Date(), auto.assign = FALSE) colnames(Samsung) &lt;- c(&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;, &#39;adjusted&#39;) chartSeries(Samsung, up.col = &quot;red&quot;, dn.col = &quot;blue&quot;, theme = &quot;white&quot;) addMACD() addBBands() addSMA(); addSMA(30, col = &quot;blue&quot;) "],["til20220814.html", "8.14 TIL20220814", " 8.14 TIL20220814 8.14.1 Tidy Anomaly Detection using R (2/2) source : https://towardsdatascience.com/tidy-anomaly-detection-using-r-82a0c776d523 if(!require(anomalize)) { install.packages(&quot;anomalize&quot;); library(anomalize); } if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } if(!require(quantmod)) { install.packages(&quot;quantmod&quot;); library(quantmod); } Samsung &lt;- getSymbols(Symbols = &quot;005930.KS&quot;, src = &quot;yahoo&quot;, from = Sys.Date() - 730, to = Sys.Date(), auto.assign = FALSE) colnames(Samsung) &lt;- c(&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;, &#39;adjusted&#39;) # class(Samsung) ss_df &lt;- as.data.frame(Samsung) ss_ts &lt;- ss_df %&gt;% rownames_to_column() %&gt;% as.tibble() %&gt;% mutate(date = as.Date(rowname)) %&gt;% select(&quot;date&quot;, &quot;close&quot;) ss_ts %&gt;% time_decompose(close, method = &quot;stl&quot;, frequency = &quot;auto&quot;, trend = &quot;auto&quot;) %&gt;% anomalize(remainder, method = &quot;gesd&quot;, alpha = 0.05, max_anoms = 0.2) %&gt;% plot_anomaly_decomposition() "],["til20220815.html", "8.15 TIL20220815", " 8.15 TIL20220815 8.15.1 파이썬으로 폴더 생성 import os try: os.mkdir(&#39;python&#39;) except FileExistsError as e: print(e) print(&quot;프로그램을 종료합니다.&quot;) "],["til20220816.html", "8.16 TIL20220816", " 8.16 TIL20220816 8.16.1 반복적용 purr - map() source - https://www.youtube.com/watch?v=zqL_lBQjFUE if(!require(purrr)) { install.packages(&quot;purrr&quot;); library(purrr); } exams &lt;- list(s1 = c(78, 89, 91, 85, 95, 98), s2 = c(85, 86, 97, 99, 90), s3 = c(98, 96, 89, 90, 93, 85, 92), s4 = c(98, 96, 91, 88, 93, 99)) exams ## $s1 ## [1] 78 89 91 85 95 98 ## ## $s2 ## [1] 85 86 97 99 90 ## ## $s3 ## [1] 98 96 89 90 93 85 92 ## ## $s4 ## [1] 98 96 91 88 93 99 map(.x = exams, .f=mean) ## $s1 ## [1] 89.3 ## ## $s2 ## [1] 91.4 ## ## $s3 ## [1] 91.9 ## ## $s4 ## [1] 94.2 lapply(exams, mean) ## $s1 ## [1] 89.3 ## ## $s2 ## [1] 91.4 ## ## $s3 ## [1] 91.9 ## ## $s4 ## [1] 94.2 map_df(exams, mean) ## # A tibble: 1 × 4 ## s1 s2 s3 s4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 89.3 91.4 91.9 94.2 map_dbl(exams, mean) ## s1 s2 s3 s4 ## 89.3 91.4 91.9 94.2 map_dbl(exams, mean, trim = 0.3) ## s1 s2 s3 s4 ## 90.0 91.0 91.7 94.5 exams %&gt;% map_dbl(mean) ## s1 s2 s3 s4 ## 89.3 91.4 91.9 94.2 exams %&gt;% map(range) ## $s1 ## [1] 78 98 ## ## $s2 ## [1] 85 99 ## ## $s3 ## [1] 85 98 ## ## $s4 ## [1] 88 99 exams %&gt;% map(range) %&gt;% map_dbl(diff) ## s1 s2 s3 s4 ## 20 14 13 11 exams %&gt;% map(function(x) x * 1.1) ## $s1 ## [1] 85.8 97.9 100.1 93.5 104.5 107.8 ## ## $s2 ## [1] 93.5 94.6 106.7 108.9 99.0 ## ## $s3 ## [1] 107.8 105.6 97.9 99.0 102.3 93.5 101.2 ## ## $s4 ## [1] 107.8 105.6 100.1 96.8 102.3 108.9 exams %&gt;% map(~.x*1.1) ## $s1 ## [1] 85.8 97.9 100.1 93.5 104.5 107.8 ## ## $s2 ## [1] 93.5 94.6 106.7 108.9 99.0 ## ## $s3 ## [1] 107.8 105.6 97.9 99.0 102.3 93.5 101.2 ## ## $s4 ## [1] 107.8 105.6 100.1 96.8 102.3 108.9 exams %&gt;% map(~.*1.1) ## $s1 ## [1] 85.8 97.9 100.1 93.5 104.5 107.8 ## ## $s2 ## [1] 93.5 94.6 106.7 108.9 99.0 ## ## $s3 ## [1] 107.8 105.6 97.9 99.0 102.3 93.5 101.2 ## ## $s4 ## [1] 107.8 105.6 100.1 96.8 102.3 108.9 fruits &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Strawberry&quot;) fruits %&gt;% map_chr(paste, &quot;Juice&quot;, sep=&quot;-&quot;) ## [1] &quot;Apple-Juice&quot; &quot;Banana-Juice&quot; &quot;Strawberry-Juice&quot; fruits %&gt;% map_chr(~paste(.x, &quot;Juice&quot;, sep=&quot;-&quot;)) ## [1] &quot;Apple-Juice&quot; &quot;Banana-Juice&quot; &quot;Strawberry-Juice&quot; lst &lt;- list(list(num=1:3, letters[1:3]), list(num=101:103, chr = letters[4:6]), list(), list(num=c(9,99), chr = letters[7:9])) lst ## [[1]] ## [[1]]$num ## [1] 1 2 3 ## ## [[1]][[2]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## ## ## [[2]] ## [[2]]$num ## [1] 101 102 103 ## ## [[2]]$chr ## [1] &quot;d&quot; &quot;e&quot; &quot;f&quot; ## ## ## [[3]] ## list() ## ## [[4]] ## [[4]]$num ## [1] 9 99 ## ## [[4]]$chr ## [1] &quot;g&quot; &quot;h&quot; &quot;i&quot; lst %&gt;% map(&quot;num&quot;) ## [[1]] ## [1] 1 2 3 ## ## [[2]] ## [1] 101 102 103 ## ## [[3]] ## NULL ## ## [[4]] ## [1] 9 99 lst %&gt;% map(&quot;num&quot;, .default = &quot;???&quot;) ## [[1]] ## [1] 1 2 3 ## ## [[2]] ## [1] 101 102 103 ## ## [[3]] ## [1] &quot;???&quot; ## ## [[4]] ## [1] 9 99 lst %&gt;% map(&quot;chr&quot;, .default = NA) ## [[1]] ## [1] NA ## ## [[2]] ## [1] &quot;d&quot; &quot;e&quot; &quot;f&quot; ## ## [[3]] ## [1] NA ## ## [[4]] ## [1] &quot;g&quot; &quot;h&quot; &quot;i&quot; lst %&gt;% map(2, .default = NA) ## [[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## ## [[2]] ## [1] &quot;d&quot; &quot;e&quot; &quot;f&quot; ## ## [[3]] ## [1] NA ## ## [[4]] ## [1] &quot;g&quot; &quot;h&quot; &quot;i&quot; lst %&gt;% map(c(2,2)) ## [[1]] ## [1] &quot;b&quot; ## ## [[2]] ## [1] &quot;e&quot; ## ## [[3]] ## NULL ## ## [[4]] ## [1] &quot;h&quot; lst %&gt;% map_chr(c(2,2), .default = NA) ## [1] &quot;b&quot; &quot;e&quot; NA &quot;h&quot; lst %&gt;% map(list(&quot;num&quot;, 3)) ## [[1]] ## [1] 3 ## ## [[2]] ## [1] 103 ## ## [[3]] ## NULL ## ## [[4]] ## NULL lst %&gt;% map_int(list(&quot;num&quot;, 3), .default = NA) ## [1] 3 103 NA NA str(USArrests) ## &#39;data.frame&#39;: 50 obs. of 4 variables: ## $ Murder : num 13.2 10 8.1 8.8 9 7.9 3.3 5.9 15.4 17.4 ... ## $ Assault : int 236 263 294 190 276 204 110 238 335 211 ... ## $ UrbanPop: int 58 48 80 50 91 78 77 72 80 60 ... ## $ Rape : num 21.2 44.5 31 19.5 40.6 38.7 11.1 15.8 31.9 25.8 ... USArrests %&gt;% map_dbl(mean) ## Murder Assault UrbanPop Rape ## 7.79 170.76 65.54 21.23 USArrests %&gt;% # map_dbl(range) map(range) ## $Murder ## [1] 0.8 17.4 ## ## $Assault ## [1] 45 337 ## ## $UrbanPop ## [1] 32 91 ## ## $Rape ## [1] 7.3 46.0 USArrests %&gt;% map_dfr(range) ## # A tibble: 2 × 4 ## Murder Assault UrbanPop Rape ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 0.8 45 32 7.3 ## 2 17.4 337 91 46 str(mtcars) ## &#39;data.frame&#39;: 32 obs. of 11 variables: ## $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... ## $ disp: num 160 160 108 258 360 ... ## $ hp : num 110 110 93 110 175 105 245 62 95 123 ... ## $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## $ wt : num 2.62 2.88 2.32 3.21 3.44 ... ## $ qsec: num 16.5 17 18.6 19.4 17 ... ## $ vs : num 0 0 1 1 0 1 0 1 1 1 ... ## $ am : num 1 1 1 0 0 0 0 0 0 0 ... ## $ gear: num 4 4 4 3 3 3 3 4 4 4 ... ## $ carb: num 4 4 1 1 2 1 4 2 2 4 ... mtcars %&gt;% split(.$am) ## $`0` ## mpg cyl disp hp drat wt qsec vs am gear carb ## Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## Duster 360 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## Merc 240D 24.4 4 147 62 3.69 3.19 20.0 1 0 4 2 ## Merc 230 22.8 4 141 95 3.92 3.15 22.9 1 0 4 2 ## Merc 280 19.2 6 168 123 3.92 3.44 18.3 1 0 4 4 ## Merc 280C 17.8 6 168 123 3.92 3.44 18.9 1 0 4 4 ## Merc 450SE 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 ## Merc 450SL 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 ## Merc 450SLC 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 ## Lincoln Continental 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 ## Chrysler Imperial 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 ## Toyota Corona 21.5 4 120 97 3.70 2.46 20.0 1 0 3 1 ## Dodge Challenger 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 ## AMC Javelin 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 ## Camaro Z28 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 ## Pontiac Firebird 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 ## ## $`1` ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 ## Fiat 128 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.57 14.6 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 models &lt;- mtcars %&gt;% split(.$am) %&gt;% map(~lm(mpg ~ wt, data = .)) models ## $`0` ## ## Call: ## lm(formula = mpg ~ wt, data = .) ## ## Coefficients: ## (Intercept) wt ## 31.42 -3.79 ## ## ## $`1` ## ## Call: ## lm(formula = mpg ~ wt, data = .) ## ## Coefficients: ## (Intercept) wt ## 46.29 -9.08 model0 &lt;- summary(models$`0`) str(model0) ## List of 11 ## $ call : language lm(formula = mpg ~ wt, data = .) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language mpg ~ wt ## .. ..- attr(*, &quot;variables&quot;)= language list(mpg, wt) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;mpg&quot; &quot;wt&quot; ## .. .. .. ..$ : chr &quot;wt&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;wt&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x7f89f54ac608&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(mpg, wt) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;mpg&quot; &quot;wt&quot; ## $ residuals : Named num [1:19] 2.156 0.307 -0.217 -3.6 5.061 ... ## ..- attr(*, &quot;names&quot;)= chr [1:19] &quot;Hornet 4 Drive&quot; &quot;Hornet Sportabout&quot; &quot;Valiant&quot; &quot;Duster 360&quot; ... ## $ coefficients : num [1:2, 1:4] 31.416 -3.786 2.947 0.767 10.661 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;wt&quot; ## .. ..$ : chr [1:4] &quot;Estimate&quot; &quot;Std. Error&quot; &quot;t value&quot; &quot;Pr(&gt;|t|)&quot; ## $ aliased : Named logi [1:2] FALSE FALSE ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;wt&quot; ## $ sigma : num 2.53 ## $ df : int [1:3] 2 17 2 ## $ r.squared : num 0.589 ## $ adj.r.squared: num 0.565 ## $ fstatistic : Named num [1:3] 24.4 1 17 ## ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;value&quot; &quot;numdf&quot; &quot;dendf&quot; ## $ cov.unscaled : num [1:2, 1:2] 1.3584 -0.3465 -0.3465 0.0919 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;wt&quot; ## .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;wt&quot; ## - attr(*, &quot;class&quot;)= chr &quot;summary.lm&quot; names(model0) ## [1] &quot;call&quot; &quot;terms&quot; &quot;residuals&quot; &quot;coefficients&quot; ## [5] &quot;aliased&quot; &quot;sigma&quot; &quot;df&quot; &quot;r.squared&quot; ## [9] &quot;adj.r.squared&quot; &quot;fstatistic&quot; &quot;cov.unscaled&quot; model0$r.squared ## [1] 0.589 models %&gt;% map(summary) %&gt;% map_dbl(function(x) x$r.squared) ## 0 1 ## 0.589 0.826 models %&gt;% map(summary) %&gt;% map_dbl(~.x$r.squared) # map_dbl(~.$r.squared) ## 0 1 ## 0.589 0.826 models %&gt;% map(summary) %&gt;% map_dbl(&quot;r.squared&quot;) ## 0 1 ## 0.589 0.826 mtcars %&gt;% split(.$am) %&gt;% map(~lm(mpg ~ wt, data = .)) %&gt;% map(summary) %&gt;% map_dbl(&quot;r.squared&quot;) ## 0 1 ## 0.589 0.826 "],["til20220817.html", "8.17 TIL20220817", " 8.17 TIL20220817 8.17.1 … https://www.youtube.com/watch?v=B-El9v5KQ5k 사람들에게 필요로 하는 재미있는 공간 제공. 오프라인 매장은 온라인 매장과 연결되어 있어… "],["til20220818.html", "8.18 TIL20220818", " 8.18 TIL20220818 8.18.1 데이터 기반 업무수행 https://www.youtube.com/watch?v=t_V4iH4emQg&amp;t=202s 데이터를 근거로 커뮤니케이션 &amp; 결정 ’내가 해봐서 아는데’에서 자신의 의견을 뒷바침하는 데이터를 가지고 설득하는 것 "],["til20220819.html", "8.19 TIL20220819", " 8.19 TIL20220819 8.19.1 … "],["til20220820.html", "8.20 TIL20220820", " 8.20 TIL20220820 8.20.1 … "],["til20220821.html", "8.21 TIL20220821", " 8.21 TIL20220821 8.21.1 … "],["til20220822.html", "8.22 TIL20220822", " 8.22 TIL20220822 8.22.1 addition of list in python def addition(a, b): return a + b a = [1,2,3] b = [4,5,6] c = map(addition, a, b) print(list(c)) "],["til20220823.html", "8.23 TIL20220823", " 8.23 TIL20220823 8.23.1 … "],["til20220824.html", "8.24 TIL20220824", " 8.24 TIL20220824 8.24.1 how to check dataframe, rdd in spark, python x = sc.parallelize([1,2,3]) # create(initialize) RDD y = x.flatMap(lambda x: (x, x*2)) from pyspark.sql import DataFrame from pyspark.rdd import RDD print(isinstance(x, DataFrame)) print(isinstance(x, RDD)) 8.24.2 union is a narrow transformation Why is union() a narrow transformation and intersection() is a wide transformation in spark? https://stackoverflow.com/questions/70643086/why-is-union-a-narrow-transformation-and-intersection-is-a-wide-transformati 8.24.3 colab, python, 경로 공백 및 특수문자 배제할 것. "],["til20220825.html", "8.25 TIL20220825", " 8.25 TIL20220825 8.25.1 Spark in R package update 필요 if(!require(sparklyr)) { install.packages(&quot;sparklyr&quot;); library(sparklyr); } 8.25.2 pyspark를 Windows에 설치하기 구글검색 요. Java 설치 Hadoop, Spark 설치 winutils 설치 환경설정 pyspark 설치 8.25.3 java 미설치 시 에러 Java gateway process exited before sending its port number 8.25.4 current working directory in python import os os.getcwd() 8.25.5 .show() b = a.withColumn(&quot;Price&quot;, col(&quot;Price&quot;)*1.05) b.show() b_drop = b.drop(&quot;Price&quot;) 정상출력 b = a.withColumn(&quot;Price&quot;, col(&quot;Price&quot;)*1.05).show() b_drop = b.drop(&quot;Price&quot;) 오류출력 AttributeError: &#39;NoneType&#39; object has no attribute &#39;drop&#39; EOF "],["til20220826.html", "8.26 TIL20220826", " 8.26 TIL20220826 8.26.1 install pytorch in windows10 local 상황에 맞춰 명령어 수행 "],["til20220827.html", "8.27 TIL20220827", " 8.27 TIL20220827 8.27.1 Spark in R Refer to https://spark.rstudio.com/ 8.27.1.1 Install the package install.packages(&quot;sparklyr&quot;) 8.27.1.2 Install Spark locally &gt; library(sparkly) &gt; spark_install() Installing Spark 2.4.3 for Hadoop 2.7 or later. Downloading from: - &#39;https://archive.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz&#39; Installing to: - &#39;C:\\Users\\User\\AppData\\Local/spark/spark-2.4.3-bin-hadoop2.7&#39; trying URL &#39;https://archive.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz&#39; Content type &#39;application/x-gzip&#39; length 229988313 bytes (219.3 MB) downloaded 219.3 MB Installation complete. &gt; 8.27.1.3 Connect and disconnect to Spark library(sparklyr) # connect sc &lt;- spark_connect(master = &quot;local&quot;) # disconnect spark_disconnect(sc) 8.27.1.4 Read Data Using copy_to() from R to Spark tbl_mtcars &lt;- copy_to(sc, mtcars, &quot;spark_mtcars&quot;) Connections in Environment panel 8.27.1.5 Prepare Data With dplyr SQL Spark’s feature transformers Using dplyr delay &lt;- flight_tbl %&gt;% group_by(tailnum) %&gt;% summarise( count = n(), dist = mean(distance, na.rm = T), delay = mean(arr_delay, na.rm = T) ) %&gt;% filter(count &gt; 20, dist &lt;2000, !is.na(delay)) delay &gt; show_query(delay) &lt;SQL&gt; SELECT * FROM ( SELECT `tailnum`, COUNT(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay` FROM `spark_flights` GROUP BY `tailnum` ) `q01` WHERE (`count` &gt; 20.0) AND (`dist` &lt; 2000.0) AND (NOT((`delay` IS NULL))) &gt; Using SQL library(DBI) dbGetQuery(sc, &quot; select carrier, sched_dep_time, dep_time, dep_delay from spark_flights limit 5&quot;) carrier sched_dep_time dep_time dep_delay 1 UA 515 517 2 2 UA 529 533 4 3 AA 540 542 2 4 B6 545 544 -1 5 DL 600 554 -6 Using Feature Transformer flight_tbl %&gt;% ft_binarizer(&quot;dep_delay&quot;, &quot;over_one&quot;, threshold = 1) %&gt;% select(dep_delay, over_one) %&gt;% head(5) dep_delay over_one &lt;dbl&gt; &lt;dbl&gt; 1 2 1 2 4 1 3 2 1 4 -1 0 5 -6 0 "],["til20220828.html", "8.28 TIL20220828", " 8.28 TIL20220828 8.28.1 Model wiht Sparklyr # setup Spark ---- library(sparklyr) sc &lt;- spark_connect(master = &#39;local&#39;) # copy data from R to Spark ---- mtcars_tbl &lt;- copy_to(sc, mtcars, overwrite = TRUE) # split train and test dataset ---- partitions &lt;- mtcars_tbl %&gt;% select(mpg, wt, cyl) %&gt;% sdf_random_split(training = .5, test = .5, seed = 1099) # fit model ---- fit &lt;- partitions $training %&gt;% ml_linear_regression(mpg ~ .) fit ## check model ---- summary(fit) # use the model ---- pred &lt;- ml_predict(fit, partitions$test) head(pred) "],["til20220829.html", "8.29 TIL20220829", " 8.29 TIL20220829 8.29.1 … "],["til20220830.html", "8.30 TIL20220830", " 8.30 TIL20220830 8.30.1 엑셀에서 R로 복사하여 붙여넣기 install.packages(&quot;datapasta&quot;) in “Addins” "],["til20220831.html", "8.31 TIL20220831", " 8.31 TIL20220831 8.31.1 mutate in dplyr mutate(.data, ...) # S3 method for data.frame mutate( .data, ..., .keep = c(&quot;all&quot;, &quot;used&quot;, &quot;unused&quot;, &quot;none&quot;), .before = NULL, .after = NULL ) transmute(.data, ...) .keep This argument allows you to control which columns from .data are retained in the output: all, the default, retains all variables. used keeps any variables used to make new variables; it’s useful for checking your work as it displays inputs and outputs side-by-side. unused keeps only existing variables not used to make new variables. none, only keeps grouping keys (like transmute()). df &lt;- data.frame( cate = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;), price = c(1,2,3,4) ) df ## cate price ## 1 A 1 ## 2 B 2 ## 3 C 3 ## 4 D 4 df_all &lt;- df %&gt;% mutate(new_cate = paste0(&quot;New_&quot;, cate), .keep = &quot;all&quot;) df_all ## cate price new_cate ## 1 A 1 New_A ## 2 B 2 New_B ## 3 C 3 New_C ## 4 D 4 New_D df_used &lt;- df %&gt;% mutate(new_cate = paste0(&quot;New_&quot;, cate), .keep = &quot;used&quot;) df_used ## cate new_cate ## 1 A New_A ## 2 B New_B ## 3 C New_C ## 4 D New_D df_unused &lt;- df %&gt;% mutate(new_cate = paste0(&quot;New_&quot;, cate), .keep = &quot;unused&quot;) df_unused ## price new_cate ## 1 1 New_A ## 2 2 New_B ## 3 3 New_C ## 4 4 New_D df_none &lt;- df %&gt;% mutate(new_cate = paste0(&quot;New_&quot;, cate), .keep = &quot;none&quot;) df_none ## new_cate ## 1 New_A ## 2 New_B ## 3 New_C ## 4 New_D "],["년-09월.html", "9 2022년 09월 ", " 9 2022년 09월 "],["til20220901.html", "9.1 TIL20220901", " 9.1 TIL20220901 9.1.1 시계열 그래프 if(!require(fpp3)) { install.packages(&quot;fpp3&quot;); library(fpp3); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//Rtmpp2vgBE/downloaded_packages if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } mn &lt;- read.csv(&quot;metaverse_nft.csv&quot;, header = T) ## Error in file(file, &quot;rt&quot;): cannot open the connection list(head(mn), tail(mn)) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;mn&#39; not found mn$date &lt;- as_date(mn$date) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;as_date&#39;: object &#39;mn&#39; not found mn_ts &lt;- mn %&gt;% mutate(Month = yearweek(date)) %&gt;% as_tsibble(index = Month) ## Error in mutate(., Month = yearweek(date)): object &#39;mn&#39; not found mn_ts %&gt;% gg_season(metaverse, labels = &quot;both&quot;) + labs(y = &quot;hits&quot;, title = &quot;Google Trends&quot;) ## Error in is_tsibble(x): object &#39;mn_ts&#39; not found mn_ts %&gt;% mutate(Month = yearweek(date)) %&gt;% gg_season(nft, labels = &quot;both&quot;) + labs(y = &quot;hits&quot;, title = &quot;Google Trends&quot;) ## Error in mutate(., Month = yearweek(date)): object &#39;mn_ts&#39; not found "],["til20220902.html", "9.2 TIL20220902", " 9.2 TIL20220902 9.2.1 … "],["til20220903.html", "9.3 TIL20220903", " 9.3 TIL20220903 9.3.1 … "],["til20220904.html", "9.4 TIL20220904", " 9.4 TIL20220904 9.4.1 … "],["til20220905.html", "9.5 TIL20220905", " 9.5 TIL20220905 9.5.1 … "],["til20220906.html", "9.6 TIL20220906", " 9.6 TIL20220906 9.6.1 … "],["til20220907.html", "9.7 TIL20220907", " 9.7 TIL20220907 9.7.1 … "],["til20220908.html", "9.8 TIL20220908", " 9.8 TIL20220908 9.8.1 … "],["til20220909.html", "9.9 TIL20220909", " 9.9 TIL20220909 9.9.1 … "],["til20220910.html", "9.10 TIL20220910", " 9.10 TIL20220910 9.10.1 … "],["til20220911.html", "9.11 TIL20220911", " 9.11 TIL20220911 9.11.1 … "],["til20220912.html", "9.12 TIL20220912", " 9.12 TIL20220912 9.12.1 … "],["til20220913.html", "9.13 TIL20220913", " 9.13 TIL20220913 9.13.1 … "],["til20220914.html", "9.14 TIL20220914", " 9.14 TIL20220914 9.14.1 … "],["til20220915.html", "9.15 TIL20220915", " 9.15 TIL20220915 9.15.1 … "],["til20220916.html", "9.16 TIL20220916", " 9.16 TIL20220916 9.16.1 … "],["til20220917.html", "9.17 TIL20220917", " 9.17 TIL20220917 9.17.1 … "],["til20220918.html", "9.18 TIL20220918", " 9.18 TIL20220918 9.18.1 … "],["til20220919.html", "9.19 TIL20220919", " 9.19 TIL20220919 9.19.1 … "],["til20220920.html", "9.20 TIL20220920", " 9.20 TIL20220920 9.20.1 … "],["til20220921.html", "9.21 TIL20220921", " 9.21 TIL20220921 9.21.1 … "],["til20220922.html", "9.22 TIL20220922", " 9.22 TIL20220922 9.22.1 … "],["til20220923.html", "9.23 TIL20220923", " 9.23 TIL20220923 9.23.1 … "],["til20220924.html", "9.24 TIL20220924", " 9.24 TIL20220924 9.24.1 … "],["til20220925.html", "9.25 TIL20220925", " 9.25 TIL20220925 9.25.1 … "],["til20220926.html", "9.26 TIL20220926", " 9.26 TIL20220926 9.26.1 … "],["til20220927.html", "9.27 TIL20220927", " 9.27 TIL20220927 9.27.1 … "],["til20220928.html", "9.28 TIL20220928", " 9.28 TIL20220928 9.28.1 … "],["til20220929.html", "9.29 TIL20220929", " 9.29 TIL20220929 9.29.1 … "],["til20220930.html", "9.30 TIL20220930", " 9.30 TIL20220930 9.30.1 … "],["년-10월.html", "10 2022년 10월 ", " 10 2022년 10월 "],["til20221001.html", "10.1 TIL20221001", " 10.1 TIL20221001 10.1.1 … "],["til20221002.html", "10.2 TIL20221002", " 10.2 TIL20221002 10.2.1 … "],["til20221003.html", "10.3 TIL20221003", " 10.3 TIL20221003 10.3.1 … "],["til20221004.html", "10.4 TIL20221004", " 10.4 TIL20221004 10.4.1 … "],["til20221005.html", "10.5 TIL20221005", " 10.5 TIL20221005 10.5.1 … "],["til20221006.html", "10.6 TIL20221006", " 10.6 TIL20221006 10.6.1 … "],["til20221007.html", "10.7 TIL20221007", " 10.7 TIL20221007 10.7.1 … "],["til20221008.html", "10.8 TIL20221008", " 10.8 TIL20221008 10.8.1 … "],["til20221009.html", "10.9 TIL20221009", " 10.9 TIL20221009 10.9.1 … "],["til20221010.html", "10.10 TIL20221010", " 10.10 TIL20221010 10.10.1 … "],["til20221011.html", "10.11 TIL20221011", " 10.11 TIL20221011 10.11.1 … "],["til20221012.html", "10.12 TIL20221012", " 10.12 TIL20221012 10.12.1 … "],["til20221013.html", "10.13 TIL20221013", " 10.13 TIL20221013 10.13.1 … "],["til20221014.html", "10.14 TIL20221014", " 10.14 TIL20221014 10.14.1 … "],["til20221015.html", "10.15 TIL20221015", " 10.15 TIL20221015 10.15.1 … "],["til20221016.html", "10.16 TIL20221016", " 10.16 TIL20221016 10.16.1 … "],["til20221017.html", "10.17 TIL20221017", " 10.17 TIL20221017 10.17.1 … "],["til20221018.html", "10.18 TIL20221018", " 10.18 TIL20221018 10.18.1 … "],["til20221019.html", "10.19 TIL20221019", " 10.19 TIL20221019 10.19.1 … "],["til20221020.html", "10.20 TIL20221020", " 10.20 TIL20221020 10.20.1 … "],["til20221021.html", "10.21 TIL20221021", " 10.21 TIL20221021 10.21.1 … "],["til20221022.html", "10.22 TIL20221022", " 10.22 TIL20221022 10.22.1 … "],["til20221023.html", "10.23 TIL20221023", " 10.23 TIL20221023 10.23.1 … "],["til20221024.html", "10.24 TIL20221024", " 10.24 TIL20221024 10.24.1 … "],["til20221025.html", "10.25 TIL20221025", " 10.25 TIL20221025 10.25.1 … "],["til20221026.html", "10.26 TIL20221026", " 10.26 TIL20221026 10.26.1 … "],["til20221027.html", "10.27 TIL20221027", " 10.27 TIL20221027 10.27.1 … "],["til20221028.html", "10.28 TIL20221028", " 10.28 TIL20221028 10.28.1 … "],["til20221029.html", "10.29 TIL20221029", " 10.29 TIL20221029 10.29.1 … "],["til20221030.html", "10.30 TIL20221030", " 10.30 TIL20221030 10.30.1 … "],["til20221031.html", "10.31 TIL20221031", " 10.31 TIL20221031 10.31.1 … "],["년-11월.html", "11 2022년 11월 ", " 11 2022년 11월 "],["til20221101.html", "11.1 TIL20221101", " 11.1 TIL20221101 11.1.1 … "],["til20221102.html", "11.2 TIL20221102", " 11.2 TIL20221102 11.2.1 … "],["til20221103.html", "11.3 TIL20221103", " 11.3 TIL20221103 11.3.1 … "],["til20221104.html", "11.4 TIL20221104", " 11.4 TIL20221104 11.4.1 … "],["til20221105.html", "11.5 TIL20221105", " 11.5 TIL20221105 11.5.1 … "],["til20221106.html", "11.6 TIL20221106", " 11.6 TIL20221106 11.6.1 … "],["til20221107.html", "11.7 TIL20221107", " 11.7 TIL20221107 11.7.1 … "],["til20221108.html", "11.8 TIL20221108", " 11.8 TIL20221108 11.8.1 … "],["til20221109.html", "11.9 TIL20221109", " 11.9 TIL20221109 11.9.1 … "],["til20221110.html", "11.10 TIL20221110", " 11.10 TIL20221110 11.10.1 … "],["til20221111.html", "11.11 TIL20221111", " 11.11 TIL20221111 11.11.1 … "],["til20221112.html", "11.12 TIL20221112", " 11.12 TIL20221112 11.12.1 … "],["til20221113.html", "11.13 TIL20221113", " 11.13 TIL20221113 11.13.1 … "],["til20221114.html", "11.14 TIL20221114", " 11.14 TIL20221114 11.14.1 … "],["til20221115.html", "11.15 TIL20221115", " 11.15 TIL20221115 11.15.1 … "],["til20221116.html", "11.16 TIL20221116", " 11.16 TIL20221116 11.16.1 … "],["til20221117.html", "11.17 TIL20221117", " 11.17 TIL20221117 11.17.1 … "],["til20221118.html", "11.18 TIL20221118", " 11.18 TIL20221118 11.18.1 … "],["til20221119.html", "11.19 TIL20221119", " 11.19 TIL20221119 11.19.1 … "],["til20221120.html", "11.20 TIL20221120", " 11.20 TIL20221120 11.20.1 … "],["til20221121.html", "11.21 TIL20221121", " 11.21 TIL20221121 11.21.1 … "],["til20221122.html", "11.22 TIL20221122", " 11.22 TIL20221122 11.22.1 … "],["til20221123.html", "11.23 TIL20221123", " 11.23 TIL20221123 11.23.1 … "],["til20221124.html", "11.24 TIL20221124", " 11.24 TIL20221124 11.24.1 … "],["til20221125.html", "11.25 TIL20221125", " 11.25 TIL20221125 11.25.1 … "],["til20221126.html", "11.26 TIL20221126", " 11.26 TIL20221126 11.26.1 … "],["til20221127.html", "11.27 TIL20221127", " 11.27 TIL20221127 11.27.1 … "],["til20221128.html", "11.28 TIL20221128", " 11.28 TIL20221128 11.28.1 … "],["til20221129.html", "11.29 TIL20221129", " 11.29 TIL20221129 11.29.1 … "],["til20221130.html", "11.30 TIL20221130", " 11.30 TIL20221130 11.30.1 … "],["년-12월.html", "12 2022년 12월 ", " 12 2022년 12월 "],["til20221201.html", "12.1 TIL20221201", " 12.1 TIL20221201 12.1.1 … "],["til20221202.html", "12.2 TIL20221202", " 12.2 TIL20221202 12.2.1 … "],["til20221203.html", "12.3 TIL20221203", " 12.3 TIL20221203 12.3.1 … "],["til20221204.html", "12.4 TIL20221204", " 12.4 TIL20221204 12.4.1 … "],["til20221205.html", "12.5 TIL20221205", " 12.5 TIL20221205 12.5.1 … "],["til20221206.html", "12.6 TIL20221206", " 12.6 TIL20221206 12.6.1 … "],["til20221207.html", "12.7 TIL20221207", " 12.7 TIL20221207 12.7.1 … "],["til20221208.html", "12.8 TIL20221208", " 12.8 TIL20221208 12.8.1 … "],["til20221209.html", "12.9 TIL20221209", " 12.9 TIL20221209 12.9.1 … "],["til20221210.html", "12.10 TIL20221210", " 12.10 TIL20221210 12.10.1 … "],["til20221211.html", "12.11 TIL20221211", " 12.11 TIL20221211 12.11.1 … "],["til20221212.html", "12.12 TIL20221212", " 12.12 TIL20221212 12.12.1 … "],["til20221213.html", "12.13 TIL20221213", " 12.13 TIL20221213 12.13.1 … "],["til20221214.html", "12.14 TIL20221214", " 12.14 TIL20221214 12.14.1 … "],["til20221215.html", "12.15 TIL20221215", " 12.15 TIL20221215 12.15.1 … "],["til20221216.html", "12.16 TIL20221216", " 12.16 TIL20221216 12.16.1 … "],["til20221217.html", "12.17 TIL20221217", " 12.17 TIL20221217 12.17.1 … "],["til20221218.html", "12.18 TIL20221218", " 12.18 TIL20221218 12.18.1 … "],["til20221219.html", "12.19 TIL20221219", " 12.19 TIL20221219 12.19.1 … "],["til20221220.html", "12.20 TIL20221220", " 12.20 TIL20221220 12.20.1 … "],["til20221221.html", "12.21 TIL20221221", " 12.21 TIL20221221 12.21.1 … "],["til20221222.html", "12.22 TIL20221222", " 12.22 TIL20221222 12.22.1 … "],["til20221223.html", "12.23 TIL20221223", " 12.23 TIL20221223 12.23.1 … "],["til20221224.html", "12.24 TIL20221224", " 12.24 TIL20221224 12.24.1 … "],["til20221225.html", "12.25 TIL20221225", " 12.25 TIL20221225 12.25.1 … "],["til20221226.html", "12.26 TIL20221226", " 12.26 TIL20221226 12.26.1 … "],["til20221227.html", "12.27 TIL20221227", " 12.27 TIL20221227 12.27.1 … "],["til20221228.html", "12.28 TIL20221228", " 12.28 TIL20221228 12.28.1 … "],["til20221229.html", "12.29 TIL20221229", " 12.29 TIL20221229 12.29.1 … "],["til20221230.html", "12.30 TIL20221230", " 12.30 TIL20221230 12.30.1 … "],["til20221231.html", "12.31 TIL20221231", " 12.31 TIL20221231 12.31.1 … "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

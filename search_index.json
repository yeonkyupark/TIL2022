[["index.html", "Today I Learned in 2022 시작하며", " Today I Learned in 2022 PARK Yeonkyu 2022-04-04 시작하며 1/01 github에 매일매일 잔디 심고 있었다. 2/18 github를 청소해 보겠다고 repo를 전체 삭제했다. 잔디도 깔끔하게 같이 사라졌다. 다시 시작하는걸로... "],["년-1월.html", "1 2022년 1월", " 1 2022년 1월 2월 18일, 날짜도 참… 심어 두었던 잔디를 모두 날려 먹었다. "],["년-2월.html", "2 2022년 2월 ", " 2 2022년 2월 "],["til20220201.html", "2.1 TIL20220201", " 2.1 TIL20220201 "],["til20220202.html", "2.2 TIL20220202", " 2.2 TIL20220202 "],["til20220203.html", "2.3 TIL20220203", " 2.3 TIL20220203 "],["til20220204.html", "2.4 TIL20220204", " 2.4 TIL20220204 "],["til20220205.html", "2.5 TIL20220205", " 2.5 TIL20220205 "],["til20220206.html", "2.6 TIL20220206", " 2.6 TIL20220206 "],["til20220207.html", "2.7 TIL20220207", " 2.7 TIL20220207 "],["til20220208.html", "2.8 TIL20220208", " 2.8 TIL20220208 "],["til20220209.html", "2.9 TIL20220209", " 2.9 TIL20220209 "],["til20220210.html", "2.10 TIL20220210", " 2.10 TIL20220210 "],["til20220211.html", "2.11 TIL20220211", " 2.11 TIL20220211 "],["til20220212.html", "2.12 TIL20220212", " 2.12 TIL20220212 "],["til20220213.html", "2.13 TIL20220213", " 2.13 TIL20220213 "],["til20220214.html", "2.14 TIL20220214", " 2.14 TIL20220214 "],["til20220215.html", "2.15 TIL20220215", " 2.15 TIL20220215 "],["til20220216.html", "2.16 TIL20220216", " 2.16 TIL20220216 "],["til20220217.html", "2.17 TIL20220217", " 2.17 TIL20220217 "],["til20220218.html", "2.18 TIL20220218", " 2.18 TIL20220218 2.18.1 github repo 삭제하면 잔디도 죽는다 사용하던 github repo를 모두 삭제했다. repo가 삭제되면 심어 두었던 잔디도 같이 죽는다는 것을 알게 되었다. 덕분에 깨끗한 마음으로 새로 시작할 수 있을 것 같다 ‘^’ 2.18.2 bookdown으로 블로그 전환 jekyll로 잘 운영하던 블로그를 bookdown으로 이사, 일단 가볍고 문서 작성하기 편하고 체계적이고, 무엇보다 기존 repo 싹 날려서 그렇다. RStudio, Bookdown, Github pages 등으로 검색하면 여러 정보를 얻을 수 있다. 중간중간 설명이 필요한 부분도 있지만 우선 여기 참조하면 세팅할 수 있다. "],["til20220219.html", "2.19 TIL20220219", " 2.19 TIL20220219 2.19.1 netlify와 bookdown 연동 https://bookdown.org/yihui/blogdown/netlify.html "],["til20220220.html", "2.20 TIL20220220", " 2.20 TIL20220220 2.20.1 netlify 자동 배포 1 rendering 안해도 netlify에 deploy되나 (’’ ?) 우선 rendering된 docs 폴더를 netlify에 연결하는 걸로 하자. 2.20.2 netlify 자동 배포 2 https://www.emilhvitfeldt.com/post/bookdown-netlify-github-actions/ 1차 실패 2차 진행 중 … 3차, 편한 방법을 찾자. "],["til20220221.html", "2.21 TIL20220221", " 2.21 TIL20220221 2.21.1 Github Actions를 이용한 자동 배포 세상은 넓고 똑똑한 사람은 참 많은 것 같다. ref to: How to publish bookdown projects with GitHub Actions on GitHub Pages 2.21.2 실습 RStudio에서 bookdown project를 하나 만든다. GitHub에서 Repository를 하나 만든다. 둘이 연결한다. GitHub Actions를 위한 workflows를 생성한다. usethis::use_github_action(url = &quot;https://raw.githubusercontent.com/ropenscilabs/actions_sandbox/main/.github/workflows/deploy_bookdown.yml&quot;) 배포할 브랜치를 변경해 준다. 코드 업데이트 후 정상 동작 확인한다. ! 주의 deploy_bookdown.yml의 branch 이름 확인할 것, 최근에 master에서 main으로 변경됨 bookdown의 _bookdown.yml의 output_dir과 deploy_bookdown.yml의 build_dir 일치시킬 것 repository에 build_dir(_book)가 없으면 만들어 둘 것 "],["til20220222.html", "2.22 TIL20220222", " 2.22 TIL20220222 2.22.1 code snippet in R RStudio에서 snippet 설정을 한다. Tools → Global Options → Code → Editing → Snippets image # snippet 등록 snippet myggplot # 코드 작성 시 반드시 tab으로 띄워쓰기 할 것 p &lt;- ggplot(data = ${1:데이터}, aes(x=${2:변수1}, y=${3:변수2}, col=${4:범주1}, fill=${5:범주2})) + geom_${6:그래프종류}() + labs(title=&quot;${7:그래프제목}&quot;, x=&quot;${8:x축}&quot;, y=&quot;${9:y축}&quot;) + theme_bw() p "],["til20220223.html", "2.23 TIL20220223", " 2.23 TIL20220223 2.23.1 rstudio.cloud PAT 업데이트 https://stackoverflow.com/questions/66065099/how-to-update-github-authentification-token-on-rstudio-to-match-the-new-policy credentials::set_gethub_pat() image 위 코드로 해결함. 2.23.2 파비콘 만들기 https://www.favicon-generator.org "],["til20220224.html", "2.24 TIL20220224", " 2.24 TIL20220224 2.24.1 RStudio + bookdown + github 배포하기 GitHub Repository 생성하기 생성된 Git Repo로 RStudio 빈 Project 생성하기 Bookdown Project 생성하기 생성된 Project GitHub에 올리기 git checkout main git add . git commit -m &#39;1st commit on main&#39; git push origin main GitHub Action workflow 생성하기 gh-pages 브랜치를 생성한다. git checkout --orphan gh-pages git rm -rf . git commit --allow-empty -m &#39;1st commit on gh-pages&#39; git push origin gh-pages git checkout main RStudio Console에서 Workflow를 생성한다. usethis::use_github_action(url = &quot;https://raw.githubusercontent.com/ropenscilabs/actions_sandbox/main/.github/workflows/deploy_bookdown.yml&quot;) 수정된 파일 GitHub에 올리기 Workflow 및 배포된 페이지 확인하기 page 생성/수정 후 정상동작 확인하기 https://yeonkyupark.github.io/Rdataanalysis/ "],["til20220225.html", "2.25 TIL20220225", " 2.25 TIL20220225 2.25.1 R에서 데이터 읽어 오기 csv 포멧으로 사용하는게 가장 편하고, 파일 형식이 다른 경우 csv 파일 형태로 변환하여 사용하길 추천. 여건이 되지 않으면 구글링해서 해당 포멧 처리하는 것으로, 하지만 가능하면 엑셀로 기본 전처리 후 csv로 변환하여 사용. read.csv(file, header = TRUE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;, fill = TRUE, comment.char = &quot;&quot;, ...) "],["til20220226.html", "2.26 TIL20220226", " 2.26 TIL20220226 2.26.1 데이터 훑어보기 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;) library(palmerpenguins) } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages 우선 데이터 구조는 str() 일반적으로 summary()를 통해 수치 연산 결과를 전체적인 모습을 살펴볼 수 있다. # base package summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 skimr 패키지의 skim()을 통해 유사한 수치연산 결과를 보다 가독성이 좋은 형태로 출력해 준다. if(!require(skimr)) { install.packages(&quot;skimr&quot;) library(skimr) } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages skim(penguins) TABLE 2.1: Data summary Name penguins Number of rows 344 Number of columns 8 _______________________ Column type frequency: factor 3 numeric 5 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts species 0 1.00 FALSE 3 Ade: 152, Gen: 124, Chi: 68 island 0 1.00 FALSE 3 Bis: 168, Dre: 124, Tor: 52 sex 11 0.97 FALSE 2 mal: 168, fem: 165 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist bill_length_mm 2 0.99 43.92 5.46 32.1 39.23 44.45 48.5 59.6 ▃▇▇▆▁ bill_depth_mm 2 0.99 17.15 1.97 13.1 15.60 17.30 18.7 21.5 ▅▅▇▇▂ flipper_length_mm 2 0.99 200.92 14.06 172.0 190.00 197.00 213.0 231.0 ▂▇▃▅▂ body_mass_g 2 0.99 4201.75 801.95 2700.0 3550.00 4050.00 4750.0 6300.0 ▃▇▆▃▂ year 0 1.00 2008.03 0.82 2007.0 2007.00 2008.00 2009.0 2009.0 ▇▁▇▁▇ "],["til20220227.html", "2.27 TIL20220227", " 2.27 TIL20220227 2.27.1 GitHub에 파일 올리기 연습용 csv 파일 올리기, GitHub Edit 창에 Drop&amp;Drop으로 등록할 수 있다. Sample_w_Header.csv Sample_wo_Header.csv sample &lt;- read.csv(&quot;https://github.com/yeonkyupark/TIL2022/files/8148798/Sample_w_Header.csv&quot;, fileEncoding=&quot;UTF-8-BOM&quot;) colnames(sample) ## [1] &quot;Time&quot; &quot;LSL&quot; &quot;USL&quot; &quot;Measure&quot; &quot;Result&quot; sample &lt;- read.csv(&quot;https://github.com/yeonkyupark/TIL2022/files/8148798/Sample_w_Header.csv&quot;) colnames(sample) ## [1] &quot;Time&quot; &quot;LSL&quot; &quot;USL&quot; &quot;Measure&quot; &quot;Result&quot; 읽어들인 첫번째 데이터가 깨지는 경우 인코딩을 확인해 본다. R을 이용하여 CSV 파일을 읽을 때 첫번째 문자가 깨지는 오류 해결 방법 2.27.2 엑셀 if 함수 정리 엑셀 IF 함수 사용법 및 예제 정리 :: 논리함수 =IF(AND(D2&gt;=C2, D2&lt;=B2), &quot;PASS&quot;, &quot;FAIL&quot;) "],["til20220228.html", "2.28 TIL20220228", " 2.28 TIL20220228 2.28.1 데이터 수집 통계데이터분석 - 데이터 수집1 2.28.1.1 데이터 수집 원천 출판물(publication) 실험(experiment) 관찰(observation) 서베이(servey) 2.28.1.2 표본과 모집단 표본, 데이터 수집에 포한된 참여자의 집단, 기술통계(descriptive statistics) 모집단, 우리가 궁극적으로 결론을 도출하고자 하는 대상이 되는 전체 집단, 추론통계(inferential statistics) 2.28.1.3 표본의 선정 판단표본(judgment sample) 편의표본(convenience sample) 무작위표본(random sample) 2.28.1.4 측정척도 측정(measurement), 데이터 항목의 속성에 숫자를 부여하는 과정 척도(scale), 측정을 위하여 사용되는 도구 2.28.1.5 척도의 종류 명목척도(nominal scale) 서열척도(ordinal scale) 간격척도(interval scale) 비율척도(ratio scale) https://www.youtube.com/watch?v=Z4Hn4LoNuE8&amp;list=PLY0OaF78qqGAxKX91WuRigHpwBU0C2SB_↩︎ "],["년-3월.html", "3 2022년 3월 ", " 3 2022년 3월 "],["til20220301.html", "3.1 TIL20220301", " 3.1 TIL20220301 3.1.1 데이터 요약 3.1.1.1 범주형 변수 요약 기술통계와 추론통계, 대부분은 모집단을 설명하는 추론통계이지만 모집단을 잘 설명하기 위해서는 표본집단을 잘 이해사고 적절한 통계기법을 선택하는 것이 중요하다. 3.1.1.1.1 빈도표 if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } ## Loading required package: MASS str(survey) ## &#39;data.frame&#39;: 237 obs. of 12 variables: ## $ Sex : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 1 2 2 2 2 1 2 1 2 2 ... ## $ Wr.Hnd: num 18.5 19.5 18 18.8 20 18 17.7 17 20 18.5 ... ## $ NW.Hnd: num 18 20.5 13.3 18.9 20 17.7 17.7 17.3 19.5 18.5 ... ## $ W.Hnd : Factor w/ 2 levels &quot;Left&quot;,&quot;Right&quot;: 2 1 2 2 2 2 2 2 2 2 ... ## $ Fold : Factor w/ 3 levels &quot;L on R&quot;,&quot;Neither&quot;,..: 3 3 1 3 2 1 1 3 3 3 ... ## $ Pulse : int 92 104 87 NA 35 64 83 74 72 90 ... ## $ Clap : Factor w/ 3 levels &quot;Left&quot;,&quot;Neither&quot;,..: 1 1 2 2 3 3 3 3 3 3 ... ## $ Exer : Factor w/ 3 levels &quot;Freq&quot;,&quot;None&quot;,..: 3 2 2 2 3 3 1 1 3 3 ... ## $ Smoke : Factor w/ 4 levels &quot;Heavy&quot;,&quot;Never&quot;,..: 2 4 3 2 2 2 2 2 2 2 ... ## $ Height: num 173 178 NA 160 165 ... ## $ M.I : Factor w/ 2 levels &quot;Imperial&quot;,&quot;Metric&quot;: 2 1 NA 2 2 1 1 2 2 2 ... ## $ Age : num 18.2 17.6 16.9 20.3 23.7 ... levels(survey$Smoke) ## [1] &quot;Heavy&quot; &quot;Never&quot; &quot;Occas&quot; &quot;Regul&quot; frqtab &lt;- table(survey$Smoke) frqtab ## ## Heavy Never Occas Regul ## 11 189 19 17 class(frqtab) ## [1] &quot;table&quot; frqtab[2] ## Never ## 189 frqtab[&quot;Never&quot;] ## Never ## 189 3.1.1.1.2 최빈값 frqtab == max(frqtab) ## ## Heavy Never Occas Regul ## FALSE TRUE FALSE FALSE frqtab[frqtab == max(frqtab)] ## Never ## 189 names(frqtab[frqtab == max(frqtab)]) ## [1] &quot;Never&quot; which.max(frqtab) ## Never ## 2 frqtab[which.max(frqtab)] ## Never ## 189 names(frqtab[which.max(frqtab)]) ## [1] &quot;Never&quot; 3.1.1.1.3 비율도표 frqtab.prop &lt;- prop.table(frqtab) frqtab.prop ## ## Heavy Never Occas Regul ## 0.04661017 0.80084746 0.08050847 0.07203390 frqtab.prop[&quot;Never&quot;] ## Never ## 0.8008475 frqtab.prop * 100 ## ## Heavy Never Occas Regul ## 4.661017 80.084746 8.050847 7.203390 "],["til20220302.html", "3.2 TIL20220302", " 3.2 TIL20220302 3.2.1 데이터 요약 3.2.1.1 범주형 변수 요약 3.2.1.1.1 비율 계산 if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } survey$Smoke==&quot;Never&quot; # 비흡연자에 대한 논리연산 ## [1] TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [13] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE FALSE FALSE ## [37] TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [49] FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE FALSE ## [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE NA TRUE FALSE ## [73] TRUE TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE ## [85] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [97] FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE ## [109] TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE ## [121] FALSE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE ## [133] TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [145] TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE ## [157] FALSE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE FALSE ## [169] TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE FALSE TRUE FALSE TRUE ## [181] FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [193] FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE ## [205] FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [217] TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [229] FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE mean(survey$Smoke==&quot;Never&quot;, na.rm = T) # 비흡연자에 대한 비율 ## [1] 0.8008475 head(anorexia) ## Treat Prewt Postwt ## 1 Cont 80.7 80.2 ## 2 Cont 89.4 80.1 ## 3 Cont 91.8 86.4 ## 4 Cont 74.0 86.3 ## 5 Cont 78.1 76.1 ## 6 Cont 88.3 78.1 anorexia$Postwt &gt; anorexia$Prewt # 치료 후의 몸무게가 치료 전의 몸무게보다 큰가? ## [1] FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE ## [13] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE ## [25] TRUE FALSE TRUE TRUE FALSE FALSE FALSE TRUE TRUE TRUE FALSE TRUE ## [37] TRUE TRUE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE ## [49] TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE ## [61] FALSE FALSE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE mean(anorexia$Postwt &gt; anorexia$Prewt) ## [1] 0.5833333 head(mammals) ## body brain ## Arctic fox 3.385 44.5 ## Owl monkey 0.480 15.5 ## Mountain beaver 1.350 8.1 ## Cow 465.000 423.0 ## Grey wolf 36.330 119.5 ## Goat 27.660 115.0 # 두뇌의 무게가 2개의 표준편차보다 큰 논리연산식 abs(mammals$brain - mean(mammals$brain)) &gt; 2*sd(mammals$brain) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE mean(abs(mammals$brain - mean(mammals$brain)) &gt; 2*sd(mammals$brain)) ## [1] 0.03225806 head(SP500) ## [1] -0.2588908 -0.8650307 -0.9804139 0.4504321 -1.1856666 -0.6629097 # 수익률이 전일보다 증가한 일자 논리식 head(diff(SP500) &gt; 0, 10) ## [1] FALSE FALSE TRUE FALSE TRUE TRUE FALSE TRUE TRUE FALSE mean(diff(SP500) &gt; 0) ## [1] 0.4857863 if(!require(vcd)) { install.packages(&quot;vcd&quot;); library(vcd); } ## Loading required package: vcd ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;vcd&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;zoo&#39;, &#39;colorspace&#39;, &#39;lmtest&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages ## Loading required package: grid str(Arthritis) # 류마티스 관절염 치료 효과 ## &#39;data.frame&#39;: 84 obs. of 5 variables: ## $ ID : int 57 46 77 17 36 23 75 39 33 55 ... ## $ Treatment: Factor w/ 2 levels &quot;Placebo&quot;,&quot;Treated&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Sex : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ Age : int 27 29 30 32 46 58 59 59 63 63 ... ## $ Improved : Ord.factor w/ 3 levels &quot;None&quot;&lt;&quot;Some&quot;&lt;..: 2 1 1 3 3 3 1 3 1 1 ... levels(Arthritis$Treatment) ## [1] &quot;Placebo&quot; &quot;Treated&quot; levels(Arthritis$Improved) ## [1] &quot;None&quot; &quot;Some&quot; &quot;Marked&quot; crosstab &lt;- table(Arthritis$Improved, Arthritis$Treatment, dnn=c(&quot;Improved&quot;, &quot;Treatment&quot;)) crosstab ## Treatment ## Improved Placebo Treated ## None 29 13 ## Some 7 7 ## Marked 7 21 crosstab[&quot;Marked&quot;, &quot;Treated&quot;] ## [1] 21 crosstab &lt;- xtabs(~ Improved + Treatment, data = Arthritis) crosstab ## Treatment ## Improved Placebo Treated ## None 29 13 ## Some 7 7 ## Marked 7 21 margin.table(crosstab, margin = 1) # 행 ## Improved ## None Some Marked ## 42 14 28 margin.table(crosstab, margin = 2) # 열 ## Treatment ## Placebo Treated ## 43 41 prop.table(crosstab, margin = 1) # 행의 합이 1 ## Treatment ## Improved Placebo Treated ## None 0.6904762 0.3095238 ## Some 0.5000000 0.5000000 ## Marked 0.2500000 0.7500000 prop.table(crosstab, margin = 2) # 열의 합이 1 ## Treatment ## Improved Placebo Treated ## None 0.6744186 0.3170732 ## Some 0.1627907 0.1707317 ## Marked 0.1627907 0.5121951 prop.table(crosstab) ## Treatment ## Improved Placebo Treated ## None 0.34523810 0.15476190 ## Some 0.08333333 0.08333333 ## Marked 0.08333333 0.25000000 addmargins(crosstab, margin = 1) # 합의 행을 생성 ## Treatment ## Improved Placebo Treated ## None 29 13 ## Some 7 7 ## Marked 7 21 ## Sum 43 41 addmargins(crosstab, margin = 2) # 합의 열을 생성 ## Treatment ## Improved Placebo Treated Sum ## None 29 13 42 ## Some 7 7 14 ## Marked 7 21 28 addmargins(crosstab) ## Treatment ## Improved Placebo Treated Sum ## None 29 13 42 ## Some 7 7 14 ## Marked 7 21 28 ## Sum 43 41 84 addmargins(prop.table(crosstab, margin = 2), 1) ## Treatment ## Improved Placebo Treated ## None 0.6744186 0.3170732 ## Some 0.1627907 0.1707317 ## Marked 0.1627907 0.5121951 ## Sum 1.0000000 1.0000000 if(!require(gmodels)) { install.packages(&quot;gmodels&quot;); library(gmodels); } ## Loading required package: gmodels ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;gmodels&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;gtools&#39;, &#39;gdata&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages CrossTable(Arthritis$Improved, Arthritis$Treatment, dnn=c(&quot;Improved&quot;, &quot;Treatment&quot;)) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 84 ## ## ## | Treatment ## Improved | Placebo | Treated | Row Total | ## -------------|-----------|-----------|-----------| ## None | 29 | 13 | 42 | ## | 2.616 | 2.744 | | ## | 0.690 | 0.310 | 0.500 | ## | 0.674 | 0.317 | | ## | 0.345 | 0.155 | | ## -------------|-----------|-----------|-----------| ## Some | 7 | 7 | 14 | ## | 0.004 | 0.004 | | ## | 0.500 | 0.500 | 0.167 | ## | 0.163 | 0.171 | | ## | 0.083 | 0.083 | | ## -------------|-----------|-----------|-----------| ## Marked | 7 | 21 | 28 | ## | 3.752 | 3.935 | | ## | 0.250 | 0.750 | 0.333 | ## | 0.163 | 0.512 | | ## | 0.083 | 0.250 | | ## -------------|-----------|-----------|-----------| ## Column Total | 43 | 41 | 84 | ## | 0.512 | 0.488 | | ## -------------|-----------|-----------|-----------| ## ## multtab &lt;- table(Arthritis$Improved, Arthritis$Sex, Arthritis$Treatment) multtab ## , , = Placebo ## ## ## Female Male ## None 19 10 ## Some 7 0 ## Marked 6 1 ## ## , , = Treated ## ## ## Female Male ## None 6 7 ## Some 5 2 ## Marked 16 5 multtab &lt;- xtabs(~ Improved + Sex + Treatment, data = Arthritis) multtab ## , , Treatment = Placebo ## ## Sex ## Improved Female Male ## None 19 10 ## Some 7 0 ## Marked 6 1 ## ## , , Treatment = Treated ## ## Sex ## Improved Female Male ## None 6 7 ## Some 5 2 ## Marked 16 5 ftable(multtab) ## Treatment Placebo Treated ## Improved Sex ## None Female 19 6 ## Male 10 7 ## Some Female 7 5 ## Male 0 2 ## Marked Female 6 16 ## Male 1 5 ftable(multtab, row.vars = c(2,3)) ## Improved None Some Marked ## Sex Treatment ## Female Placebo 19 7 6 ## Treated 6 5 16 ## Male Placebo 10 0 1 ## Treated 7 2 5 ftable(Arthritis[c(&quot;Improved&quot;, &quot;Sex&quot;, &quot;Treatment&quot;)], row.vars = c(2,3)) ## Improved None Some Marked ## Sex Treatment ## Female Placebo 19 7 6 ## Treated 6 5 16 ## Male Placebo 10 0 1 ## Treated 7 2 5 margin.table(multtab, 1) ## Improved ## None Some Marked ## 42 14 28 margin.table(multtab, 2) ## Sex ## Female Male ## 59 25 margin.table(multtab, 3) ## Treatment ## Placebo Treated ## 43 41 ftable(prop.table(multtab, c(2,3))) ## Treatment Placebo Treated ## Improved Sex ## None Female 0.59375000 0.22222222 ## Male 0.90909091 0.50000000 ## Some Female 0.21875000 0.18518519 ## Male 0.00000000 0.14285714 ## Marked Female 0.18750000 0.59259259 ## Male 0.09090909 0.35714286 ftable(addmargins(prop.table(multtab, c(2,3)))) ## Treatment Placebo Treated Sum ## Improved Sex ## None Female 0.59375000 0.22222222 0.81597222 ## Male 0.90909091 0.50000000 1.40909091 ## Sum 1.50284091 0.72222222 2.22506313 ## Some Female 0.21875000 0.18518519 0.40393519 ## Male 0.00000000 0.14285714 0.14285714 ## Sum 0.21875000 0.32804233 0.54679233 ## Marked Female 0.18750000 0.59259259 0.78009259 ## Male 0.09090909 0.35714286 0.44805195 ## Sum 0.27840909 0.94973545 1.22814454 ## Sum Female 1.00000000 1.00000000 2.00000000 ## Male 1.00000000 1.00000000 2.00000000 ## Sum 2.00000000 2.00000000 4.00000000 "],["til20220303.html", "3.3 TIL20220303", " 3.3 TIL20220303 3.3.1 데이터 요약 3.3.1.1 연속형 변수 요약 3.3.1.1.1 중심경향 지표 중심경향 지표(measures of central tendency)는 데이터가 특정 값을 중심으로 집중되어 있는 정도를 뜻한다. 중위수(median) 백분위수(quantile, percentile) 사분위수(quartile) 평균(mean) if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS) } median(survey$Pulse) # 결측, 즉 NA 값에 따른 결과 ## [1] NA median(survey$Pulse, na.rm=T) # 결측값 제거 후 계산산 ## [1] 72.5 quantile(survey$Pulse, probs = 0.5, na.rm = T) # 중위수 ## 50% ## 72.5 quantile(survey$Pulse, probs = c(0.05, 0.95), na.rm = T) ## 5% 95% ## 59.55 92.00 # Q1, ... Q4 quantile(survey$Pulse, na.rm = T) ## 0% 25% 50% 75% 100% ## 35.0 66.0 72.5 80.0 104.0 quantile(survey$Pulse, seq(0,1,0.25), na.rm = T) ## 0% 25% 50% 75% 100% ## 35.0 66.0 72.5 80.0 104.0 # 주어진 값으로 백분위수 계산 survey$Pulse &lt;=80 # 80보다 작거나 같은 맥박수수 ## [1] FALSE FALSE FALSE NA TRUE TRUE FALSE TRUE TRUE FALSE TRUE TRUE ## [13] NA TRUE TRUE NA FALSE TRUE NA TRUE TRUE TRUE TRUE TRUE ## [25] TRUE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [37] NA TRUE TRUE NA NA TRUE TRUE TRUE TRUE NA FALSE FALSE ## [49] TRUE TRUE TRUE TRUE TRUE TRUE TRUE NA TRUE TRUE TRUE NA ## [61] TRUE TRUE TRUE NA TRUE NA NA TRUE NA TRUE TRUE NA ## [73] TRUE TRUE FALSE TRUE TRUE NA TRUE NA TRUE TRUE FALSE NA ## [85] FALSE TRUE TRUE TRUE TRUE FALSE TRUE NA TRUE NA TRUE NA ## [97] TRUE TRUE NA TRUE NA TRUE NA TRUE TRUE TRUE NA FALSE ## [109] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE ## [121] TRUE TRUE FALSE TRUE TRUE NA TRUE TRUE TRUE FALSE FALSE TRUE ## [133] FALSE TRUE FALSE FALSE TRUE TRUE NA TRUE FALSE NA TRUE FALSE ## [145] TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE TRUE ## [157] NA TRUE NA FALSE TRUE NA TRUE TRUE NA FALSE TRUE TRUE ## [169] NA TRUE NA TRUE TRUE TRUE TRUE FALSE TRUE FALSE NA TRUE ## [181] TRUE FALSE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE ## [193] TRUE TRUE NA TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE ## [205] TRUE FALSE TRUE FALSE FALSE NA TRUE FALSE TRUE TRUE TRUE NA ## [217] NA FALSE NA TRUE NA TRUE FALSE NA NA FALSE TRUE TRUE ## [229] TRUE TRUE TRUE NA FALSE FALSE NA FALSE FALSE mean(survey$Pulse &lt;= 80, na.rm = T) ## [1] 0.7552083 mean(survey$Pulse, na.rm = T) ## [1] 74.15104 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } summary(penguins$body_mass_g) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2700 3550 4050 4202 4750 6300 2 summary(penguins$species) ## Adelie Chinstrap Gentoo ## 152 68 124 summary(as.character(penguins$species)) ## Length Class Mode ## 344 character character summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 # list 형태를 인자로 입력하는 경우 penguins.list &lt;- as.list(penguins) summary(penguins.list) ## Length Class Mode ## species 344 factor numeric ## island 344 factor numeric ## bill_length_mm 344 -none- numeric ## bill_depth_mm 344 -none- numeric ## flipper_length_mm 344 -none- numeric ## body_mass_g 344 -none- numeric ## sex 344 factor numeric ## year 344 -none- numeric # lapply()를 통해 요약통계량 계산 lapply(penguins.list, summary) ## $species ## Adelie Chinstrap Gentoo ## 152 68 124 ## ## $island ## Biscoe Dream Torgersen ## 168 124 52 ## ## $bill_length_mm ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 32.10 39.23 44.45 43.92 48.50 59.60 2 ## ## $bill_depth_mm ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 13.10 15.60 17.30 17.15 18.70 21.50 2 ## ## $flipper_length_mm ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 172.0 190.0 197.0 200.9 213.0 231.0 2 ## ## $body_mass_g ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2700 3550 4050 4202 4750 6300 2 ## ## $sex ## female male NA&#39;s ## 165 168 11 ## ## $year ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2007 2007 2008 2008 2009 2009 3.3.2 변동성 지표 변동성 지표(measures of variability)는 데이터의 산포 정도를 뜻한다. 범위(range) 사분위 범위(interquartile range) 분산(variance) 표준편차(standard deviation) range(survey$Pulse, na.rm = T) ## [1] 35 104 var(survey$Pulse, na.rm = T) ## [1] 136.5896 sd(survey$Pulse, na.rm = T) ## [1] 11.68716 R에서는 다양한 기술 통계량을 계산하는 함수들을 제공한다. if(!require(pastecs)) { install.packages(&quot;pastecs&quot;); library(pastecs); } ## Loading required package: pastecs ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;pastecs&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages stat.desc(mtcars[c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)]) ## mpg hp wt ## nbr.val 32.0000000 32.0000000 32.0000000 ## nbr.null 0.0000000 0.0000000 0.0000000 ## nbr.na 0.0000000 0.0000000 0.0000000 ## min 10.4000000 52.0000000 1.5130000 ## max 33.9000000 335.0000000 5.4240000 ## range 23.5000000 283.0000000 3.9110000 ## sum 642.9000000 4694.0000000 102.9520000 ## median 19.2000000 123.0000000 3.3250000 ## mean 20.0906250 146.6875000 3.2172500 ## SE.mean 1.0654240 12.1203173 0.1729685 ## CI.mean.0.95 2.1729465 24.7195501 0.3527715 ## var 36.3241028 4700.8669355 0.9573790 ## std.dev 6.0269481 68.5628685 0.9784574 ## coef.var 0.2999881 0.4674077 0.3041285 if(!require(psych)) { install.packages(&quot;psych&quot;); library(psych); } ## Loading required package: psych ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;psych&#39; ## Installing package into &#39;/Users/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## also installing the dependencies &#39;tmvnsim&#39;, &#39;mnormt&#39; ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages describe(mtcars[c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)]) ## vars n mean sd median trimmed mad min max range skew kurtosis ## mpg 1 32 20.09 6.03 19.20 19.70 5.41 10.40 33.90 23.50 0.61 -0.37 ## hp 2 32 146.69 68.56 123.00 141.19 77.10 52.00 335.00 283.00 0.73 -0.14 ## wt 3 32 3.22 0.98 3.33 3.15 0.77 1.51 5.42 3.91 0.42 -0.02 ## se ## mpg 1.07 ## hp 12.12 ## wt 0.17 집단별 기술 통계량을 계산한다. levels(survey$Exer) ## [1] &quot;Freq&quot; &quot;None&quot; &quot;Some&quot; tapply(survey$Pulse, survey$Exer, mean, na.rm = T) ## Freq None Some ## 71.96842 76.76471 76.18750 tapply(survey$Pulse, list(survey$Exer, survey$Sex), mean, na.rm = T) ## Female Male ## Freq 73.60976 70.67925 ## None 71.42857 80.50000 ## Some 77.00000 75.03030 aggregate(survey$Pulse, list(Exercise=survey$Exer, Sex=survey$Sex), mean, na.rm = T) ## Exercise Sex x ## 1 Freq Female 73.60976 ## 2 None Female 71.42857 ## 3 Some Female 77.00000 ## 4 Freq Male 70.67925 ## 5 None Male 80.50000 ## 6 Some Male 75.03030 aggregate(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), mean, na.rm = T) ## Exercise Sex Pulse Age ## 1 Freq Female 73.60976 20.11229 ## 2 None Female 71.42857 22.32582 ## 3 Some Female 77.00000 20.29316 ## 4 Freq Male 70.67925 20.50257 ## 5 None Male 80.50000 20.75646 ## 6 Some Male 75.03030 19.91675 aggregate()는 FUN 인수에 사용자 정의 함수를 사용할 수 있다. myStats &lt;- function(x, na.rm = F) { if(na.rm) x &lt;- x[!is.na(x)] n &lt;- length(x) mean &lt;- mean(x) sd &lt;- sd(x) skew &lt;- sum((x-mean)^3/sd^3)/n kurt &lt;- sum((x-mean)^4/sd^4)/n - 3 return(c(n=n, mean=mean, sd=sd, skewness=skew, kurtosis=kurt)) } aggregate(survey$Pulse, list(Exercise=survey$Exer, Sex=survey$Sex), myStats, na.rm = T) ## Exercise Sex x.n x.mean x.sd x.skewness ## 1 Freq Female 41.000000000 73.609756098 12.491753377 -0.007083877 ## 2 None Female 7.000000000 71.428571429 11.414276775 -0.582777800 ## 3 Some Female 47.000000000 77.000000000 10.270260993 -0.057861601 ## 4 Freq Male 53.000000000 70.679245283 9.593213917 0.484695772 ## 5 None Male 10.000000000 80.500000000 15.204166096 0.148604585 ## 6 Some Male 33.000000000 75.030303030 13.501122288 -0.674836829 ## x.kurtosis ## 1 0.443768611 ## 2 -0.795725215 ## 3 -0.215883000 ## 4 0.543653114 ## 5 -1.649344568 ## 6 0.299978722 by(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), summary) ## Exercise: Freq ## Sex: Female ## Pulse Age ## Min. : 40.00 Min. :16.92 ## 1st Qu.: 68.00 1st Qu.:17.42 ## Median : 72.00 Median :18.50 ## Mean : 73.61 Mean :20.11 ## 3rd Qu.: 80.00 3rd Qu.:20.17 ## Max. :104.00 Max. :39.75 ## NA&#39;s :8 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Female ## Pulse Age ## Min. :50.00 Min. :17.17 ## 1st Qu.:69.00 1st Qu.:18.54 ## Median :70.00 Median :19.83 ## Mean :71.43 Mean :22.33 ## 3rd Qu.:78.00 3rd Qu.:20.79 ## Max. :86.00 Max. :41.58 ## NA&#39;s :4 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Female ## Pulse Age ## Min. : 50.0 Min. :16.92 ## 1st Qu.: 70.0 1st Qu.:17.50 ## Median : 76.0 Median :18.21 ## Mean : 77.0 Mean :20.29 ## 3rd Qu.: 83.5 3rd Qu.:19.15 ## Max. :100.0 Max. :73.00 ## NA&#39;s :11 ## ------------------------------------------------------------ ## Exercise: Freq ## Sex: Male ## Pulse Age ## Min. : 48.00 Min. :17.17 ## 1st Qu.: 64.00 1st Qu.:17.92 ## Median : 70.00 Median :18.58 ## Mean : 70.68 Mean :20.50 ## 3rd Qu.: 76.00 3rd Qu.:20.33 ## Max. :100.00 Max. :70.42 ## NA&#39;s :12 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Male ## Pulse Age ## Min. : 60.00 Min. :16.92 ## 1st Qu.: 68.00 1st Qu.:18.17 ## Median : 80.00 Median :18.92 ## Mean : 80.50 Mean :20.76 ## 3rd Qu.: 93.75 3rd Qu.:19.67 ## Max. :104.00 Max. :43.83 ## NA&#39;s :3 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Male ## Pulse Age ## Min. :35.00 Min. :16.75 ## 1st Qu.:66.00 1st Qu.:18.31 ## Median :75.00 Median :18.92 ## Mean :75.03 Mean :19.92 ## 3rd Qu.:85.00 3rd Qu.:20.04 ## Max. :96.00 Max. :35.50 ## NA&#39;s :7 aggregate(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), summary) ## Exercise Sex Pulse.Min. Pulse.1st Qu. Pulse.Median Pulse.Mean ## 1 Freq Female 40.00000 68.00000 72.00000 73.60976 ## 2 None Female 50.00000 69.00000 70.00000 71.42857 ## 3 Some Female 50.00000 70.00000 76.00000 77.00000 ## 4 Freq Male 48.00000 64.00000 70.00000 70.67925 ## 5 None Male 60.00000 68.00000 80.00000 80.50000 ## 6 Some Male 35.00000 66.00000 75.00000 75.03030 ## Pulse.3rd Qu. Pulse.Max. Pulse.NA&#39;s Age.Min. Age.1st Qu. Age.Median Age.Mean ## 1 80.00000 104.00000 8.00000 16.91700 17.41700 18.50000 20.11229 ## 2 78.00000 86.00000 4.00000 17.16700 18.54200 19.83300 22.32582 ## 3 83.50000 100.00000 11.00000 16.91700 17.50000 18.20850 20.29316 ## 4 76.00000 100.00000 12.00000 17.16700 17.91700 18.58300 20.50257 ## 5 93.75000 104.00000 3.00000 16.91700 18.16700 18.91700 20.75646 ## 6 85.00000 96.00000 7.00000 16.75000 18.31225 18.91700 19.91675 ## Age.3rd Qu. Age.Max. ## 1 20.16700 39.75000 ## 2 20.79150 41.58300 ## 3 19.14600 73.00000 ## 4 20.33300 70.41700 ## 5 19.66700 43.83300 ## 6 20.04200 35.50000 by(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], list(Exercise=survey$Exer, Sex=survey$Sex), function(x) sapply(x, myStats, na.rm=T)) ## Exercise: Freq ## Sex: Female ## Pulse Age ## n 41.000000000 49.000000 ## mean 73.609756098 20.112286 ## sd 12.491753377 4.831792 ## skewness -0.007083877 2.455680 ## kurtosis 0.443768611 5.815635 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Female ## Pulse Age ## n 7.0000000 11.000000 ## mean 71.4285714 22.325818 ## sd 11.4142768 7.345709 ## skewness -0.5827778 1.687717 ## kurtosis -0.7957252 1.500502 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Female ## Pulse Age ## n 47.0000000 58.000000 ## mean 77.0000000 20.293155 ## sd 10.2702610 8.244537 ## skewness -0.0578616 4.976422 ## kurtosis -0.2158830 27.133862 ## ------------------------------------------------------------ ## Exercise: Freq ## Sex: Male ## Pulse Age ## n 53.0000000 65.000000 ## mean 70.6792453 20.502569 ## sd 9.5932139 7.098771 ## skewness 0.4846958 5.585797 ## kurtosis 0.5436531 35.161334 ## ------------------------------------------------------------ ## Exercise: None ## Sex: Male ## Pulse Age ## n 10.0000000 13.000000 ## mean 80.5000000 20.756462 ## sd 15.2041661 7.024934 ## skewness 0.1486046 2.688832 ## kurtosis -1.6493446 5.973724 ## ------------------------------------------------------------ ## Exercise: Some ## Sex: Male ## Pulse Age ## n 33.0000000 40.000000 ## mean 75.0303030 19.916750 ## sd 13.5011223 3.516292 ## skewness -0.6748368 2.719822 ## kurtosis 0.2999787 8.174582 describeBy(survey[c(&quot;Pulse&quot;, &quot;Age&quot;)], group = list(Exercise=survey$Exer)) ## ## Descriptive statistics by group ## Exercise: Freq ## vars n mean sd median trimmed mad min max range skew ## Pulse 1 95 71.97 10.93 71.0 71.57 10.38 40.00 104.00 64.0 0.28 ## Age 2 115 20.34 6.18 18.5 19.08 1.61 16.92 70.42 53.5 5.32 ## kurtosis se ## Pulse 0.73 1.12 ## Age 36.42 0.58 ## ------------------------------------------------------------ ## Exercise: None ## vars n mean sd median trimmed mad min max range skew kurtosis ## Pulse 1 17 76.76 14.14 76.00 76.73 11.86 50.00 104.00 54.00 0.20 -0.79 ## Age 2 24 21.48 7.06 19.33 19.80 1.61 16.92 43.83 26.92 2.32 4.09 ## se ## Pulse 3.43 ## Age 1.44 ## ------------------------------------------------------------ ## Exercise: Some ## vars n mean sd median trimmed mad min max range skew kurtosis ## Pulse 1 80 76.19 11.67 76.00 76.66 11.86 35.00 100 65.00 -0.52 0.63 ## Age 2 98 20.14 6.70 18.54 18.80 1.54 16.75 73 56.25 5.69 38.61 ## se ## Pulse 1.30 ## Age 0.68 "],["til20220304.html", "3.4 TIL20220304", " 3.4 TIL20220304 3.4.1 가설검정 가설의 종류 대립가설(alternative hypothesis), 모집단에 대한 새로운 주장 귀무가설(null hypothesis), 기존의 주장 통계적 검정(statistical test) 또는 가설검정(hypothesis test)이란 표본 데이터를 기반으로 모집단에 대한 새로운 주장의 옮고 그름을 추론하는 과정을 말한다. 가설검정 절차 귀무가설이 사실이라는 전제하에서 수행되며 일반적으로 다음과 같은 절차를 따른다. 표본으로부터 검정하고자 하는 검정통계량(test statistic) 계산 검정통계량과 그 확률분포로부터 p-값(p-value) 계산 귀무가설이 사실이라는 가정하에서 관측한 통계량과 같거나 그보다 더 극단적인 값이 발생할 확률을 의미 유의확률(significance probability)이라고도 함 p-값이 매우 작으면 귀무가설 기각 판단의 기준으로 사용하는 5% 또는 1%의 확률을 유의수준(significance level)이라고 함 표본으로부터 관측된 결과(즉 계산된 통계량)가 나타날 가능성이 5% 미만 또는 1% 미만이 되는 귀무가설을 기각하면 이를 통계적으로 유의하다(statistically significant)라고 표현함 가설검정과 검정력 출처2 3.4.2 확률분포 출처3 이항분포(binomial distribution) 대표적인 이산확률분포(discrete probability distribution)로서 매회 어떤 사건이 일어날 확률이 동일한 독립 시행의 경우에 있어서 이 사건이 일어나는 횟수가 만들어 내는 분포이다. 예를 들면 동전 던지기로 동전을 일정 횟수 반복하여 던지는 실험에서 매 시행시마다 숫자면이 나타날 확률이 1/2이라고 할 때 숫자면이 나타나는 횟수는 이항분포를 따른다고 할 수 있다. dbinom(7, 10, 0.5) # 10번 던져 숫자면이 7번 나타날 확률 ## [1] 0.1171875 pbinom(7, 10, 0.5) # 10번 던져 숫자면이 7번 이하가 나타날 확률 ## [1] 0.9453125 누적확률은 밀도함수의 합으로 계산이 가능하다. sum(dbinom(c(0:7), 10, 0.5)) # 0번, 1번, ..., 7번 나타날 확률의 합 ## [1] 0.9453125 pbinom(7, 10, 0.5, lower.tail = F) # 1 - pbinom(7, 10, 0.5) ## [1] 0.0546875 # 4번 이상 7번 이하 발생할 누적확률, 7번에서 4번의 누적확률을 빼서 계산 pbinom(7, 10, 0.5) - pbinom(3, 10, 0.5) ## [1] 0.7734375 diff(pbinom(c(3,7), 10, 0.5)) ## [1] 0.7734375 set.seed(1) rbinom(1, size=10, prob = 0.5) ## [1] 4 rbinom(5, size=10, prob = 0.5) ## [1] 4 5 7 4 7 http://www.ktword.co.kr/img_data/5094_2.JPG↩︎ https://miro.medium.com/max/1400/1*fP1TTrA7TYD58rYgMHiL_A.png↩︎ "],["til20220305.html", "3.5 TIL20220305", " 3.5 TIL20220305 3.5.1 정규분포 정규분포(normal distribution)는 대표적인 연속확률분포(continuous probability distribution)으로 통계적 검정을 위해 가장 널리 사용되는 분포이다. 정규분포에서는 대부분의 관측값이 중앙에 몰려 있으며 중앙에서 멀어질수록 그 빈도수가 점점 작아지는 종 모양의 대칭인 모습을 가진다. if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } ## ## There is a binary version available but the source version is later: ## binary source needs_compilation ## RColorBrewer 1.1-2 1.1-3 FALSE ## ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages x &lt;- seq(-4, 4, length=100) y &lt;- dnorm(x) df &lt;- data.frame(x=x, y=y) ggplot(df, aes(x,y)) + geom_line() + theme_bw() ggplot(data = data.frame(x=c(65,135)), aes(x)) + stat_function(fun=dnorm, n=101, args=list(mean=100, sd=10)) + labs(title=&quot;Normal Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + theme_bw() # IQ가 110 이하일 누적확률 계산 pnorm(110, mean=100, sd=10) ## [1] 0.8413447 # IQ가 110 초과일 누적확률 계산 pnorm(110, mean=100, sd=10, lower.tail = F) # 1 - pnorm(110, mean=100, sd=10) ## [1] 0.1586553 pnorm(0) # 표준정규 분포를 가정정 ## [1] 0.5 pnorm(0, mean=0, sd=1) ## [1] 0.5 # 90 ~ 110 사이의 누적확률 pnorm(110, mean=100, sd=10) - pnorm(90, mean=100, sd=10) ## [1] 0.6826895 diff(pnorm(c(90, 110), mean=100, sd=10)) ## [1] 0.6826895 주어진 누적확률의 관측값을 알고자 할 때는 qnorm() 함수를 수행한다. qnorm(0.05, mean=100, sd=10) ## [1] 83.55146 qnorm(0.95, mean=100, sd=10) ## [1] 116.4485 qnorm(c(0.05, 0.95), mean=100, sd=10) ## [1] 83.55146 116.44854 qnorm(c(0.025, 0.975)) ## [1] -1.959964 1.959964 rnorm(1, mean=100, sd=10) ## [1] 115.9528 rnorm(5, mean=100, sd=10) ## [1] 103.29508 91.79532 104.87429 107.38325 105.75781 rnorm(1) ## [1] -0.3053884 rnorm(5) ## [1] 1.5117812 0.3898432 -0.6212406 -2.2146999 1.1249309 3.5.2 데이터의 정규성 검정 set.seed(123) shapiro.test(rnorm(100, mean=100, sd=10)) # 정규분포 ## ## Shapiro-Wilk normality test ## ## data: rnorm(100, mean = 100, sd = 10) ## W = 0.99388, p-value = 0.9349 shapiro.test(runif(100, min=2, max=4)) # 일항분포 ## ## Shapiro-Wilk normality test ## ## data: runif(100, min = 2, max = 4) ## W = 0.9454, p-value = 0.0004182 set.seed(123) qqnorm(rnorm(100, mean=100, sd=10), col=&quot;blue&quot;, main = &quot;Sample from Normal Distribution&quot;) qqline(rnorm(100, mean=100, sd=10)) x축은 이론적 정규 분포에 의해 생성된 표본이고 y축은 실제 표본이다. set.seed(123) qqnorm(runif(100, min=2, max=4), col=&quot;red&quot;, main = &quot;Sample from Uniform Distribution&quot;) qqline(runif(100, min=2, max=4)) "],["til20220306.html", "3.6 TIL20220306", " 3.6 TIL20220306 3.6.1 대응표본 평균검정 독립표본 평균검정은 두 개의 표본이 서로 독립인 모집단으로부터추출되었다는 가정을 전제로 한다. 두 표본의 값이 쌍(pair)을 이루고 있는 경우 쌍을 이룬 값은 서로 독립이 아니며, 이처럼 검정하려고 하는 두 개의 표본이 서로 독립이 아닌 모집단으로부터 추출되었을 대 대응표본 평균검정(paired-samples t test)을 이용하여 두 집단 간의차이 검정을 수행할 수 있다. 독립표본 대응표본 무작위로 실험 대상자를선정하여 두 개의 집단으로 나눔 무작위로 실험 대상자를 선정 한 집단에는 앛미식사를 하고 IQ 테스트에 응하도록 하고 다른 집단에는 앛미식사를 거르고 IQ 테스트에참가하도록 함 각 실험 대아자를 대상으로 IQ 테스트를 두 차례 실시 각 실험 대상자에 대해 하나씩의 IQ 테스트 점수를 얻게 됨 한번은 아침칫가를 하고 테스트에 응하고 다른 한번은 아침식사를 하지 않은 상태로 테스트에 참가하도록 함 각 식험 대상자에 대해 두 개의 IQ 테스트 점수를 얻게 됨 str(sleep) ## &#39;data.frame&#39;: 20 obs. of 3 variables: ## $ extra: num 0.7 -1.6 -0.2 -1.2 -0.1 3.4 3.7 0.8 0 2 ... ## $ group: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ ID : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 6 7 8 9 10 ... t.test(extra ~ group, data = sleep, paired = T) ## ## Paired t-test ## ## data: extra by group ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean of the differences ## -1.58 주어진 표본이 wide format일 경우 벡터를 직접 지정하여 수행한다. if(!require(tidyr)) { install.packages(&quot;tidyr&quot;); library(tidyr); } sleep.wide &lt;- spread(sleep, key = group, value = extra) sleep.wide ## ID 1 2 ## 1 1 0.7 1.9 ## 2 2 -1.6 0.8 ## 3 3 -0.2 1.1 ## 4 4 -1.2 0.1 ## 5 5 -0.1 -0.1 ## 6 6 3.4 4.4 ## 7 7 3.7 5.5 ## 8 8 0.8 1.6 ## 9 9 0.0 4.6 ## 10 10 2.0 3.4 t.test(sleep.wide$`1`, sleep.wide$`2`, paired = T) ## ## Paired t-test ## ## data: sleep.wide$`1` and sleep.wide$`2` ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean of the differences ## -1.58 3.6.2 독립표본 비율검정 귀무가설: 폐질환자 대비 흡연자의 비율이 병원별로 같다. 대립가설: 폐질환자 대비 흡연자의 비율이 병원별로 다르다. # 4개 병원에 대한 폐질환자 및 흡연자 비율 patients &lt;- c(86, 93, 136, 82) # 폐질환자 smokers &lt;- c(83, 90, 129,70) # 흡연자 smokers/patients # 페질환자 대비 흡연자 비율 ## [1] 0.9651163 0.9677419 0.9485294 0.8536585 prop.test(x=smokers, n=patients) ## ## 4-sample test for equality of proportions without continuity ## correction ## ## data: smokers out of patients ## X-squared = 12.6, df = 3, p-value = 0.005585 ## alternative hypothesis: two.sided ## sample estimates: ## prop 1 prop 2 prop 3 prop 4 ## 0.9651163 0.9677419 0.9485294 0.8536585 검정 수행 결과 네 병원의 폐질환자 대비 흡연자 수는 값다고 볼 수 없다. 3.6.3 독립표본 평균검정 독립표본 평균검정(two-independent samples t test)는 두 개의 독립표본 데이터를 이용하여 각각 대응되는 두 개의 모집단 평균이 서로 동일한지 검정한다. 두 집단이 서로 차이가 있는지를 검정하고자 할 때 수행한다. 귀무가설: 두 집단의 평균에는 차이가 없다(같다). 대립가설: 두 집단의 평균에는 차이가 있다(다르다). 예제 고양이의 성별에 따른 몸무게의 차이가 있는지를 검정한다. 귀무가설: 고양이 성별에 따른 몸무게 차이는 없다. 대립가설: 고양이 성별에 따른 몸무게 차이는 있다. t.test(formula = Bwt ~ Sex, data = cats) ## ## Welch Two Sample t-test ## ## data: Bwt by Sex ## t = -8.7095, df = 136.84, p-value = 8.831e-15 ## alternative hypothesis: true difference in means between group F and group M is not equal to 0 ## 95 percent confidence interval: ## -0.6631268 -0.4177242 ## sample estimates: ## mean in group F mean in group M ## 2.359574 2.900000 Bwt.f &lt;- cats$Bwt[cats$Sex==&quot;F&quot;] Bwt.m &lt;- cats$Bwt[cats$Sex==&quot;M&quot;] mean(Bwt.f); mean(Bwt.m); ## [1] 2.359574 ## [1] 2.9 t.test(Bwt.f, Bwt.m) ## ## Welch Two Sample t-test ## ## data: Bwt.f and Bwt.m ## t = -8.7095, df = 136.84, p-value = 8.831e-15 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.6631268 -0.4177242 ## sample estimates: ## mean of x mean of y ## 2.359574 2.900000 3.6.4 일표본 비율검정 prop.test() 함수는 모집단에 대한 표본의 비율에 대한 검정을 수행한다. 예제 프로야구 팀이 30경기 중 18승을 거두었을 때, 승률이 50%가 넘는다고 말할 수 있는가? 귀무가설: 승률이 50% 이하다. 대립가설: 승률이 50% 이상이다. # prop.test(x=성공횟수, n=시행횟수, p=검정코자하는비율) prop.test(x=18, n=30, p=0.5, alternative = &quot;greater&quot;) ## ## 1-sample proportions test with continuity correction ## ## data: 18 out of 30, null probability 0.5 ## X-squared = 0.83333, df = 1, p-value = 0.1807 ## alternative hypothesis: true p is greater than 0.5 ## 95 percent confidence interval: ## 0.4344744 1.0000000 ## sample estimates: ## p ## 0.6 3.6.5 일표본 평균검정 일표본 평균검정(one-sample t test)는 하나의 표본 데이터를 이용하여 모집단의 평균이 특정 값과 같은지 검정하는 것이다. 표본집단이 특정 모집단과 일치하는지 혹은 그렇지 않은지를 알고 싶을 때 이용한다. str(cats) ## &#39;data.frame&#39;: 144 obs. of 3 variables: ## $ Sex: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Bwt: num 2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ... ## $ Hwt: num 7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ... 귀무가설: 고양이의 몸무게가 2.6kg이다. 대립가설: 고양이의 몸무게가 2.6kg이 아니다. t.result &lt;- t.test(x=cats$Bwt, mu=2.6); t.result ## ## One Sample t-test ## ## data: cats$Bwt ## t = 3.0565, df = 143, p-value = 0.002673 ## alternative hypothesis: true mean is not equal to 2.6 ## 95 percent confidence interval: ## 2.643669 2.803553 ## sample estimates: ## mean of x ## 2.723611 p95 &lt;- qt(0.975, df=143) ggplot(data = data.frame(x=c(-4,4)), aes(x)) + stat_function(fun=dt, args = list(df=143)) + labs(title=&quot;t Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + geom_vline(xintercept=t.result$statistic, color=&quot;blue&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=t.result$statistic+0.4, y=0.02, aes(label=round(t.result$statistic,2)), col=&quot;blue&quot;) + geom_vline(xintercept=p95, color=&quot;red&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=p95+0.3, y=0.06, aes(label=round(p95,2)), col=&quot;red&quot;) + theme_bw() 귀무가설: 고양이의 몸무게가 2.7kg이다. 대립가설: 고양이의 몸무게가 2.7kg이 아니다. t.result &lt;- t.test(x=cats$Bwt, mu=2.7); t.result ## ## One Sample t-test ## ## data: cats$Bwt ## t = 0.58382, df = 143, p-value = 0.5603 ## alternative hypothesis: true mean is not equal to 2.7 ## 95 percent confidence interval: ## 2.643669 2.803553 ## sample estimates: ## mean of x ## 2.723611 p95 &lt;- qt(0.975, df=143) ggplot(data = data.frame(x=c(-4,4)), aes(x)) + stat_function(fun=dt, args = list(df=143)) + labs(title=&quot;t Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + geom_vline(xintercept=t.result$statistic, color=&quot;blue&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=t.result$statistic+0.4, y=0.02, aes(label=round(t.result$statistic,2)), col=&quot;blue&quot;) + geom_vline(xintercept=p95, color=&quot;red&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=p95+0.3, y=0.06, aes(label=round(p95,2)), col=&quot;red&quot;) + theme_bw() 3.6.6 평균검정 평균검정은 평균에 대한 가설검정을 의미한다. 선정한 표본이 특정 평균값을 갖는 모집단에 속하는지(즉 표본의 평균과 모집단의 평균이 동일한지) 또는 두 표본 집단의 평균값 간에 차이가 존재하는지(즉 두 표본집단이 동일한 모집단에 속하는지) 검정한다. 일표본 평균검정, 독립표본 평균검정, 대응표본 평균 검정이 있다. 평균에 대한 가설검정은 t검정(t test)을 통해 수행할 수 있다. 표본평균이 모집단 평균과 동일한지 여부는 t값을 검정 통계량으로 사용하여 검정한다. \\[ t = \\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}} \\] 예제 귀무가설: 벤처기업 경영자의 혈압은 일반일과 같다 대립가설; 벤터기업 경영자의 혈압은 일반일과 다르다 표본: 20명의 벤처기업 경영자 평균 135, 표준편차 25 모집단: 일반인 혈압 평균 115 \\[ 검정통계량 \\ \\ t = \\frac{135-115}{\\frac{25}{\\sqrt{20}}} = 3.58 \\] t &lt;- 3.58; n &lt;- 20; pt(t, df=n-1) # t값에 해당하는 누적확률 계산 ## [1] 0.9990014 # 특정 t값 이상의 누적확률에 관심이 있으므로 lower.tail을 F로 설정 # 반대편도 고려해야 함으로 두배 함 pt(t, df=n-1, lower.tail = F)*2 ## [1] 0.001997274 모집단 평균 115라는 가정하에서 135라는 평균은 0.002의 유의확률을 가지므로 5% 유의수준 하에서 귀무가설을 기각하고 대립가설을 채택한다. 유사한 방식으로 유의수준 0.05에 해당하는 t값을 계산하고 관측된 t값을 비교하여 검정한다. p95 &lt;- qt(0.025, df=n-1, lower.tail = F); p95 ## [1] 2.093024 주어진 t 값은 유의수준 5%에 해당하는 t값의 오른쪽에 위치함으로 귀무가설을 기각하고 대립가설을 채택한다. dt_range &lt;- function(x) { y &lt;- dt(x, df=19) y[x &lt; 2.09] &lt;- NA return(y) } ggplot(data = data.frame(x=c(-4,4)), aes(x)) + stat_function(fun=dt, args = list(df=19)) + stat_function(fun=dt_range, geom=&quot;area&quot;, fill=&quot;salmon&quot;, alpha=.5) + labs(title=&quot;t Distribution&quot;, x=&quot;x&quot;, y=&quot;&quot;) + scale_y_continuous(breaks = NULL) + geom_vline(xintercept=t, color=&quot;blue&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=t+0.3, y=0.02, aes(label=t), col=&quot;blue&quot;) + geom_vline(xintercept=p95, color=&quot;red&quot;, linetype = &quot;dashed&quot;, size=1) + geom_text(x=p95+0.3, y=0.06, aes(label=round(p95,2)), col=&quot;red&quot;) + theme_bw() "],["til20220307.html", "3.7 TIL20220307", " 3.7 TIL20220307 3.7.1 결측치 처리 3.7.1.1 결측치 종류 결측치 종류 3.7.1.2 확인 ## summary() summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 colSums(is.na(penguins)); nrow(penguins) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 ## [1] 344 등등등 3.7.1.3 제거 penguins.naomit &lt;- na.omit(penguins) colSums(is.na(penguins.naomit)); nrow(penguins.naomit) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex year ## 0 0 0 0 ## [1] 333 penguins.naomit &lt;- penguins[complete.cases(penguins), ] colSums(is.na(penguins.naomit)); nrow(penguins.naomit) ## species island bill_length_mm bill_depth_mm ## 0 0 0 0 ## flipper_length_mm body_mass_g sex year ## 0 0 0 0 ## [1] 333 제거 후 11개 행이 감소된 것을 볼 수 있다. 3.7.1.4 대체 3.7.1.5 0으로 대체 # 연속형 변수에 대해서만 적용 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } penguins.0 &lt;- penguins[c(3:6)] %&gt;% select_if(function(x) any(is.na(x))) %&gt;% replace(is.na(.), 0) colSums(is.na(penguins.0)) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 0 0 0 0 3.7.1.6 평균으로 대체 penguins.mean &lt;- penguins[c(3:6)] %&gt;% select_if(function(x) any(is.na(x))) %&gt;% mutate(bill_length_mm = ifelse(is.na(bill_length_mm), mean(bill_length_mm, na.rm=T), bill_length_mm), bill_depth_mm = ifelse(is.na(bill_depth_mm), mean(bill_depth_mm, na.rm=T), bill_depth_mm), flipper_length_mm = ifelse(is.na(flipper_length_mm), mean(flipper_length_mm, na.rm=T), flipper_length_mm), body_mass_g = ifelse(is.na(body_mass_g), mean(body_mass_g, na.rm=T), body_mass_g)) colSums(is.na(penguins.mean)) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 0 0 0 0 # 0으로 대체한 경우와 평균값으로 대체한 경우의 차이 colMeans(penguins[c(3:6)], na.rm = T); colMeans(penguins.0); colMeans(round(penguins.mean,1)); ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92193 17.15117 200.91520 4201.75439 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.66657 17.05145 199.74709 4177.32558 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.92180 17.15145 200.91512 4201.75465 all_column_median &lt;- apply(penguins[c(3:6)], 2, median, na.rm=T); all_column_median ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 44.45 17.30 197.00 4050.00 penguins.median &lt;- penguins[c(3:6)] for(i in colnames(penguins.median)) { penguins.median[is.na(penguins.median[,i]), i] &lt;- all_column_median[i] } colMeans(round(penguins.median)) ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 43.93314 17.15407 200.89244 4200.87209 "],["til20220308.html", "3.8 TIL20220308", " 3.8 TIL20220308 3.8.1 R 에러 수정 &gt; library(dplyr) Error: package or namespace load failed for ‘dplyr’ in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]): ‘rlang’이라고 불리는 패키지가 없습니다 In addition: Warning message: 패키지 ‘dplyr’는 R 버전 3.4.4에서 작성되었습니다 이런 식으로 에러가 발생하면 깔끔하게 R을 재설치 하자. libpath나 패키지 재설치 등의 방법이 언급되지만 안되는 경우가 있다. 한시간 반 소비하고 내린 결론이다. 4.0.3에서 문제가 일어났고 4.1.2로 버전 업해서 문제 해결되었다. Error: ! Assigned data `all_column_mean[i]` must be compatible with existing data. i Error occurred for column `flipper_length_mm`. x Can&#39;t convert from &lt;double&gt; to &lt;integer&gt; due to loss of precision. * Locations: 1. Backtrace: 1. base::`[&lt;-`(`*tmp*`, is.na(p.mean[, i]), i, value = `&lt;dbl&gt;`) 19. tibble `&lt;fn&gt;`(`&lt;vctrs___&gt;`) p.mean &lt;- as.data.frame(penguins[c(3:6)])와 같이 데이터 형태를 명시적으로 지정해 준다. 3.8.2 결측치 시각화 if(!require(mice)) { install.packages(&quot;mice&quot;); library(mice); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages md.pattern(penguins, plot=T, rotate.names = T) ## species island year bill_length_mm bill_depth_mm flipper_length_mm ## 333 1 1 1 1 1 1 ## 9 1 1 1 1 1 1 ## 2 1 1 1 0 0 0 ## 0 0 0 2 2 2 ## body_mass_g sex ## 333 1 1 0 ## 9 1 0 1 ## 2 0 0 5 ## 2 11 19 "],["til20220309.html", "3.9 TIL20220309", " 3.9 TIL20220309 3.9.1 클래스 불균형과 샘플링 분류 분석의 경우 관찰된 표본 범주 비율이 큰 쪽으로 편향되는 경향이 있다. 이를 해결하기 위해 범주의 비율을 조절하여 정제한다. Downsampling &amp; Upsampling4 SMOTE5 Upsampling: this method increases the size of the minority class by sampling with replacement so that the classes will have the same size. Downsampling: in contrast to the above method, this one decreases the size of the majority class to be the same or closer to the minority class size by just taking out a random sample. Hybrid methods : The well known hybrid methods are ROSE (Random oversampling examples), and SMOTE (Synthetic minority oversampling technique), they downsample the majority class, and creat new artificial points in the minority class. For more detail about SMOTE method click here, and for ROSE click here. from: Methods for dealing with imbalanced data6 https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/resampling.png↩︎ https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/smote.png↩︎ https://www.r-bloggers.com/2019/04/methods-for-dealing-with-imbalanced-data/↩︎ "],["til20220310.html", "3.10 TIL20220310", " 3.10 TIL20220310 if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } data(&quot;BreastCancer&quot;) bc &lt;- BreastCancer[, -1] # Id 열 제외 ## Error in eval(expr, envir, enclos): object &#39;BreastCancer&#39; not found str(bc) ## Error in str(bc): object &#39;bc&#39; not found train.index &lt;- createDataPartition(bc$Class, p=0.75, list=F) bc.train &lt;- bc[train.index, ]; bc.test &lt;- bc[-train.index, ]; rbind(TrainData = table(bc.train$Class), TestData = table(bc.test$Class)) # upsampling / downsample / SMOTE bc.train.up &lt;- upSample(subset(bc.train, select = -Class), bc.train$Class) bc.train.down &lt;- downSample(subset(bc.train, select = -Class), bc.train$Class) bc.train.smote &lt;- SMOTE(Class ~ ., bc.train, prec.over = 900, perc.under=150) rbind(Upsampling = table(bc.train.up$Class), Downsampling = table(bc.train.down$Class), SMOTE = table(bc.train.smote$Class)) p.dt &lt;- rpart(Class ~ ., bc.train) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) orig.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] p.dt &lt;- rpart(Class ~ ., bc.train.up) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) up.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] p.dt &lt;- rpart(Class ~ ., bc.train.down) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) down.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] p.dt &lt;- rpart(Class ~ ., bc.train.smote) p.dt.pred &lt;- predict(p.dt, bc.test, type = &quot;class&quot;) smote.cm &lt;- confusionMatrix(p.dt.pred, bc.test$Class)$overall[1] rbind(Orig = orig.cm, Upsampling = up.cm, Downsampling = down.cm, SMOTE = smote.cm) 상황에 따라 결과가 다르게 나오지만 대체적으로 SMOTE에서 높은 정확도를 보인다. 3.10.1 SMOTE 데이터 형식 오류 Why do I get ‘Error in T[, col] &lt;- data[, col]’ when I use SMOTE in R? 변수는 facter형이고, tibble 형식을 지원하지 않는다. "],["til20220311.html", "3.11 TIL20220311", " 3.11 TIL20220311 DWmR 패키지는 github actions로 설치 안되는 걸로… RStudio에서 rendering 후 업로드 하자. 3.11.1 URL을 통해 직접 패키지 설치 Install an R package directly from a URL for the package source7 install.packages(&quot;https://cran.r-project.org/src/contrib/Archive/DMwR/DMwR_0.4.1.tar.gz&quot;, repos=NULL, method=&quot;libcurl&quot;) data(&quot;BreastCancer&quot;) bc &lt;- BreastCancer[, -1] # Id 열 제외 ## Error in eval(expr, envir, enclos): object &#39;BreastCancer&#39; not found bc.smote &lt;- SMOTE(Class ~ ., bc, perc.over = 100, perc.under = 200) bc.smote.compete &lt;- complete(bc.smote) rbind(Orig = table(bc$Class), SMOTE = table(bc.smote.compete$Class)) https://stackoverflow.com/questions/16412638/install-an-r-package-directly-from-a-url-for-the-package-source↩︎ "],["til20220312.html", "3.12 TIL20220312", " 3.12 TIL20220312 3.12.1 RStudio Chunk options R Code Chunks8 Rmarkdown으로 문서 작성 시 꼭 필요한 사용하게 된다. 알아 둘 것. knitr::opts_chunk$set(# root.dir = &#39;../..&#39;, # 프로젝트 폴더 지정 eval = TRUE, echo = FALSE, cache = FALSE, include = TRUE, tidy = TRUE, tidy.opts = list(blank=FALSE, width.cutoff=120), # 소스 출력길이 지정 message = FALSE, warning = FALSE, engine = &quot;R&quot;, # Chunks will always have R code, unless noted error = TRUE, fig.path=&quot;Figures/&quot;, # Set the figure options fig.align = &quot;center&quot;, fig.width = 7, fig.height = 7, fig.keep=&#39;all&#39;, fig.retina=2) https://zorba78.github.io/cnu-r-programming-lecture-note/r-code-chunks.html↩︎ "],["til20220313.html", "3.13 TIL20220313", " 3.13 TIL20220313 3.13.1 시계열 데이터 분할 출처: 시계열 데이터 - 항공여객(Air Passenger) 데이터9 시계열은 일반적인 방법으로 표본상에서 랜덤하게 원소를 추출할 수 없다. 시간 흐름을 고려하여 훈련 데이터와 시험 데이터로 분할해야 한다. train = 1:18 test = 19:24 par(mar=c(0,0,0,0)) {plot(0,0,xlim=c(0,26),ylim=c(0,2),xaxt=&quot;n&quot;,yaxt=&quot;n&quot;,bty=&quot;n&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;,type=&quot;n&quot;) arrows(0,0.5,25,0.5,0.05) points(train, train*0+0.5, pch=19, col=&quot;blue&quot;) points(test, test*0+0.5, pch=19, col=&quot;red&quot;) text(26,0.5,&quot;시간&quot;) text(10,0.7,&quot;훈련데이터&quot;,col=&quot;blue&quot;) text(21,0.7,&quot;시험데이터&quot;,col=&quot;red&quot;)} # Core Tidyverse if(!require(tidyverse)) { install.packages(&quot;tidyverse&quot;); library(tidyverse); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages if(!require(glue)) { install.packages(&quot;glue&quot;); library(glue); } if(!require(forcats)) { install.packages(&quot;forcats&quot;); library(forcats); } # Time Series if(!require(timetk)) { install.packages(&quot;timetk&quot;); library(timetk); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages if(!require(tidyquant)) { install.packages(&quot;tidyquant&quot;); library(tidyquant); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages if(!require(tibbletime)) { install.packages(&quot;tibbletime&quot;); library(tibbletime); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages if(!require(sweep)) { install.packages(&quot;sweep&quot;); library(sweep); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages # Visualization if(!require(cowplot)) { install.packages(&quot;cowplot&quot;); library(cowplot); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages # Preprocessing if(!require(recipes)) { install.packages(&quot;recipes&quot;); library(recipes); } # Sampling / Accuracy if(!require(rsample)) { install.packages(&quot;rsample&quot;); library(rsample); } if(!require(yardstick)) { install.packages(&quot;yardstick&quot;); library(yardstick); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages # Modeling if(!require(forecast)) { install.packages(&quot;forecast&quot;); library(forecast); } data(&quot;AirPassengers&quot;) ap_ts &lt;- AirPassengers %&gt;% tk_tbl() %&gt;% mutate(index = as_date(index)) %&gt;% as_tbl_time(index = index) %&gt;% filter(index &gt;= &quot;1950-01-01&quot;, index &lt;= &quot;1959-12-31&quot;) ggplot(ap_ts, aes(x=index, y=value)) + geom_line() 오늘은 여기까지… http://aispiration.com/model/model-rsampling-time-series.html↩︎ "],["til20220314.html", "3.14 TIL20220314", " 3.14 TIL20220314 데이터 분할, 이건 내일 정리하자. 양이 많네. 3.14.1 일반적인 데이터 분할 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages trainIndex &lt;- createDataPartition(penguins$species, p=.7, list=F) pTrain &lt;- penguins[trainIndex, ] pTest &lt;- penguins[-trainIndex, ] addmargins(addmargins(rbind( pTrain = table(pTrain$species), pTest = table(pTest$species) ),2),1) ## Adelie Chinstrap Gentoo Sum ## pTrain 107 48 87 242 ## pTest 45 20 37 102 ## Sum 152 68 124 344 "],["til20220315.html", "3.15 TIL20220315", " 3.15 TIL20220315 3.15.1 caret을 이용한 기계학습 절차 데이터 전처리 데이터 분할 학습 성능평가 하이퍼 파라메터 튜닝 # 0. 데이터 준비 data(&quot;penguins&quot;) str(penguins) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... summary(penguins) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 # 1. 데이터 전처리 if(!require(mice)) { install.packages(&quot;mice&quot;); library(mice); } penguins.preprocessing &lt;- mice(penguins, m=1, print=F) # 결측치 처리 data &lt;- complete(penguins.preprocessing) # 수치형 변수 정규화 data[, c(3:6)] &lt;- scale(data[, c(3:6)]) # 년도 범주로 변환 data$year &lt;- as.factor(data$year) summary(data) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :-2.1700 Min. :-2.03915 ## Chinstrap: 68 Dream :124 1st Qu.:-0.8530 1st Qu.:-0.79363 ## Gentoo :124 Torgersen: 52 Median : 0.0969 Median : 0.07446 ## Mean : 0.0000 Mean : 0.00000 ## 3rd Qu.: 0.8403 3rd Qu.: 0.77900 ## Max. : 2.8777 Max. : 2.18808 ## flipper_length_mm body_mass_g sex year ## Min. :-2.0579 Min. :-1.8762 female:173 2007:110 ## 1st Qu.:-0.7774 1st Qu.:-0.8142 male :171 2008:114 ## Median :-0.2794 Median :-0.1895 2009:120 ## Mean : 0.0000 Mean : 0.0000 ## 3rd Qu.: 0.8766 3rd Qu.: 0.6851 ## Max. : 2.1394 Max. : 2.6216 # 2. 데이터 분할 train.index &lt;- createDataPartition(data$sex, p=0.7, list=F) data.train &lt;- data[train.index, ] data.test &lt;- data[-train.index, ] addmargins(rbind( TrainSet = table(data.train$sex), TestSet = table(data.test$sex) ),2) ## female male Sum ## TrainSet 122 120 242 ## TestSet 51 51 102 # 3. 학습 fitControl &lt;- trainControl(method = &quot;repeatedcv&quot;, repeats = 5) model.rf &lt;- train(sex ~ ., data=data.train, method = &quot;rf&quot;, trControl = fitControl); model.rf ## Error: Required packages are missing: randomForest ## Error in eval(expr, envir, enclos): object &#39;model.rf&#39; not found # 4. 성능평가 model.rf.pred &lt;- predict(model.rf, newdata = data.test) ## Error in predict(model.rf, newdata = data.test): object &#39;model.rf&#39; not found model.rf.cm &lt;- confusionMatrix(model.rf.pred, data.test$sex); model.rf.cm ## Error in confusionMatrix(model.rf.pred, data.test$sex): object &#39;model.rf.pred&#39; not found ## Error in eval(expr, envir, enclos): object &#39;model.rf.cm&#39; not found # 5. 하이퍼 파라메터 튜닝 ## 5-1. custom search grid customGrid &lt;- expand.grid(mtry = 1:(dim(data.train)[2]-1)) model.rf.tuned &lt;- train(sex ~ ., data=data.train, method = &quot;rf&quot;, trControl = fitControl, tuneGrid = customGrid); model.rf.tuned ## Error: Required packages are missing: randomForest ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned&#39; not found model.rf.tuned.pred &lt;- predict(model.rf.tuned, newdata = data.test) ## Error in predict(model.rf.tuned, newdata = data.test): object &#39;model.rf.tuned&#39; not found model.rf.tuned.cm &lt;- confusionMatrix(model.rf.tuned.pred, data.test$sex); model.rf.tuned.cm ## Error in confusionMatrix(model.rf.tuned.pred, data.test$sex): object &#39;model.rf.tuned.pred&#39; not found ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned.cm&#39; not found # 5-2. Random Search Grid fitControl.random &lt;- trainControl(method = &quot;repeatedcv&quot;, repeats = 5, search = &quot;random&quot;) model.rf.tuned2 &lt;- train(sex ~ ., data=data.train, method = &quot;rf&quot;, trControl = fitControl.random, tuneLength = 10); model.rf.tuned2 ## Error: Required packages are missing: randomForest ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned2&#39; not found model.rf.tuned2.pred &lt;- predict(model.rf.tuned2, newdata = data.test) ## Error in predict(model.rf.tuned2, newdata = data.test): object &#39;model.rf.tuned2&#39; not found model.rf.tuned2.cm &lt;- confusionMatrix(model.rf.tuned2.pred, data.test$sex); model.rf.tuned2.cm ## Error in confusionMatrix(model.rf.tuned2.pred, data.test$sex): object &#39;model.rf.tuned2.pred&#39; not found ## Error in eval(expr, envir, enclos): object &#39;model.rf.tuned2.cm&#39; not found "],["til20220316.html", "3.16 TIL20220316", " 3.16 TIL20220316 3.16.1 페널티 회귀분석 - 1 페널티 회귀분석(penalized regression analysis)10 릿지 (Ridge) 회귀계수를 0에 가깝게 만듬(모든 변수 사용), 독립변수의 회귀계수가 비슷한 경우 우수 라소 (Lasso) 설명력에 기여하지 못하는 독립변수의 회귀계수를 0으로 만듬(간명한 모델), 독립변수의 회귀변수간 차이가 클 때 우수 일래스틱넷 (ElasticNet), 릿지 + 라소 지나치게많은 독립변수를 갖는 모델에 페널티를 부과하는 방식으로 보다 간명한 회귀모델을 생성할 수 있다. 모델의 성능에 크게 기여하지 못하는 변수의 영향력을 축소(Lasso)하거나 모델에서 제거(Ridge)한다. 최소자승법에 의한 잔차(=관측값-예측값)의 제곱합과 페널티항의 합이 최소가 되도록 회귀계수를 추정한다. str(Boston) ## &#39;data.frame&#39;: 506 obs. of 14 variables: ## $ crim : num 0.00632 0.02731 0.02729 0.03237 0.06905 ... ## $ zn : num 18 0 0 0 0 0 12.5 12.5 12.5 12.5 ... ## $ indus : num 2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ... ## $ chas : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nox : num 0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ... ## $ rm : num 6.58 6.42 7.18 7 7.15 ... ## $ age : num 65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ... ## $ dis : num 4.09 4.97 4.97 6.06 6.06 ... ## $ rad : int 1 2 2 3 3 3 5 5 5 5 ... ## $ tax : num 296 242 242 222 222 222 311 311 311 311 ... ## $ ptratio: num 15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ... ## $ black : num 397 397 393 395 397 ... ## $ lstat : num 4.98 9.14 4.03 2.94 5.33 ... ## $ medv : num 24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ... glmnet 패키지 내 glmnet() 함수를 통해 페널티 회귀분석을 수행할 수 있다. glmnet() 함수는 인자로 결과변수 y는 벡터로 예측변수 x는 행렬 형태로 제공해야 한다. 추가로 연속형 변수만 처리 가능하므로 범주형 변수는 사전에 더미변수로 변환해야 한다. family = 결과변수의 확률분포, gaussian, binomial 등 alpha = 0(Ridge), 1(Lasso), 0~1(ElasticNet) lambda = 패널티 크기 조절, 예측오차를 최소화 하는 람다 설정, 교차검정을 통해 설정 3.16.1.1 Ridge Regression # 최적의 람다 계산 set.seed(123) Boston.cv &lt;- cv.glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0) # Ridge ## Error in cv.glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0): could not find function &quot;cv.glmnet&quot; plot(Boston.cv) ## Error in plot(Boston.cv): object &#39;Boston.cv&#39; not found 왼쪽의 점선은 최적 람다의 로그 값, 상단의 숫자는 예측변수의 개수, Ridge 회귀분석은 회귀계수를 0으로 만들지 않기 때문에 예측변수 개수가 줄어들지 않는다. str(Boston.cv) ## Error in str(Boston.cv): object &#39;Boston.cv&#39; not found cbind(lambda.min = Boston.cv$lambda.min, lambda.min.log = log(Boston.cv$lambda.min)) ## Error in cbind(lambda.min = Boston.cv$lambda.min, lambda.min.log = log(Boston.cv$lambda.min)): object &#39;Boston.cv&#39; not found Boston.gnet &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0, lambda = Boston.cv$lambda.min) ## Error in glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 0, lambda = Boston.cv$lambda.min): could not find function &quot;glmnet&quot; coef(Boston.gnet) ## Error in coef(Boston.gnet): object &#39;Boston.gnet&#39; not found Boston.pred &lt;- predict(Boston.gnet, newx = Boston.test.x) ## Error in predict(Boston.gnet, newx = Boston.test.x): object &#39;Boston.gnet&#39; not found head(Boston.pred) ## Error in head(Boston.pred): object &#39;Boston.pred&#39; not found postResample(pred = Boston.pred, obs = Boston.test.y) ## Error in postResample(pred = Boston.pred, obs = Boston.test.y): object &#39;Boston.pred&#39; not found RMSE와 MAE는 오차 지표로 값이 작을수록, Rsquared는 모델의 설명력 지표로 값이 클수록 우수한 모델이다. 3.16.2 Markdown 문법 https://daringfireball.net/projects/markdown/syntax#p https://www.youtube.com/watch?v=3OEwk2VxZdE&amp;list=PLY0OaF78qqGAxKX91WuRigHpwBU0C2SB_&amp;index=31&amp;t=228s↩︎ "],["til20220317.html", "3.17 TIL20220317", " 3.17 TIL20220317 3.17.1 분산분석 분산분석(analysis of variance, ANOVA)은 여러 모집단 간의 평균의 동일성을 검정한다.11 일원분산분석 (one-way ANOVA) 이원분산분석 (two-way ANOVA) 공분산분석 (analysis of corvariance, ANCOVA) 반복측정 분산분석 (repeated measures ANOVA) 다변량 분산분석 (multivariate analysis of variance, MANOVA) 다변량 공분산분석 (multivariate analysis of covariance, MANCOVA) 3.17.2 페널티 회귀분석 - 2 str(Boston) ## &#39;data.frame&#39;: 506 obs. of 14 variables: ## $ crim : num 0.00632 0.02731 0.02729 0.03237 0.06905 ... ## $ zn : num 18 0 0 0 0 0 12.5 12.5 12.5 12.5 ... ## $ indus : num 2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ... ## $ chas : int 0 0 0 0 0 0 0 0 0 0 ... ## $ nox : num 0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ... ## $ rm : num 6.58 6.42 7.18 7 7.15 ... ## $ age : num 65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ... ## $ dis : num 4.09 4.97 4.97 6.06 6.06 ... ## $ rad : int 1 2 2 3 3 3 5 5 5 5 ... ## $ tax : num 296 242 242 222 222 222 311 311 311 311 ... ## $ ptratio: num 15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ... ## $ black : num 397 397 393 395 397 ... ## $ lstat : num 4.98 9.14 4.03 2.94 5.33 ... ## $ medv : num 24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ... set.seed(123) train.index &lt;- createDataPartition(y = Boston$medv, p = 0.7, list = F) Boston.train &lt;- Boston[train.index, ] Boston.test &lt;- Boston[-train.index, ] Boston.test.x &lt;- model.matrix(medv ~ ., Boston.test)[, -1] Boston.test.y &lt;- Boston.test$medv Boston.split &lt;- rbind(Train.Data = nrow(Boston.train), Test.Data = nrow(Boston.test)) colnames(Boston.split) &lt;- c(&quot;Number&quot;); Boston.split ## Number ## Train.Data 356 ## Test.Data 150 glmnet 패키지 내 glmnet() 함수를 통해 페널티 회귀분석을 수행할 수 있다. glmnet() 함수는 인자로 결과변수 y는 벡터로 예측변수 x는 행렬 형태로 제공해야 한다. 추가로 연속형 변수만 처리 가능하므로 범주형 변수는 사전에 더미변수로 변환해야 한다. family = 결과변수의 확률분포, gaussian, binomial 등 alpha = 0(Ridge), 1(Lasso), 0~1(ElasticNet) lambda = 패널티 크기 조절, 예측오차를 최소화 하는 람다 설정, 교차검정을 통해 설정 if(!require(glmnet)) { install.packages(&quot;glmnet&quot;); library(glmnet); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages # 예측변수 행렬 + 더미변수 생성 x &lt;- model.matrix(medv ~., Boston.train)[, -1] # 불필요한 첫 번째 열 삭제 head(x) ## crim zn indus chas nox rm age dis rad tax ptratio black lstat ## 1 0.00632 18.0 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 ## 4 0.03237 0.0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 2.94 ## 10 0.17004 12.5 7.87 0 0.524 6.004 85.9 6.5921 5 311 15.2 386.71 17.10 ## 12 0.11747 12.5 7.87 0 0.524 6.009 82.9 6.2267 5 311 15.2 396.90 13.27 ## 13 0.09378 12.5 7.87 0 0.524 5.889 39.0 5.4509 5 311 15.2 390.50 15.71 ## 16 0.62739 0.0 8.14 0 0.538 5.834 56.5 4.4986 4 307 21.0 395.62 8.47 # 결과변수 y &lt;- Boston.train$medv 3.17.2.1 Lasso Regression set.seed(123) Boston.cv &lt;- cv.glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 1) # Lasso plot(Boston.cv) 왼쪽의 점선은 예측오차를 최소화하는, 즉 예측 정확도를 가장 크게하는 로그 람다값을 나타낸다. Lasso 회귀분석에서는 영향력이 작은 예측변수의 회귀계수를 0으로 만들어 제거할 수 있다. 우측 상단의 예측변수 개수에서 확인이 가능하다. cbind(lambda.min = Boston.cv$lambda.min, lambda.min.log = log(Boston.cv$lambda.min)) ## lambda.min lambda.min.log ## [1,] 0.01189058 -4.432009 예측 정확도와 모델 간명도를 고려하여 최소 예측 오차의 1개 표준편차 이내에 있으면서 예측변수의 개수를 최소화하는 람다를 제공한다. cbind(lambda.1se = Boston.cv$lambda.1se, lambda.1se.log = log(Boston.cv$lambda.1se)) ## lambda.1se lambda.1se.log ## [1,] 0.3716657 -0.9897604 cbind(lambda.min = coef(Boston.cv, Boston.cv$lambda.min), lambda.1se = coef(Boston.cv, Boston.cv$lambda.1se)) ## 14 x 2 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 s1 ## (Intercept) 32.720731705 16.0297569500 ## crim -0.087271032 -0.0139981876 ## zn 0.027462832 . ## indus -0.045858550 -0.0166198270 ## chas 2.904607308 2.0413930420 ## nox -15.675976627 -2.5456625823 ## rm 3.997011835 4.3113894194 ## age . . ## dis -1.236733449 -0.2334310319 ## rad 0.255230956 . ## tax -0.009918317 -0.0007771602 ## ptratio -0.920530277 -0.7681696792 ## black 0.008606410 0.0061710231 ## lstat -0.481377769 -0.4700816156 lambda.min은 1개의, lambda.1se는 3개의 예측변수가 제거되었다. Boston.gnet1 &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 1, lambda = Boston.cv$lambda.min) Boston.pred1 &lt;- predict(Boston.gnet1, newx = Boston.test.x) postResample(pred = Boston.pred1, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.1150340 0.7197637 3.3091787 Boston.gnet2 &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = 1, lambda = Boston.cv$lambda.1se) Boston.pred2 &lt;- predict(Boston.gnet2, newx = Boston.test.x) postResample(pred = Boston.pred2, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.5656605 0.6795993 3.6151777 3.17.2.2 ElasticNet Regression ElasticNet읜 L2-norm, L1-norm 페널티항을 설정해야 하므로 최적의 alpha값을 산출해야 한다. caret 패키지 내 train() 함수를 이용한다. set.seed(123) Boston.cv &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneLength = 10) Boston.cv$bestTune ## alpha lambda ## 6 0.1 0.2020812 Boston.gnet &lt;- glmnet(x = x, y = y, family = &quot;gaussian&quot;, alpha = Boston.cv$bestTune$alpha, lambda = Boston.cv$bestTune$lambda) coef(Boston.gnet) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s0 ## (Intercept) 29.766401348 ## crim -0.078819914 ## zn 0.021807176 ## indus -0.064680920 ## chas 2.966225220 ## nox -13.617871871 ## rm 4.056442437 ## age . ## dis -1.097715391 ## rad 0.194940136 ## tax -0.007343684 ## ptratio -0.891291598 ## black 0.008443963 ## lstat -0.466614849 Boston.pred &lt;- predict(Boston.gnet, newx = Boston.test.x) postResample(pred = Boston.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.1766444 0.7148912 3.3115941 3.17.3 모델별 비교 lambda &lt;- 10^seq(-1, 5, length = 100) # ridge set.seed(123) ridge &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneGrid = expand.grid(alpha = 0, lambda = lambda)) coef(ridge$finalModel, ridge$bestTune$lambda) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 26.531756149 ## crim -0.074428914 ## zn 0.017800440 ## indus -0.084013662 ## chas 3.079990715 ## nox -10.929321371 ## rm 4.075749392 ## age -0.003350370 ## dis -0.950562016 ## rad 0.143524673 ## tax -0.005528583 ## ptratio -0.844792464 ## black 0.008418506 ## lstat -0.433322899 ridge.pred &lt;- predict(ridge, Boston.test) postResample(pred = ridge.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.2697535 0.7078302 3.3430299 # lasso set.seed(123) lasso &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneGrid = expand.grid(alpha = 1, lambda = lambda)) coef(lasso$finalModel, lasso$bestTune$lambda) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 27.091673886 ## crim -0.057263747 ## zn 0.011752233 ## indus -0.060580843 ## chas 2.817475257 ## nox -11.877653738 ## rm 4.155604866 ## age . ## dis -0.934714973 ## rad 0.114348391 ## tax -0.004015459 ## ptratio -0.877240341 ## black 0.007739894 ## lstat -0.477162631 lasso.pred &lt;- predict(lasso, Boston.test) postResample(pred = lasso.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.245637 0.708739 3.362308 # lasso set.seed(123) elastic &lt;- train(form = medv ~ ., data = Boston.train, method = &quot;glmnet&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 10), tuneLength = 10) coef(elastic$finalModel, elastic$bestTune$lambda) ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 ## (Intercept) 29.765523097 ## crim -0.078486897 ## zn 0.021723671 ## indus -0.064825528 ## chas 2.965478459 ## nox -13.585240410 ## rm 4.054072843 ## age . ## dis -1.097151673 ## rad 0.194485494 ## tax -0.007329651 ## ptratio -0.891156341 ## black 0.008442569 ## lstat -0.467123628 elastic.pred &lt;- predict(elastic, Boston.test) postResample(pred = elastic.pred, obs = Boston.test.y) ## RMSE Rsquared MAE ## 5.1769223 0.7148754 3.3120692 models &lt;- list(ridge = ridge, lasso = lasso, elastic = elastic) summary(resamples(models)) ## ## Call: ## summary.resamples(object = resamples(models)) ## ## Models: ridge, lasso, elastic ## Number of resamples: 10 ## ## MAE ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## ridge 2.314983 3.095864 3.358949 3.350092 3.553519 4.758853 0 ## lasso 2.334122 3.113956 3.355747 3.384424 3.536837 4.889416 0 ## elastic 2.370271 3.091582 3.351099 3.369054 3.544919 4.741635 0 ## ## RMSE ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## ridge 3.217597 4.220445 4.527056 4.702958 5.047501 6.966902 0 ## lasso 3.259155 4.242220 4.489430 4.744627 5.168922 7.113506 0 ## elastic 3.323486 4.222079 4.511393 4.699214 5.056862 6.952270 0 ## ## Rsquared ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## ridge 0.5685060 0.7102964 0.7569726 0.7432102 0.7896808 0.8415753 0 ## lasso 0.5567794 0.6909231 0.7576300 0.7387044 0.7934118 0.8391494 0 ## elastic 0.5743693 0.7076979 0.7608565 0.7432037 0.7831245 0.8450374 0 세 모델이 RMSE 관점에서 비슷한 성능을 보이는 것 같다. 통계적으로 유의한 차이가 있는지 검정해 본다. summary(diff(resamples(models), metric=&quot;RMSE&quot;)) ## ## Call: ## summary.diff.resamples(object = diff(resamples(models), metric = &quot;RMSE&quot;)) ## ## p-value adjustment: bonferroni ## Upper diagonal: estimates of the difference ## Lower diagonal: p-value for H0: difference = 0 ## ## RMSE ## ridge lasso elastic ## ridge -0.041669 0.003744 ## lasso 0.7838 0.045413 ## elastic 1.0000 0.6350 행렬의 대각선 위쪽은 모델간 차이, 아래쪽은 유의확률을 나타낸다. 세 모델 간 통계적 유의한 차이는 없는 것으로 확인된다. 따라서 간명도 관점에서 예측변수의 개수가 적은 모델을 선택하는 것이 바람직하다. https://www.youtube.com/watch?v=BnFkVjjSv6I&amp;list=PLY0OaF78qqGAxKX91WuRigHpwBU0C2SB_&amp;index=11↩︎ "],["til20220318.html", "3.18 TIL20220318", " 3.18 TIL20220318 3.18.1 구미시 선별진료소 구미시 선별진료소12 https://www.mohw.go.kr/react/ncov/selclinic04ls.jsp↩︎ "],["til20220319.html", "3.19 TIL20220319", " 3.19 TIL20220319 3.19.1 일반선형델회귀모델 일반선형회귀모델 \\(f(\\mu \\_y) = \\beta\\_0 + \\beta\\_1 x_1 + \\beta\\_2 x_2 + ... + \\beta\\_n x_n\\) 로지스틱 선형회귀모델 \\(ln( \\frac{p}{1-p} ) = \\beta\\_0 + \\beta\\_1 x_1 + \\beta\\_2 x_2 + ... + \\beta\\_m x_m\\) 포아송 선형회귀모델 \\(ln(\\lambda) = \\beta\\_0 + \\beta\\_1 x_1 + \\beta\\_2 x_2 + ... + \\beta\\_m x_m\\) 3.19.2 이항 로지스틱 회귀분석 결과변수(종속변수)가 이분형 범주를 가질 때 예측변수(독립변수)로부터 결과변수의 범주를 예측한다. if(!require(modeldata)) { install.packages(&quot;modeldata&quot;); library(modeldata); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages data(mlc_churn) str(mlc_churn) ## tibble [5,000 × 20] (S3: tbl_df/tbl/data.frame) ## $ state : Factor w/ 51 levels &quot;AK&quot;,&quot;AL&quot;,&quot;AR&quot;,..: 17 36 32 36 37 2 20 25 19 50 ... ## $ account_length : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ... ## $ area_code : Factor w/ 3 levels &quot;area_code_408&quot;,..: 2 2 2 1 2 3 3 2 1 2 ... ## $ international_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 2 2 2 1 2 1 2 ... ## $ voice_mail_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 1 2 1 1 2 ... ## $ number_vmail_messages : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ... ## $ total_day_minutes : num [1:5000] 265 162 243 299 167 ... ## $ total_day_calls : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ... ## $ total_day_charge : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ... ## $ total_eve_minutes : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ... ## $ total_eve_calls : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ... ## $ total_eve_charge : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ... ## $ total_night_minutes : num [1:5000] 245 254 163 197 187 ... ## $ total_night_calls : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ... ## $ total_night_charge : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ... ## $ total_intl_minutes : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ... ## $ total_intl_calls : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ... ## $ total_intl_charge : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ... ## $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ... ## $ churn : Factor w/ 2 levels &quot;yes&quot;,&quot;no&quot;: 2 2 2 2 2 2 2 2 2 2 ... churn &lt;- mlc_churn[-c(1,3)] churn$churn &lt;- factor(ifelse(churn$churn==&quot;no&quot;, 1, 2), levels=c(1,2), labels=c(&quot;no&quot;, &quot;yes&quot;)) str(churn) ## tibble [5,000 × 18] (S3: tbl_df/tbl/data.frame) ## $ account_length : int [1:5000] 128 107 137 84 75 118 121 147 117 141 ... ## $ international_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 2 2 2 1 2 1 2 ... ## $ voice_mail_plan : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 2 2 1 1 1 1 2 1 1 2 ... ## $ number_vmail_messages : int [1:5000] 25 26 0 0 0 0 24 0 0 37 ... ## $ total_day_minutes : num [1:5000] 265 162 243 299 167 ... ## $ total_day_calls : int [1:5000] 110 123 114 71 113 98 88 79 97 84 ... ## $ total_day_charge : num [1:5000] 45.1 27.5 41.4 50.9 28.3 ... ## $ total_eve_minutes : num [1:5000] 197.4 195.5 121.2 61.9 148.3 ... ## $ total_eve_calls : int [1:5000] 99 103 110 88 122 101 108 94 80 111 ... ## $ total_eve_charge : num [1:5000] 16.78 16.62 10.3 5.26 12.61 ... ## $ total_night_minutes : num [1:5000] 245 254 163 197 187 ... ## $ total_night_calls : int [1:5000] 91 103 104 89 121 118 118 96 90 97 ... ## $ total_night_charge : num [1:5000] 11.01 11.45 7.32 8.86 8.41 ... ## $ total_intl_minutes : num [1:5000] 10 13.7 12.2 6.6 10.1 6.3 7.5 7.1 8.7 11.2 ... ## $ total_intl_calls : int [1:5000] 3 3 5 7 3 6 7 6 4 5 ... ## $ total_intl_charge : num [1:5000] 2.7 3.7 3.29 1.78 2.73 1.7 2.03 1.92 2.35 3.02 ... ## $ number_customer_service_calls: int [1:5000] 1 1 0 2 3 0 3 0 1 0 ... ## $ churn : Factor w/ 2 levels &quot;no&quot;,&quot;yes&quot;: 1 1 1 1 1 1 1 1 1 1 ... churn_train &lt;- churn[1:3333,] churn_test &lt;- churn[3334:5000,] rbind(ChurnTrain = prop.table(table(churn_train$churn)), ChurnTest = prop.table(table(churn_test$churn))) ## no yes ## ChurnTrain 0.8550855 0.1449145 ## ChurnTest 0.8656269 0.1343731 churn_logit &lt;- glm(churn ~ ., data = churn_train, family = binomial(link = &quot;logit&quot;)) summary(churn_logit) ## ## Call: ## glm(formula = churn ~ ., family = binomial(link = &quot;logit&quot;), data = churn_train) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.1532 -0.5132 -0.3402 -0.1953 3.2528 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -8.6515638 0.7243142 -11.944 &lt; 2e-16 *** ## account_length 0.0008458 0.0013912 0.608 0.543199 ## international_planyes 2.0427543 0.1454974 14.040 &lt; 2e-16 *** ## voice_mail_planyes -2.0250146 0.5740840 -3.527 0.000420 *** ## number_vmail_messages 0.0358803 0.0180108 1.992 0.046355 * ## total_day_minutes -0.2441993 3.2742224 -0.075 0.940547 ## total_day_calls 0.0031962 0.0027612 1.158 0.247048 ## total_day_charge 1.5127081 19.2601862 0.079 0.937398 ## total_eve_minutes 0.8186945 1.6357258 0.501 0.616717 ## total_eve_calls 0.0010579 0.0027826 0.380 0.703817 ## total_eve_charge -9.5463678 19.2437266 -0.496 0.619840 ## total_night_minutes -0.1238287 0.8764906 -0.141 0.887650 ## total_night_calls 0.0006993 0.0028419 0.246 0.805628 ## total_night_charge 2.8338084 19.4769043 0.145 0.884319 ## total_intl_minutes -4.3377914 5.3009719 -0.818 0.413185 ## total_intl_calls -0.0929680 0.0250603 -3.710 0.000207 *** ## total_intl_charge 16.3900316 19.6323938 0.835 0.403804 ## number_customer_service_calls 0.5135638 0.0392678 13.079 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 2758.3 on 3332 degrees of freedom ## Residual deviance: 2158.7 on 3315 degrees of freedom ## AIC: 2194.7 ## ## Number of Fisher Scoring iterations: 6 exp(coef(churn_logit)) # 해석상의 용이를 위해 오즈비를 지수변환 함 ## (Intercept) account_length ## 1.748532e-04 1.000846e+00 ## international_planyes voice_mail_planyes ## 7.711821e+00 1.319919e-01 ## number_vmail_messages total_day_minutes ## 1.036532e+00 7.833315e-01 ## total_day_calls total_day_charge ## 1.003201e+00 4.539006e+00 ## total_eve_minutes total_eve_calls ## 2.267538e+00 1.001058e+00 ## total_eve_charge total_night_minutes ## 7.146035e-05 8.835312e-01 ## total_night_calls total_night_charge ## 1.000700e+00 1.701012e+01 ## total_intl_minutes total_intl_calls ## 1.306535e-02 9.112226e-01 ## total_intl_charge number_customer_service_calls ## 1.312503e+07 1.671236e+00 로지스틱 회귀모델의 통계적 유의성은 summary() 함수를 통해 제공되지 않아 직접 계산을 한다. Null deviance와 Residual deviance를 통해 검정할 수 있다. Deviance(이탈도) 모델의 적합도 정도를 나타내는 지표, 이탈도가 적을수록 우수한 모델임 Null deviance는 상수항만을 포함하는 모델이고, Residual deviance는 모든변수를 포함하는 모델이다. 예측변수를 포함될수록 설명력은 좋아지기 때문에 이탈도는 작아질 수밖에 없다. 예측변수에 의해 작아지는 정도가 통계적으로 유의한지를 검정한다. 이탈도는 \\(\\chi^2\\) 분포를 따르므로 \\(\\chi^2\\) 검정 통계량을 계산해서 검정한다. pchisq(q=(2758.3-2158.7), df=(3332-3315), lower.tail = F) ## [1] 1.731898e-116 pchisq(q = (churn_logit$null.deviance - churn_logit$deviance), df = (churn_logit$df.null - churn_logit$df.residual), lower.tail = F) ## [1] 1.757917e-116 churn_logit_pred &lt;- predict(churn_logit, newdata = churn_test, type = &quot;response&quot;) head(churn_logit_pred) ## 1 2 3 4 5 6 ## 0.07236813 0.05774332 0.22650409 0.15289153 0.07078500 0.05880824 churn_logit_pred &lt;- factor(churn_logit_pred &gt; 0.5, levels = c(FALSE, TRUE), labels = c(&quot;no&quot;, &quot;yes&quot;)) head(churn_logit_pred) ## 1 2 3 4 5 6 ## no no no no no no ## Levels: no yes table(churn_logit_pred) ## churn_logit_pred ## no yes ## 1595 72 table(churn_test$churn, churn_logit_pred, dnn=c(&quot;Acutal&quot;, &quot;Predicted&quot;)) ## Predicted ## Acutal no yes ## no 1414 29 ## yes 181 43 mean(churn_test$churn == churn_logit_pred) ## [1] 0.8740252 단계별 변수 선택을 통해 유의한 변수만 선택하만 보다 간결한 모델을 생성할 수 있다. churn_logit2 &lt;- step(churn_logit, trace = F) summary(churn_logit2) ## Error in summary(churn_logit2): class name too long in &#39;summary&#39; pchisq(q = (churn_logit2$null.deviance - churn_logit2$deviance), df = (churn_logit2$df.null - churn_logit2$df.residual), lower.tail = F) ## Error in churn_logit2$null.deviance: class name too long in &#39;$&#39; 특정 예측변수의 변화에 따른 결과변수의 변화를 보기 위해서는 다른 변수를 고정한 후 특정 변수만 변화를 시키면서 결과를 확인할 수 있다. table(churn_test$number_customer_service_calls) ## ## 0 1 2 3 4 5 6 7 ## 326 605 368 236 86 30 12 4 서비스센터 전화회수의 분포는 0 ~ 7번으로 구성되어 있다. 나머지 변수는 평균이나 가장 낮은 변주 유형으로 고정한 데이터셋을 생성한다. testdata &lt;- data.frame( number_customer_service_calls = c(0:7), international_plan = &quot;no&quot;, voice_mail_plan =&quot;no&quot; , number_vmail_messages = mean(churn_test$number_vmail_messages), total_day_charge = mean(churn_test$total_day_charge), total_eve_minutes = mean(churn_test$total_eve_minutes), total_night_charge = mean(churn_test$total_night_charge), total_intl_calls = mean(churn_test$total_intl_calls), total_intl_charge = mean(churn_test$total_intl_charge) ); testdata ## number_customer_service_calls international_plan voice_mail_plan ## 1 0 no no ## 2 1 no no ## 3 2 no no ## 4 3 no no ## 5 4 no no ## 6 5 no no ## 7 6 no no ## 8 7 no no ## number_vmail_messages total_day_charge total_eve_minutes total_night_charge ## 1 7.067786 30.82434 199.9492 8.974559 ## 2 7.067786 30.82434 199.9492 8.974559 ## 3 7.067786 30.82434 199.9492 8.974559 ## 4 7.067786 30.82434 199.9492 8.974559 ## 5 7.067786 30.82434 199.9492 8.974559 ## 6 7.067786 30.82434 199.9492 8.974559 ## 7 7.067786 30.82434 199.9492 8.974559 ## 8 7.067786 30.82434 199.9492 8.974559 ## total_intl_calls total_intl_charge ## 1 4.346731 2.784421 ## 2 4.346731 2.784421 ## 3 4.346731 2.784421 ## 4 4.346731 2.784421 ## 5 4.346731 2.784421 ## 6 4.346731 2.784421 ## 7 4.346731 2.784421 ## 8 4.346731 2.784421 testdata$prob &lt;- predict(churn_logit2, newdata = testdata, type = &quot;response&quot;) ## Error in predict(churn_logit2, newdata = testdata, type = &quot;response&quot;): class name too long in &#39;predict&#39; testdata[c(1,10)] ## Error in `[.data.frame`(testdata, c(1, 10)): undefined columns selected 이항 로지스틱분석은 과산포의 문제를 확인해야 한다. 결과변수의 실제 관측된 분산이 이항분포의 기대되는 분산보다 더 클 때 발생한다. 과산포는 표준오차를 왜곡시켜 회귀계수의 유의성 검정을 부정확하게 만들 위험성이 있다. 과산포 발생 시 family 인수에 quasibinomial() 함수를 적용한다. 과산포를 확인하는 방법은 이탈도와 자유도간의 비율을 살펴본다. 이탈도대 자유도의 비율이 1을 크게 상외하면 과산포를 의심한다. deviance(churn_logit2) / df.residual(churn_logit2) ## Error in deviance(churn_logit2): class name too long in &#39;deviance&#39; 또는 binomial()와 quasibinomial() 함수를 적용한 모델을 생성하고 통계적으로 유의성을 검정하는 방법도 있다. fit.origin1 &lt;- glm(churn ~ number_customer_service_calls + international_plan + voice_mail_plan + number_vmail_messages + total_day_charge + total_eve_minutes + total_night_charge + total_intl_calls + total_intl_charge, data = churn_train, family = binomial(link = &quot;logit&quot;)) fit.origin2 &lt;- glm(churn ~ number_customer_service_calls + international_plan + voice_mail_plan + number_vmail_messages + total_day_charge + total_eve_minutes + total_night_charge + total_intl_calls + total_intl_charge, data = churn_train, family = quasibinomial(link = &quot;logit&quot;)) pchisq(summary(fit.origin2)$dispersion*fit.origin1$df.residual, fit.origin1$df.residual, lower.tail = F) ## [1] 0.08385493 위 예제에서는 p값이 0.08385493로 유의수준 0.05에서 통계적으로 과산포의 가능성은 작다고 볼 수 있다. 3.19.3 패널티 로지스틱회귀분석 3.16 참고 당뇨평(diabetes) 여부를 예측하는 모델을 생성한다. if(!require(mlbench)) { install.packages(&quot;mlbench&quot;); library(mlbench); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages data(&quot;PimaIndiansDiabetes2&quot;) str(PimaIndiansDiabetes2) ## &#39;data.frame&#39;: 768 obs. of 9 variables: ## $ pregnant: num 6 1 8 1 0 5 3 10 2 8 ... ## $ glucose : num 148 85 183 89 137 116 78 115 197 125 ... ## $ pressure: num 72 66 64 66 40 74 50 NA 70 96 ... ## $ triceps : num 35 29 NA 23 35 NA 32 NA 45 NA ... ## $ insulin : num NA NA NA 94 168 NA 88 NA 543 NA ... ## $ mass : num 33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 NA ... ## $ pedigree: num 0.627 0.351 0.672 0.167 2.288 ... ## $ age : num 50 31 32 21 33 30 26 29 53 54 ... ## $ diabetes: Factor w/ 2 levels &quot;neg&quot;,&quot;pos&quot;: 2 1 2 1 2 1 2 1 2 2 ... # 결측치 제거하는 전처리 PimaIndiansDiabetes3 &lt;- na.omit(PimaIndiansDiabetes2) if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } set.seed(123) train.index &lt;- createDataPartition(y = PimaIndiansDiabetes3$diabetes, p = 0.7, list = F) diabetes.train &lt;- PimaIndiansDiabetes3[train.index, ] diabetes.test &lt;- PimaIndiansDiabetes3[-train.index, ] class.status &lt;- rbind( Train = prop.table(table(diabetes.train$diabetes)), Test = prop.table(table(diabetes.test$diabetes)) ); colnames(class.status) &lt;- c(&quot;Negative&quot;, &quot;Positive&quot;); class.status ## Negative Positive ## Train 0.6690909 0.3309091 ## Test 0.6666667 0.3333333 # 예측오차를 최소로 하는 최적의 lambda 계산 if(!require(glmnet)) { install.packages(&quot;glmnet&quot;); library(glmnet); } x &lt;- model.matrix(diabetes ~ ., diabetes.train)[, -1] y &lt;- ifelse(diabetes.train$diabetes == &quot;pos&quot;, 1, 0) test.x &lt;- model.matrix(diabetes ~ ., diabetes.test)[, -1] test.y &lt;- diabetes.test$diabetes diabetes.cv &lt;- cv.glmnet(x, y, family = &quot;binomial&quot;, alpha = 1) # lasso 회귀모델 diabetes.lambda &lt;- cbind(lambda.min = diabetes.cv$lambda.min, lambda.1se = diabetes.cv$lambda.1se) rownames(diabetes.lambda) &lt;- c(&quot;value&quot;); diabetes.lambda ## lambda.min lambda.1se ## value 0.01578334 0.05289948 cbind(lambda.min = coef(diabetes.cv, diabetes.cv$lambda.min), lambda.1se = coef(diabetes.cv, diabetes.cv$lambda.1se) ) ## 9 x 2 sparse Matrix of class &quot;dgCMatrix&quot; ## s1 s1 ## (Intercept) -8.747546342 -5.9547905277 ## pregnant 0.001210910 . ## glucose 0.033473180 0.0281738015 ## pressure . . ## triceps 0.025187290 0.0149718685 ## insulin 0.001292712 0.0002823976 ## mass 0.038416286 0.0146328065 ## pedigree 1.025851783 0.3927570506 ## age 0.029786375 0.0153986131 예측 오차를 최소로 하는 lambda를 사용하여 모델을 생성한 후 성능을 평가한다. diabets.gnet.min &lt;- glmnet(x, y, family = &quot;binomial&quot;, alpha = 1, lambda = diabetes.cv$lambda.min) diabets.gnet.min.pred &lt;- predict(diabets.gnet.min, test.x, type=&quot;response&quot;) diabets.gnet.min.pred &lt;- ifelse(diabets.gnet.min.pred &gt; 0.5, &quot;pos&quot;, &quot;neg&quot;) table(test.y, diabets.gnet.min.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Predicted ## Actual neg pos ## neg 69 9 ## pos 20 19 mean(test.y == diabets.gnet.min.pred) ## [1] 0.7521368 간명도를 고려한 1se lambda를 사용하여 모델을 생성한 후 성능을 평가한다. diabets.gnet.1se &lt;- glmnet(x, y, family = &quot;binomial&quot;, alpha = 1, lambda = diabetes.cv$lambda.1se) diabets.gnet.1se.pred &lt;- predict(diabets.gnet.1se, test.x, type=&quot;response&quot;) diabets.gnet.1se.pred &lt;- ifelse(diabets.gnet.1se.pred &gt; 0.5, &quot;pos&quot;, &quot;neg&quot;) table(test.y, diabets.gnet.1se.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Predicted ## Actual neg pos ## neg 71 7 ## pos 21 18 mean(test.y == diabets.gnet.min.pred) ## [1] 0.7521368 모든 예측변수를 사용한 이항 로지스틱회귀모델을 생성하고 성능을 평가한다. diabetes.logit &lt;- glm(diabetes ~ ., data = diabetes.train, family = binomial(link = &quot;logit&quot;)) diabetes.logit.pred &lt;- predict(diabetes.logit, diabetes.test, type = &quot;response&quot;) diabetes.logit.pred &lt;- ifelse(diabetes.logit.pred &gt; 0.5, &quot;pos&quot;, &quot;neg&quot;) table(diabetes.test$diabetes, diabetes.logit.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Predicted ## Actual neg pos ## neg 66 12 ## pos 20 19 mean(diabetes.test$diabetes == diabetes.logit.pred) ## [1] 0.7264957 최종 모델별 예측정확도는 다음과 같고 간명도 관점에서 1se lambda를 이용한 모델을 선택하는 것이 바람직 하다. perf.stats &lt;- rbind( lambda.min = mean(test.y == diabets.gnet.min.pred), lambda.1se = mean(test.y == diabets.gnet.1se.pred), predictor.all = mean(diabetes.test$diabetes == diabetes.logit.pred) ); colnames(perf.stats) &lt;- c(&quot;Accuracy&quot;); perf.stats ## Accuracy ## lambda.min 0.7521368 ## lambda.1se 0.7606838 ## predictor.all 0.7264957 "],["til20220320.html", "3.20 TIL20220320", " 3.20 TIL20220320 3.20.1 다항 로지스틱회귀분석 세 개 이상의 범주를 갖는 결과변수의 사건발생확률을 예측한다. if(!require(EffectStars)) { install.packages(&quot;EffectStars&quot;); library(EffectStars); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages data(PID) str(PID) ## &#39;data.frame&#39;: 944 obs. of 6 variables: ## $ TVnews : int 7 1 7 4 7 3 7 1 7 0 ... ## $ PID : Factor w/ 3 levels &quot;Democrat&quot;,&quot;Independent&quot;,..: 3 1 1 1 1 1 1 2 2 1 ... ## $ Income : num 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 1.5 ... ## $ Education : Factor w/ 2 levels &quot;low&quot;,&quot;high&quot;: 1 2 2 2 2 2 2 2 2 1 ... ## $ Age : int 36 20 24 28 68 21 77 21 31 39 ... ## $ Population: int 0 190 31 83 640 110 100 31 180 2800 ... levels(PID$PID) ## [1] &quot;Democrat&quot; &quot;Independent&quot; &quot;Republican&quot; if(!require(VGAM)) { install.packages(&quot;VGAM&quot;); library(VGAM); } pid.mlogit &lt;- vglm(PID ~ ., family = multinomial(), data = PID) summary(pid.mlogit) ## ## Call: ## vglm(formula = PID ~ ., family = multinomial(), data = PID) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept):1 1.2296119 0.3031106 4.057 4.98e-05 *** ## (Intercept):2 0.1275830 0.3405777 0.375 0.70795 ## TVnews:1 0.0440935 0.0321897 1.370 0.17075 ## TVnews:2 0.0247123 0.0350497 0.705 0.48077 ## Income:1 -0.0165464 0.0027760 -5.960 2.51e-09 *** ## Income:2 -0.0002418 0.0027864 -0.087 0.93085 ## Educationhigh:1 -0.2886055 0.1759813 -1.640 0.10101 ## Educationhigh:2 -0.3530642 0.1971199 -1.791 0.07328 . ## Age:1 -0.0077751 0.0052743 -1.474 0.14044 ## Age:2 -0.0066722 0.0059864 -1.115 0.26503 ## Population:1 0.0002592 0.0000984 2.634 0.00844 ** ## Population:2 0.0002052 0.0001053 1.949 0.05135 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Names of linear predictors: log(mu[,1]/mu[,3]), log(mu[,2]/mu[,3]) ## ## Residual deviance: 1969.38 on 1876 degrees of freedom ## ## Log-likelihood: -984.6901 on 1876 degrees of freedom ## ## Number of Fisher scoring iterations: 4 ## ## No Hauck-Donner effect found in any of the estimates ## ## ## Reference group is level 3 of the response vglm() 함수는 마지막 범주를 기준범주로 사용한다. exp(coef(pid.mlogit)) ## (Intercept):1 (Intercept):2 TVnews:1 TVnews:2 Income:1 ## 3.4199020 1.1360792 1.0450800 1.0250202 0.9835898 ## Income:2 Educationhigh:1 Educationhigh:2 Age:1 Age:2 ## 0.9997582 0.7493078 0.7025321 0.9922550 0.9933500 ## Population:1 Population:2 ## 1.0002592 1.0002052 pid.mlogit.pred &lt;- fitted(pid.mlogit) head(pid.mlogit.pred) ## Democrat Independent Republican ## 1 0.6247928 0.1932306 0.1819766 ## 2 0.5739020 0.1817883 0.2443097 ## 3 0.6109039 0.1745194 0.2145766 ## 4 0.5843473 0.1772105 0.2384421 ## 5 0.5839453 0.1694467 0.2466080 ## 6 0.5856824 0.1794368 0.2348808 교육수준에 정치 성향에 미치는 영향을 보고 위해 교육수준은 변화시키고 나머지 예측변수는 고정된 데이터셋을 생성한다. testdata &lt;- data.frame( Education = c(&quot;low&quot;, &quot;high&quot;), TVnews = mean(PID$TVnews), Income = mean(PID$Income), Age = mean(PID$Age), Population = mean(PID$Population) ); testdata; ## Education TVnews Income Age Population ## 1 low 3.727754 46.57574 47.04343 306.3814 ## 2 high 3.727754 46.57574 47.04343 306.3814 pid.mlogit.pred &lt;- predict(pid.mlogit, newdata = testdata, type=&quot;response&quot;) cbind(testdata, pid.mlogit.pred) ## Education TVnews Income Age Population Democrat Independent ## 1 low 3.727754 46.57574 47.04343 306.3814 0.4169951 0.2852971 ## 2 high 3.727754 46.57574 47.04343 306.3814 0.3854667 0.2472630 ## Republican ## 1 0.2977078 ## 2 0.3672703 교육수준이 low -&gt; higt로 변화하면 Democrat일 확률이 감소하고, Republican일 확률이 증가하는 것을 볼 수 있다. 하지만 교육수준의 변화와 상관없이 항상 Democrate으로 예측할 확률이 가장 높기 때문에 교육수준과 성치성향과의 명확한 관계가 있다고 판단하기는 어렵다. 이는 교육수준의 회귀계수가 통계적으로 유의하지 않다는 것을 의미하기도 한다. 소득수준을 기준으로 같은 분석을 진행한다. range(PID$Income) ## [1] 1.5 115.0 testdata &lt;- data.frame( Education = rep(&quot;low&quot;, 5), TVnews = mean(PID$TVnews), Income = seq(20, 100, 20), Age = mean(PID$Age), Population = mean(PID$Population) ); testdata; ## Education TVnews Income Age Population ## 1 low 3.727754 20 47.04343 306.3814 ## 2 low 3.727754 40 47.04343 306.3814 ## 3 low 3.727754 60 47.04343 306.3814 ## 4 low 3.727754 80 47.04343 306.3814 ## 5 low 3.727754 100 47.04343 306.3814 pid.mlogit.pred &lt;- predict(pid.mlogit, newdata = testdata, type=&quot;response&quot;) cbind(testdata, pid.mlogit.pred) ## Education TVnews Income Age Population Democrat Independent ## 1 low 3.727754 20 47.04343 306.3814 0.5253435 0.2330383 ## 2 low 3.727754 40 47.04343 306.3814 0.4434690 0.2725630 ## 3 low 3.727754 60 47.04343 306.3814 0.3645531 0.3104445 ## 4 low 3.727754 80 47.04343 306.3814 0.2923033 0.3448868 ## 5 low 3.727754 100 47.04343 306.3814 0.2292065 0.3747050 ## Republican ## 1 0.2416182 ## 2 0.2839680 ## 3 0.3250024 ## 4 0.3628100 ## 5 0.3960885 소득의 수준에 따른 정치성향이 다른 것을 알 수 있다. if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } str(fgl) # 유리 조각에 대한 성분 ## &#39;data.frame&#39;: 214 obs. of 10 variables: ## $ RI : num 3.01 -0.39 -1.82 -0.34 -0.58 ... ## $ Na : num 13.6 13.9 13.5 13.2 13.3 ... ## $ Mg : num 4.49 3.6 3.55 3.69 3.62 3.61 3.6 3.61 3.58 3.6 ... ## $ Al : num 1.1 1.36 1.54 1.29 1.24 1.62 1.14 1.05 1.37 1.36 ... ## $ Si : num 71.8 72.7 73 72.6 73.1 ... ## $ K : num 0.06 0.48 0.39 0.57 0.55 0.64 0.58 0.57 0.56 0.57 ... ## $ Ca : num 8.75 7.83 7.78 8.22 8.07 8.07 8.17 8.24 8.3 8.4 ... ## $ Ba : num 0 0 0 0 0 0 0 0 0 0 ... ## $ Fe : num 0 0 0 0 0 0.26 0 0 0 0.11 ... ## $ type: Factor w/ 6 levels &quot;WinF&quot;,&quot;WinNF&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... levels(fgl$type) # (6개의 유리 유형) ## [1] &quot;WinF&quot; &quot;WinNF&quot; &quot;Veh&quot; &quot;Con&quot; &quot;Tabl&quot; &quot;Head&quot; # 변수 값의 범위가 다양하여 표준화하는 전처리 진행 fgl.scaled &lt;- cbind(scale(fgl[, 1:9]), fgl[10]) set.seed(123) train &lt;- sample(nrow(fgl), 0.7*nrow(fgl)) fgl.train &lt;- fgl.scaled[train, ] fgl.test &lt;- fgl.scaled[-train, ] rbind(Train = table(fgl.train$type), Test = table(fgl.train$type)) ## WinF WinNF Veh Con Tabl Head ## Train 48 54 10 11 5 21 ## Test 48 54 10 11 5 21 if(!require(nnet)) { install.packages(&quot;nnet&quot;); library(nnet); } fgl.mlogit &lt;- multinom(type ~ ., data = fgl.train, trace = 0) summary(fgl.mlogit) ## Call: ## multinom(formula = type ~ ., data = fgl.train, trace = 0) ## ## Coefficients: ## (Intercept) RI Na Mg Al ## WinNF 9.355295e-02 -0.8953382 -4.063962 -9.048398 -0.5114149 ## Veh -1.133317e+03 -8.6962954 -5.829434 -7.471188 -3.8837185 ## Con -1.775676e+03 809.3073019 -1498.700239 -5267.689197 2633.0124594 ## Tabl -5.707417e+03 1503.0305126 3453.631583 402.083873 4796.9312894 ## Head -3.440740e+03 3973.2180820 2766.948337 -567.865018 6106.0668610 ## Si K Ca Ba Fe ## WinNF -4.762664 -5.224543 -7.036873 -6.887587 0.3130040 ## Veh -9.568647 -8.386972 -2.916572 -3210.962581 0.2369889 ## Con 411.127579 -2096.906955 -3215.489974 3890.713665 -1142.1918831 ## Tabl 2213.126389 -5318.320092 850.190517 356.705595 -4547.5583934 ## Head 5085.219769 463.552740 -641.047023 4867.920523 -1662.5175407 ## ## Std. Errors: ## (Intercept) RI Na Mg Al Si K ## WinNF 2.250252 1.199628 2.399749 4.300370 1.600933 2.240364 2.512023 ## Veh 1.639861 2.688003 3.037652 5.870651 2.192671 3.194121 3.509944 ## Con 13.950757 10.090718 4.104262 13.278437 15.332909 3.331481 62.182580 ## Tabl 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ## Head 5.158491 8.757124 2.576395 9.600709 16.273983 12.993265 45.186352 ## Ca Ba Fe ## WinNF 4.440853 6.3418754 0.2713187 ## Veh 5.911691 0.5773154 0.4929929 ## Con 12.352283 16.6950553 7.2049922 ## Tabl 0.000000 0.0000000 0.0000000 ## Head 7.347112 1.8160539 3.0181253 ## ## Residual Deviance: 140.2764 ## AIC: 240.2764 multinom() 함수는 첫 번째 범주를 기준 범주로 사용한다. 회귀계수에 대한 유의확률을 제공하지 않아 별도로 계산을 해야 한다. 회귀계수를 표준오차로 나눠서 z 값을 계산하고 이 z 값으로 유의확률을 계산한다. z &lt;- summary(fgl.mlogit)$coefficients/summary(fgl.mlogit)$standard.errors p &lt;- (1- pnorm(abs(z), 0, 1))*2 print(p, digit=3) ## (Intercept) RI Na Mg Al Si K Ca Ba Fe ## WinNF 0.967 0.45546 0.0904 0.0354 0.7494 0.03352 0.0375 0.113 0.277 0.249 ## Veh 0.000 0.00122 0.0550 0.2031 0.0765 0.00274 0.0169 0.622 0.000 0.631 ## Con 0.000 0.00000 0.0000 0.0000 0.0000 0.00000 0.0000 0.000 0.000 0.000 ## Tabl 0.000 0.00000 0.0000 0.0000 0.0000 0.00000 0.0000 0.000 0.000 0.000 ## Head 0.000 0.00000 0.0000 0.0000 0.0000 0.00000 0.0000 0.000 0.000 0.000 fgl.mlogit.pred &lt;- predict(fgl.mlogit, fgl.test, type = &quot;response&quot;) ## Error in match.arg(type): &#39;arg&#39; should be one of &quot;class&quot;, &quot;probs&quot; head(fgl.mlogit.pred) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;fgl.mlogit.pred&#39; not found cbind(round(fgl.mlogit.pred, 3), fgl.test[&quot;type&quot;]) ## Error in cbind(round(fgl.mlogit.pred, 3), fgl.test[&quot;type&quot;]): object &#39;fgl.mlogit.pred&#39; not found fgl.mlogit.pred &lt;- colnames(fgl.mlogit.pred)[max.col(fgl.mlogit.pred)] ## Error in is.data.frame(x): object &#39;fgl.mlogit.pred&#39; not found head(fgl.mlogit.pred) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: object &#39;fgl.mlogit.pred&#39; not found table(fgl.test$type, fgl.mlogit.pred, dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Error in table(fgl.test$type, fgl.mlogit.pred, dnn = c(&quot;Actual&quot;, &quot;Predicted&quot;)): object &#39;fgl.mlogit.pred&#39; not found table(fgl.test$type, factor(fgl.mlogit.pred, levels=levels(fgl.test$type), labels=levels(fgl.test$type)), dnn=c(&quot;Actual&quot;, &quot;Predicted&quot;)) ## Error in factor(fgl.mlogit.pred, levels = levels(fgl.test$type), labels = levels(fgl.test$type)): object &#39;fgl.mlogit.pred&#39; not found mean(fgl.test$type == fgl.mlogit.pred) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;fgl.mlogit.pred&#39; not found 100번의 교차 검정을 통해 보다 안정적인 예측 정확도를 계산한다. fgl.mlogit.cv &lt;- numeric() for(i in 1:100) { train &lt;- sample(nrow(fgl), 0.7*nrow(fgl)) fgl.train &lt;- fgl.scaled[train, ] fgl.test &lt;- fgl.scaled[-train, ] fgl.mlogit &lt;- multinom(type ~ ., data = fgl.train, trace = 0) fgl.mlogit.pred &lt;- predict(fgl.mlogit, fgl.test, type = &quot;probs&quot;) fgl.mlogit.pred &lt;- colnames(fgl.mlogit.pred)[max.col(fgl.mlogit.pred)] fgl.mlogit.cv[i] &lt;- mean(fgl.test$type == fgl.mlogit.pred) } summary(fgl.mlogit.cv) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4308 0.5692 0.6000 0.6063 0.6346 0.7538 boxplot(fgl.mlogit.cv, horizontal = T, col=&quot;tomato&quot;, xlab=&quot;Accuracy&quot;, main = &quot;Accuracy for Forensic Glass (100 samples)&quot;) # fgl.mlogit &lt;- vglm(type ~ ., family = multinomial(), data = fgl.train) # fgl.mlogit.pred &lt;- predict(fgl.mlogit, newdata = fgl.test, type=&quot;response&quot;) # fgl.mlogit.pred &lt;- colnames(fgl.mlogit.pred)[max.col(fgl.mlogit.pred)] # mean(fgl.test$type == fgl.mlogit.pred) "],["til20220321.html", "3.21 TIL20220321", " 3.21 TIL20220321 3.21.1 가설검정 3.21.1.1 범주형 데이터 3.21.1.1.1 한 집단일 때 일원 카이 제곱 검정 one sample \\(x^2\\) test, 적합성 검정에활용 # 주사위를 60번 던져 때, 기대빈도와 관측빈도가 적합한지 검정 # 귀무가설: 기대빈도와 관측빈도는 차이가 없다 # 대립가설: 기대빈도와 관측빈도는 차이가 있다. chisq.test(c(4,6,17,15,9,9), p = rep(1/6, 6)) ## ## Chi-squared test for given probabilities ## ## data: c(4, 6, 17, 15, 9, 9) ## X-squared = 12.8, df = 5, p-value = 0.02533 p값에 따라 유의수준 0.05에서 귀무가설을 기각하고 대립가설을 채택한다. 즉 주사위의 기대빈도와 관측빈도에는 차이가 있다고 판단할 수 있다. # 통신 3사 점유율 차이 40%, 30%, 30%인지 검정 chisq.test(c(45, 30, 25), p = c(0.4, 0.3, 0.3)) ## ## Chi-squared test for given probabilities ## ## data: c(45, 30, 25) ## X-squared = 1.4583, df = 2, p-value = 0.4823 3.21.1.1.2 두 집단일 때 이원 카이 제곱 검정 if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } chisq.test(x=penguins$species, y=penguins$island) ## ## Pearson&#39;s Chi-squared test ## ## data: penguins$species and penguins$island ## X-squared = 299.55, df = 4, p-value &lt; 2.2e-16 if(!require(gmodels)) { install.packages(&quot;gmodels&quot;); library(gmodels); } CrossTable(x=penguins$species, y=penguins$island, chisq = T) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 344 ## ## ## | penguins$island ## penguins$species | Biscoe | Dream | Torgersen | Row Total | ## -----------------|-----------|-----------|-----------|-----------| ## Adelie | 44 | 56 | 52 | 152 | ## | 12.313 | 0.027 | 36.661 | | ## | 0.289 | 0.368 | 0.342 | 0.442 | ## | 0.262 | 0.452 | 1.000 | | ## | 0.128 | 0.163 | 0.151 | | ## -----------------|-----------|-----------|-----------|-----------| ## Chinstrap | 0 | 68 | 0 | 68 | ## | 33.209 | 77.157 | 10.279 | | ## | 0.000 | 1.000 | 0.000 | 0.198 | ## | 0.000 | 0.548 | 0.000 | | ## | 0.000 | 0.198 | 0.000 | | ## -----------------|-----------|-----------|-----------|-----------| ## Gentoo | 124 | 0 | 0 | 124 | ## | 66.463 | 44.698 | 18.744 | | ## | 1.000 | 0.000 | 0.000 | 0.360 | ## | 0.738 | 0.000 | 0.000 | | ## | 0.360 | 0.000 | 0.000 | | ## -----------------|-----------|-----------|-----------|-----------| ## Column Total | 168 | 124 | 52 | 344 | ## | 0.488 | 0.360 | 0.151 | | ## -----------------|-----------|-----------|-----------|-----------| ## ## ## Statistics for All Table Factors ## ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 299.5503 d.f. = 4 p = 1.354574e-63 ## ## ## 3.21.1.1.3 피셔 정확 검정 분할표를 그린 뒤 카이 제곱을 적용할 때 표본 수가 적거나 표본이 분팔표의 셀에 매우 치우치게 분포되어 있다면 카이 제곱 검정의 결과가 부정확할 수 있다. 기대 빈도가 5 이하인 셀이 전체의 20% 수준일 때 표본의 수가 적다고 볼 수 있다. 이런 경우 Fisher’s Exact Test를 적용한다. if(!require(MASS)) { install.packages(&quot;MASS&quot;); library(MASS); } xtabs( ~ W.Hnd + Clap, data = survey) ## Clap ## W.Hnd Left Neither Right ## Left 9 5 4 ## Right 29 45 143 chisq.test(survey$W.Hnd, survey$Clap) ## ## Pearson&#39;s Chi-squared test ## ## data: survey$W.Hnd and survey$Clap ## X-squared = 19.252, df = 2, p-value = 6.598e-05 fisher.test(survey$W.Hnd, survey$Clap) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: survey$W.Hnd and survey$Clap ## p-value = 0.0001413 ## alternative hypothesis: two.sided 3.21.1.1.4 맥니마 검정 (McNemar Test) 사건 전후의 차이 검정에 활용된다. Performance &lt;- matrix(c(794, 86, 150, 570), nrow = 2, dimnames = list( &quot;1st Survey&quot; = c(&quot;Approve&quot;, &quot;Disapprove&quot;), &quot;2nd Survey&quot; = c(&quot;Approve&quot;, &quot;Disapprove&quot;))) Performance ## 2nd Survey ## 1st Survey Approve Disapprove ## Approve 794 150 ## Disapprove 86 570 mcnemar.test(Performance) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: Performance ## McNemar&#39;s chi-squared = 16.818, df = 1, p-value = 4.115e-05 p값에 따라 첫번째 조사와 두번째 조사 간에는 유의확률 0.05 하에서 통계적으로 유의미한 차이가 있다. 참고로, 사건 전후의 차이 검정은 b=c를 검토하여 변화 여부를 판단할 수 있다. \\[b \\sim B(b+c, \\frac{1}{2})\\] 따라서 위 예제의 경우 86 ~ B(86+150, 1/2)를 검토한다. binom.test(86, 86+150, 0.5) ## ## Exact binomial test ## ## data: 86 and 86 + 150 ## number of successes = 86, number of trials = 236, p-value = 3.716e-05 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.3029404 0.4293268 ## sample estimates: ## probability of success ## 0.3644068 3.21.1.2 연속형 데이터 3.21.1.2.1 정규성 검정 3.21.1.2.1.1 shapiro.test() shapiro.test(rnorm(1000)) ## ## Shapiro-Wilk normality test ## ## data: rnorm(1000) ## W = 0.99841, p-value = 0.4971 3.21.1.2.1.2 ks.test() 콜모고로프 스미르노프 검정(Kolmogorov-Smirnov Test), 두 숫자 벡터 간의 차이가 없는지를 검정한다. ks.test(rnorm(100), rnorm(100)) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: rnorm(100) and rnorm(100) ## D = 0.1, p-value = 0.6994 ## alternative hypothesis: two-sided ks.test(rnorm(100), runif(100)) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: rnorm(100) and runif(100) ## D = 0.54, p-value = 4.335e-13 ## alternative hypothesis: two-sided x를 정규분포에서 추출하였는지 검정을 할 수도 있다. ks.test(rnorm(1000), &quot;pnorm&quot;, 0 ,1) ## ## One-sample Kolmogorov-Smirnov test ## ## data: rnorm(1000) ## D = 0.037474, p-value = 0.1206 ## alternative hypothesis: two-sided ks.test(runif(1000), &quot;pnorm&quot;, c(0, 1)) ## ## One-sample Kolmogorov-Smirnov test ## ## data: runif(1000) ## D = 0.50021, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided 3.21.1.2.1.3 qqplot() x &lt;- rnorm(1000, mean = 10, sd = 1) qqnorm(x); qqline(x, lty=2, col = &quot;blue&quot;) x &lt;- runif(1000) qqnorm(x); qqline(x, lty=2, col = &quot;red&quot;) qqplot(runif(1000, min=1, max=10), 1:10) qqplot(rnorm(1000), 1:1000) 3.21.1.2.2 한 집단일 때 3.21.1.2.2.1 one sample t-test 3.21.1.2.2.1.1 정규성을 만족할 경우 t.test() 3.21.1.2.2.1.2 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon signed rank test 3.21.1.2.3 두 집단일 때 3.21.1.2.3.1 independent two sample t-test 3.21.1.2.3.1.1 정규성을 만족할 경우 t.test() 3.21.1.2.3.1.2 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon rank sum test 3.21.1.2.3.2 paired two sample t-test 3.21.1.2.3.2.1 정규성을 만족할 경우 t.test() 3.21.1.2.3.2.2 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon signed rank test with paired 3.21.1.2.4 세 집단 이상일 때 3.21.1.2.4.0.1 정규성을 만족할 경우 aov() 3.21.1.2.4.0.2 정규성을 만족하지 못할 경우 kruskal() 3.21.1.2.4.0.3 사후검정 Fisher’s LSD, Bonferroni, Shelf, Turkey, Duncan 등 3.21.2 비율검정 3.21.2.1 일표본 binom.test() 3.21.2.2 이표본 prop.test() 3.21.3 동질성 검사 3.21.3.1 이표본 var.test() 3.21.3.2 삼표본 이상 bartlett.test() "],["til20220322.html", "3.22 TIL20220322", " 3.22 TIL20220322 3.22.1 비모수 검정 if(!require(moonBook)) { install.packages(&quot;moonBook&quot;); library(moonBook); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } data &lt;- penguins densityplot(body_mass_g ~ sex, data = data) 정규성 검정 shapiro.test(data$body_mass_g) ## ## Shapiro-Wilk normality test ## ## data: data$body_mass_g ## W = 0.95921, p-value = 3.679e-08 Wilcoxon Rank Sum Test wilcox.result &lt;- wilcox.test(body_mass_g ~ sex, data); wilcox.result ## ## Wilcoxon rank sum test with continuity correction ## ## data: body_mass_g by sex ## W = 6874.5, p-value = 1.813e-15 ## alternative hypothesis: true location shift is not equal to 0 Kruskal-Wallis Rank Sun Test kruskal.result &lt;- kruskal.test(body_mass_g ~ species, data); kruskal.result ## ## Kruskal-Wallis rank sum test ## ## data: body_mass_g by species ## Kruskal-Wallis chi-squared = 217.6, df = 2, p-value &lt; 2.2e-16 다중비교 mctp in nparcomp package if(!require(nparcomp)) { install.packages(&quot;nparcomp&quot;); library(nparcomp); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages mctp(body_mass_g ~ species, data) ## ## #----------------Nonparametric Multiple Comparisons for relative effects---------------# ## ## - Alternative Hypothesis: True differences of relative effects are not equal to 0 ## - Estimation Method: Global Pseudo Ranks ## - Type of Contrast : Tukey ## - Confidence Level: 95 % ## - Method = Fisher with 143 DF ## ## #--------------------------------------------------------------------------------------# ## ## $Data.Info ## Sample Size Effect Lower Upper ## 1 Adelie 151 0.3306848 0.3079187 0.3542725 ## 2 Chinstrap 68 0.3483905 0.3252036 0.3723185 ## 3 Gentoo 123 0.8209247 0.8149834 0.8267158 ## ## $Contrast ## 1 2 3 ## 2 - 1 -1 1 0 ## 3 - 1 -1 0 1 ## 3 - 2 0 -1 1 ## ## $Analysis ## Estimator Lower Upper Statistic p.Value ## 2 - 1 0.018 -0.044 0.080 0.628 0.7107447 ## 3 - 1 0.490 0.457 0.522 27.622 0.0000000 ## 3 - 2 0.473 0.438 0.506 25.876 0.0000000 ## ## $Analysis.Inf ## Estimator Lower Upper Statistic p.Value ## 2 - 1 0.0177057 -0.04437702 0.0796522 0.627583 0.7107447 ## 3 - 1 0.4902399 0.45709074 0.5220290 27.621509 0.0000000 ## 3 - 2 0.4725342 0.43792131 0.5057482 25.875668 0.0000000 ## ## $Overall ## Quantile p.Value ## 1 2.201406 0 ## ## $input ## $input$formula ## body_mass_g ~ species ## ## $input$data ## # A tibble: 344 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## 7 Adelie Torgersen 38.9 17.8 181 3625 ## 8 Adelie Torgersen 39.2 19.6 195 4675 ## 9 Adelie Torgersen 34.1 18.1 193 3475 ## 10 Adelie Torgersen 42 20.2 190 4250 ## # … with 334 more rows, and 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; ## ## $input$type ## [1] &quot;Tukey&quot; ## ## $input$conf.level ## [1] 0.95 ## ## $input$alternative ## [1] &quot;two.sided&quot; ## ## $input$asy.method ## [1] &quot;fisher&quot; ## ## $input$plot.simci ## [1] FALSE ## ## $input$control ## NULL ## ## $input$info ## [1] TRUE ## ## $input$rounds ## [1] 3 ## ## $input$contrast.matrix ## NULL ## ## $input$correlation ## [1] FALSE ## ## $input$effect ## [1] &quot;unweighted&quot; ## ## $input$const ## [1] 0.5875441 ## ## ## $text.Output ## [1] &quot;True differences of relative effects are not equal to 0&quot; ## ## $text.output.W ## [1] &quot;Global Pseudo Ranks&quot; ## ## $connames ## [1] &quot;2 - 1&quot; &quot;3 - 1&quot; &quot;3 - 2&quot; ## ## $AsyMethod ## [1] &quot;Fisher with 143 DF&quot; ## ## attr(,&quot;class&quot;) ## [1] &quot;mctp&quot; 3.22.2 ANOVA in R 3.22.2.1 ANOVA 가정 점검 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } data &lt;- penguins %&gt;% select(body_mass_g, species, sex) %&gt;% na.omit() ggplot(data, aes(species, body_mass_g, col=sex)) + geom_boxplot() + theme_bw() 펭귄 종에 따른 몸무게의 유의한 차이가 있는지 ANOVA로 분석한다. 신뢰성 있는 결과 도출을 위해 아래의 가정을 확인한다. 변수 유형 독립변수 범주형, 종속변수 연속형 str(data) ## tibble [333 × 3] (S3: tbl_df/tbl/data.frame) ## $ body_mass_g: int [1:333] 3750 3800 3250 3450 3650 3625 4675 3200 3800 4400 ... ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 1 2 1 2 1 2 2 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:11] 4 9 10 11 12 48 179 219 257 269 ... ## ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;4&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; ... 독립성, durbinWatsonTest() 함수를 통해 통계적으로 검정 if(!require(car)) { install.packages(&quot;car&quot;); library(car); } ## ## There is a binary version available but the source version is later: ## binary source needs_compilation ## rprojroot 2.0.2 2.0.3 FALSE ## ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages data.aov &lt;- aov(body_mass_g ~ species, data) durbinWatsonTest(data.aov) ## lag Autocorrelation D-W Statistic p-value ## 1 -0.4946035 2.989155 0 ## Alternative hypothesis: rho != 0 정규성 Shapiro-Wilk normality test Kolmogorov-Smirnov test QQPlot, Histogram # Shapiro-Wilk normality test shapiro.test(data.aov$residuals) ## ## Shapiro-Wilk normality test ## ## data: data.aov$residuals ## W = 0.9922, p-value = 0.07835 # Kolmogorov-Smirnov test ks.test(x = data$species, y = data$body_mass_g) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: data$species and data$body_mass_g ## D = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided # QQPlot, Histogram qqPlot(data.aov) ## [1] 164 186 등분산성 Levene’s test Bartlette test Boxplot leveneTest(body_mass_g ~ species, data) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 5.1349 0.006367 ** ## 330 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 leveneTest(body_mass_g ~ species*sex, data) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 5 1.3908 0.2272 ## 327 bartlett.test(body_mass_g ~ species, data) ## ## Bartlett test of homogeneity of variances ## ## data: body_mass_g by species ## Bartlett&#39;s K-squared = 5.692, df = 2, p-value = 0.05808 bartlett.test(body_mass_g ~ interaction(species,sex), data) ## ## Bartlett test of homogeneity of variances ## ## data: body_mass_g by interaction(species, sex) ## Bartlett&#39;s K-squared = 7.6908, df = 5, p-value = 0.1741 이상치 Boxplot, outlierTest() outlierTest(data.aov) ## No Studentized residuals with Bonferroni p &lt; 0.05 ## Largest |rstudent|: ## rstudent unadjusted p-value Bonferroni p ## 164 2.655717 0.0082993 NA range(data$body_mass_g); data[164,] ## [1] 2700 6300 ## # A tibble: 1 × 3 ## body_mass_g species sex ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; ## 1 6300 Gentoo male 3.22.2.2 ANOVA oneway.test(…, var.equal=) oneway.result &lt;- oneway.test(body_mass_g ~ species, data, var.equal = F); oneway.result ## ## One-way analysis of means (not assuming equal variances) ## ## data: body_mass_g and species ## F = 316.5, num df = 2.00, denom df = 187.68, p-value &lt; 2.2e-16 aov() aov.result &lt;- aov(body_mass_g ~ species, data) summary(aov.result) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## species 2 145190219 72595110 341.9 &lt;2e-16 *** ## Residuals 330 70069447 212332 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Kruskal-Wallis test (정규성 불만족 시) kruskal.test(body_mass_g ~ species, data) ## ## Kruskal-Wallis rank sum test ## ## data: body_mass_g by species ## Kruskal-Wallis chi-squared = 212.09, df = 2, p-value &lt; 2.2e-16 3.22.2.3 사후검정 Tukey HSD TukeyHSD(aov.result) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = body_mass_g ~ species, data = data) ## ## $species ## diff lwr upr p adj ## Chinstrap-Adelie 26.92385 -132.3528 186.2005 0.916431 ## Gentoo-Adelie 1386.27259 1252.2897 1520.2554 0.000000 ## Gentoo-Chinstrap 1359.34874 1194.4304 1524.2671 0.000000 if(!require(multcomp)) { install.packages(&quot;multcomp&quot;); library(multcomp); } tukey.result &lt;- glht(aov.result, linfct = mcp(species = &quot;Tukey&quot;)); tukey.result ## ## General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Linear Hypotheses: ## Estimate ## Chinstrap - Adelie == 0 26.92 ## Gentoo - Adelie == 0 1386.27 ## Gentoo - Chinstrap == 0 1359.35 plot(tukey.result, las=1) Dunnett if(!require(multcomp)) { install.packages(&quot;multcomp&quot;); library(multcomp); } dunnett.result &lt;- glht(aov.result, linfct = mcp(species = &quot;Dunnett&quot;)); dunnett.result ## ## General Linear Hypotheses ## ## Multiple Comparisons of Means: Dunnett Contrasts ## ## ## Linear Hypotheses: ## Estimate ## Chinstrap - Adelie == 0 26.92 ## Gentoo - Adelie == 0 1386.27 Bonferroni correction pairwise.t.test(data$body_mass_g, data$species, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: data$body_mass_g and data$species ## ## Adelie Chinstrap ## Chinstrap 1 - ## Gentoo &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: bonferroni "],["til20220323.html", "3.23 TIL20220323", " 3.23 TIL20220323 3.23.1 히트맵 in R if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } data &lt;- penguins data.matrix &lt;- as.matrix(cor(data[,3:6], use=&quot;complete.obs&quot;)) 3.23.1.1 heatmap() in base if(!require(reshape2)) { install.packages(&quot;reshape2&quot;); library(reshape2); } heatmap(data.matrix, Rowv = NA, Colv = NA) 3.23.1.2 heatmap.2() in gplots if(!require(gplots)) { install.packages(&quot;gplots&quot;); library(gplots); } ## ## The downloaded binary packages are in ## /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpPI140k/downloaded_packages heatmap.2(data.matrix, Rowv = NA, Colv = NA, ) 3.23.1.3 geom_tile() in ggplot2 if(!require(reshape2)) { install.packages(&quot;reshape2&quot;); library(reshape2); } if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } data.melted &lt;- melt(data.matrix); head(data.melted) ## Var1 Var2 value ## 1 bill_length_mm bill_length_mm 1.0000000 ## 2 bill_depth_mm bill_length_mm -0.2350529 ## 3 flipper_length_mm bill_length_mm 0.6561813 ## 4 body_mass_g bill_length_mm 0.5951098 ## 5 bill_length_mm bill_depth_mm -0.2350529 ## 6 bill_depth_mm bill_depth_mm 1.0000000 ggplot(data.melted, aes(x=Var1, y=Var2, fill = value)) + geom_tile() + scale_fill_gradient2(low=&quot;red&quot;, mid = &quot;white&quot;, high=&quot;blue&quot;) + guides(fill = guide_colorbar(barwidth = .5, barheight = 15)) "],["til20220324.html", "3.24 TIL20220324", " 3.24 TIL20220324 3.24.1 기계학습 모델링 with Caret 데이터 준비 데이터 탐색 데이터 전처리 데이터 분할 모델 학습 예측 및 성능평가 모델 개선 # 데이터 준비 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } if(!require(mlbench)) { install.packages(&quot;mlbench&quot;); library(mlbench); } data &lt;- BreastCancer ## Error in eval(expr, envir, enclos): object &#39;BreastCancer&#39; not found # 데이터 탐색 str(data) ## tibble [344 × 8] (S3: tbl_df/tbl/data.frame) ## $ species : Factor w/ 3 levels &quot;Adelie&quot;,&quot;Chinstrap&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ island : Factor w/ 3 levels &quot;Biscoe&quot;,&quot;Dream&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... ## $ bill_length_mm : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ... ## $ bill_depth_mm : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ... ## $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ... ## $ body_mass_g : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ... ## $ sex : Factor w/ 2 levels &quot;female&quot;,&quot;male&quot;: 2 1 1 NA 1 2 1 2 NA NA ... ## $ year : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ... summary(data) ## species island bill_length_mm bill_depth_mm ## Adelie :152 Biscoe :168 Min. :32.10 Min. :13.10 ## Chinstrap: 68 Dream :124 1st Qu.:39.23 1st Qu.:15.60 ## Gentoo :124 Torgersen: 52 Median :44.45 Median :17.30 ## Mean :43.92 Mean :17.15 ## 3rd Qu.:48.50 3rd Qu.:18.70 ## Max. :59.60 Max. :21.50 ## NA&#39;s :2 NA&#39;s :2 ## flipper_length_mm body_mass_g sex year ## Min. :172.0 Min. :2700 female:165 Min. :2007 ## 1st Qu.:190.0 1st Qu.:3550 male :168 1st Qu.:2007 ## Median :197.0 Median :4050 NA&#39;s : 11 Median :2008 ## Mean :200.9 Mean :4202 Mean :2008 ## 3rd Qu.:213.0 3rd Qu.:4750 3rd Qu.:2009 ## Max. :231.0 Max. :6300 Max. :2009 ## NA&#39;s :2 NA&#39;s :2 colSums(is.na(data)) ## species island bill_length_mm bill_depth_mm ## 0 0 2 2 ## flipper_length_mm body_mass_g sex year ## 2 2 11 0 table(data$Class) ## &lt; table of extent 0 &gt; # 데이터 전처리 if(!require(dplyr)) { install.packages(&quot;dplyr&quot;); library(dplyr); } data &lt;- data %&gt;% select(-Id) # 필요한 컬럼 제외 ## Error in `select()`: ## ! Can&#39;t subset columns past the end. ## ✖ Column `Id` doesn&#39;t exist. data &lt;- data %&gt;% na.omit() # 결측치 제외 (16/699이므로) # 데이터 분할 if(!require(caret)) { install.packages(&quot;caret&quot;); library(caret); } train.index &lt;- createDataPartition(data$Class, p=.7, list=F) ## Error in createDataPartition(data$Class, p = 0.7, list = F): y must have at least 2 data points data.train &lt;- data[train.index, ] data.test &lt;- data[-train.index, ] # 모델 학습 trCtrl.up &lt;- trainControl(sampling = &quot;up&quot;) trCtrl.down &lt;- trainControl(sampling = &quot;down&quot;) model.dt.up &lt;- train(Class ~ ., data = data.train, method = &quot;rpart&quot;, trControl = trCtrl.up) ## Error in eval(predvars, data, env): object &#39;Class&#39; not found model.dt.down &lt;- train(Class ~ ., data = data.train, method = &quot;rpart&quot;, trControl = trCtrl.down) ## Error in eval(predvars, data, env): object &#39;Class&#39; not found model.list &lt;- list(up = model.dt.up, down = model.dt.down) ## Error in eval(expr, envir, enclos): object &#39;model.dt.up&#39; not found model.resamples &lt;- resamples(model.list) ## Error in resamples(model.list): object &#39;model.list&#39; not found dotplot(model.resamples) ## Error in dotplot(model.resamples): object &#39;model.resamples&#39; not found # 예측 및 성능평가 model.dt.up.pred &lt;- predict(model.dt.up, data.test) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.up&#39; not found model.dt.down.pred &lt;- predict(model.dt.down, data.test) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.down&#39; not found rbind(up = mean(model.dt.up.pred == data.test$Class), down = mean(model.dt.down.pred == data.test$Class) ) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;model.dt.up.pred&#39; not found if(!require(pROC)) { install.packages(&quot;pROC&quot;); library(pROC); } model.dt.up.pred &lt;- predict(model.dt.up, data.test, type = &quot;prob&quot;) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.up&#39; not found model.dt.down.pred &lt;- predict(model.dt.down, data.test, type = &quot;prob&quot;) ## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;object&#39; in selecting a method for function &#39;predict&#39;: object &#39;model.dt.down&#39; not found roc(data.test$Class, model.dt.up.pred[,1], plot=T, print.auc=T, col=&quot;red&quot;) ## Error in roc.default(data.test$Class, model.dt.up.pred[, 1], plot = T, : No valid data provided. roc(data.test$Class, model.dt.down.pred[,1], plot=T, print.auc=T, add=T, col=&quot;blue&quot;, print.auc.adj=c(0,-1)) ## Error in roc.default(data.test$Class, model.dt.down.pred[, 1], plot = T, : No valid data provided. text(1.2, 0.8, &quot;Blue: Down sampling\\nRed: Up sampling&quot;) ## Error in text.default(1.2, 0.8, &quot;Blue: Down sampling\\nRed: Up sampling&quot;): plot.new has not been called yet 3.24.2 다중범주 ROC if(!require(rpart)) { install.packages(&quot;rpart&quot;); library(rpart); } data &lt;- penguins data &lt;- na.omit(data) set.seed(1234) train.index &lt;- sample(nrow(data), 0.7*nrow(data), replace=F) train &lt;- data[train.index,] test &lt;- data[-train.index,] model.dt &lt;- rpart(species ~ ., train) model.dt.pred &lt;- predict(model.dt, test, type=&quot;class&quot;) if(!require(pROC)) { install.packages(&quot;pROC&quot;); library(pROC); } mroc &lt;- multiclass.roc(test$species, as.numeric(model.dt.pred)) pROC::plot.roc(mroc$rocs[[1]], plot=T, col=1, print.auc=T) for(i in 2:3) { pROC::plot.roc(mroc$rocs[[i]], plot=T, col=i, print.auc=T, add=T, print.auc.adj = c(0,i)) } "],["til20220325.html", "3.25 TIL20220325", " 3.25 TIL20220325 아… 이날은 잊지 말자 🤮 "],["til20220326.html", "3.26 TIL20220326", " 3.26 TIL20220326 [Github] 깃허브 커밋 날짜를 조작하고 싶지 않으신가요?13 이게 되는구나… https://cindycho.tistory.com/71↩︎ "],["til20220327.html", "3.27 TIL20220327", " 3.27 TIL20220327 if(!require(ggplot2)) { install.packages(&quot;ggplot2&quot;); library(ggplot2); } x &lt;- seq(-4, 4, length=100) y3 &lt;- dt(x, df=3) y10 &lt;- dt(x, df=10) y50 &lt;- dt(x, df=50) ggplot(data.frame(x,y3), aes(x,y3)) + geom_line(col=1) + geom_line(aes(x, y10), col=2) + geom_line(aes(x, y50), col=3) + geom_text(aes(-3, 0.3, label=&quot;df=50&quot;), color=3) + geom_text(aes(-3, 0.25, label=&quot;df=10&quot;), col=2) + geom_text(aes(-3, 0.2, label=&quot;df=3&quot;), col=1) + theme_bw() str(cars) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ speed: num 4 4 7 7 8 9 10 10 10 11 ... ## $ dist : num 2 10 4 22 16 10 18 26 34 17 ... plot(cars$speed, cars$dist) x &lt;- seq(-4, 4, length=100) y1 &lt;- dnorm(x, sd=1) y2 &lt;- dnorm(x, sd=2) ggplot(data.frame(x,y1), aes(x,y1)) + geom_line() + geom_line(aes(y=y2), col=2) \\[CV, coefficient of variance = \\frac{s}{\\bar x}\\] if(!require(palmerpenguins)) { install.packages(&quot;palmerpenguins&quot;); library(palmerpenguins); } pa &lt;- subset(penguins[penguins$species==&quot;Adelie&quot;, ], select = c(&quot;species&quot;, &quot;body_mass_g&quot;)) pg &lt;- subset(penguins[penguins$species==&quot;Gentoo&quot;, ], select = c(&quot;species&quot;, &quot;body_mass_g&quot;)) pa.cv &lt;- sd(pa$body_mass_g, na.rm=T)/mean(pa$body_mass_g, na.rm = T) pg.cv &lt;- sd(pg$body_mass_g, na.rm=T)/mean(pg$body_mass_g, na.rm = T) cv &lt;- rbind(Adelie = pa.cv, Gentoo = pg.cv) colnames(cv) &lt;- c(&quot;CV&quot;); cv ## CV ## Adelie 0.12391461 ## Gentoo 0.09931336 Adelie가 Gentoo에 비해 변동성이 큰 것을 알 수 있다. boxplot(pa$body_mass_g, pg$body_mass_g) "],["til20220328.html", "3.28 TIL20220328", " 3.28 TIL20220328 베르누이 시행 p의 확률로 원하는 결과가 나타났을 때 성공으로 (1-p)의 확률로 그렇지 않은 결과가 나타났을 때 실패로 하는 두 가지 결과가 나타나는 확률실험을 베르누이 시행이라 한다. 이항 분포 성공 확률이 p로 동일한 베르누이 시행을 n번 반복해서 실험하는 경우, 실험이 n번 반복되더라도 성공 확률 p는 변하지 않고 동일한것으로 이는 앞의 실험이 뒤에 할 실험에 영향을 끼치지 않고 각 실험이 서로 독립적으로 실행될 때 이와 같은 실험에서 성공 횟수가 따르는 분포함수를 이항분포라 한다. 이항 계수 \\(p^x(1-p)^{n-x}\\) n &lt;- 6 p &lt;- 1/3 x &lt;- 0:n dbinom(2, size = n, prob = p) ## [1] 0.3292181 dbinom(4, size = n, prob = p) ## [1] 0.08230453 px &lt;- dbinom(x, size = n, prob = p) plot(x, px, type=&quot;s&quot;,xlab=&quot;성공횟수&quot;, ylab=&quot;확률&quot;, main=&quot;B(6, 1/3)&quot;) # B(6, 1/3)의 기댓값과 분산 n &lt;- 6 p &lt;- 1/3 x &lt;- 0:n px &lt;- dbinom(x, size = n, prob = p) ex &lt;- sum(x * px) ex2 &lt;- sum(x^2 * px) # V(X) = E(X^2) - {E(X)}^2 varx &lt;- ex2 - ex^2; varx ## [1] 1.333333 options(digits = 3) mu = 170 sigma &lt;- 6 ll &lt;- mu - 3*sigma ul &lt;- mu + 3*sigma x &lt;- seq(ll, ul, by=0.01) nd &lt;- dnorm(x, mean=mu, sd=sigma) plot(x, nd, type=&quot;l&quot;, xlab=&quot;x&quot;, ylab=&quot;P(X=x)&quot;, lwd=2, col=&quot;red&quot;); abline(v=mu) options(digis=5) set.seed(5) smp &lt;- rnorm(400, mean=mu, sd=sigma) c(mean(smp), sd(smp)) ## [1] 170.02 6.01 hist(smp, prob=T, main=&quot;N(170, 6^2)으로부터 추출한 표본의 분포(n=400)&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;, border=&quot;black&quot;); lines(x, nd, lty=2) x &lt;- seq(ll, ul, length = 400) nd &lt;- dnorm(x, mean=mean(smp), sd=sd(smp)) plot(x, nd, type=&quot;l&quot;, xlab=&quot;x&quot;, ylab=&quot;P(X=x)&quot;, lwd=2, col=&quot;red&quot;);abline(v=mean(smp)) "],["til20220329.html", "3.29 TIL20220329", " 3.29 TIL20220329 v &lt;- c(1,4,5) for (i in v) { print(i) } ## [1] 1 ## [1] 4 ## [1] 5 모수 모집단의 특성을 나타내는 값, parameter 통계량 표본으로부터 관찰되는 표본의 특성, statistic 표본분포 표본 크기가 n으로 정해졌을 때 추출될 수 있는 모든 표본으로부터 구한 통계량들로 구성된 확률분포 # 모집단 100개 중 표본 크기 10이 되도록 하는 표본추출의 경우의 수 choose(100, 10) ## [1] 1.73e+13 # 카드 4장 중 2장 선택 choose(4, 2) ## [1] 6 표본평균 \\(\\bar{x}\\)의 분포 m10 &lt;- rep(NA, 1000) m40 &lt;- rep(NA, 1000) set.seed(9) for(i in 1:1000) { m10[i] &lt;- mean(rnorm(10)) m40[i] &lt;- mean(rnorm(40)) } options(digits = 4) c(mean(m10), sd(m10)) ## [1] -0.01214 0.30311 c(mean(m40), sd(m40)) ## [1] 0.004212 0.160942 par(mfrow = c(1,2)) hist(m10, xlim = c(-1.5, 1.5), main=&quot;&quot;, xlab=&quot;x&quot;, ylab=&quot;y&quot;, col=&quot;cyan&quot;, border = &quot;blue&quot;) hist(m40, xlim = c(-1.5, 1.5), main=&quot;&quot;, xlab=&quot;x&quot;, ylab=&quot;y&quot;, col=&quot;cyan&quot;, border = &quot;blue&quot;) par(mfrow = c(1,1)) 표본 크기가 클수록 기댓값 주변에 많이 몰려 있으며 자료가 분포하는 전체 폭이 줄어듦을 볼 수 있다. "],["til20220330.html", "3.30 TIL20220330", " 3.30 TIL20220330 3.30.1 정규분포에서 추출한 표본평균의 분포 set.seed(9) n &lt;- 1000 r.1.mean &lt;- rep(NA, n) r.2.mean &lt;- rep(NA, n) for(i in 1:n) { r.1.mean[i] &lt;- mean(rnorm(4, mean=3, sd=1)) r.2.mean[i] &lt;- mean(rnorm(4, mean=170, sd=6)) } options(digits = 4) c(mean(r.1.mean), sd(r.1.mean)) ## [1] 3.0214 0.5096 c(mean(r.2.mean), sd(r.2.mean)) ## [1] 170.032 2.835 {hist(r.1.mean, prob=T, xlab=&quot;표본평균&quot;, ylab=&quot;밀도&quot;, main=&quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x1 &lt;- seq(min(r.1.mean), max(r.1.mean), length=1000) y1 &lt;- dnorm(x=x1, mean=3, sd=(1/sqrt(4))) lines(x1, y1, lty=2, lwd=2, col=&quot;blue&quot;)} {hist(r.2.mean, prob=T, xlab=&quot;표본평균&quot;, ylab=&quot;밀도&quot;, main=&quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x2 &lt;- seq(min(r.2.mean), max(r.2.mean), length=1000) y2 &lt;- dnorm(x=x2, mean=170, sd=(6/sqrt(4))) lines(x2, y2, lty=2, lwd=2, col=&quot;blue&quot;)} 모집단이 정규분포를 다를 경우 표본평균의 분포가 정규분포와 유사함을 확인할 수 있다. \\[ \\bar{X} \\sim N(\\mu, (\\frac{\\sigma}{\\sqrt{n}})^2) \\] 3.30.2 모집단이 정규분포 이외의 분포를 따를 경우 시행횟수가 10회, 성공확률이 0.1인 이항분포 B(10, 0.1)의 평균 1, 표준편차 0.9487일 때, 표본 크기 2,4,32로 늘릴 경우 B(10, 01), E(X) = np, VAR(X) = np(1-p)이므로 t &lt;- 10; p &lt;- 0.1; x &lt;- 0:10; px &lt;- dbinom(0:10, 10, prob=0.1) names(px) &lt;- 0:10 barplot(px, col=&quot;orange&quot;, border=&quot;red&quot;) set.seed(9) t &lt;- 10 p &lt;- 0.1 x &lt;- 0:10 n &lt;- 1000 b.2.mean &lt;- rep(NA, n) b.4.mean &lt;- rep(NA, n) b.32.mean &lt;- rep(NA, n) for(i in 1:n) { b.2.mean[i] &lt;- mean(rbinom(2, size=t, prob=p)) b.4.mean[i] &lt;- mean(rbinom(4, size=t, prob=p)) b.32.mean[i] &lt;- mean(rbinom(32, size=t, prob=p)) } options(digits = 4) c(mean(b.2.mean), sd(b.2.mean)) ## [1] 1.0090 0.6763 c(mean(b.4.mean), sd(b.4.mean)) ## [1] 1.006 0.481 c(mean(b.32.mean), sd(b.32.mean)) ## [1] 0.9989 0.1624 {hist(b.2.mean, prob=T, xlim=c(0,4), main=&quot;표본크기: 2&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x1 &lt;- seq(min(b.2.mean), max(b.2.mean), length=1000) y1 &lt;- dnorm(x=x1, mean = 1, sd = sqrt(0.9)/sqrt(2)) lines(x1, y1, lty=2, lwd=2, col=&quot;blue&quot;)} {hist(b.4.mean, prob=T, xlim=c(0,4), main=&quot;표본크기: 8&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x2 &lt;- seq(min(b.4.mean), max(b.4.mean), length=1000) y2 &lt;- dnorm(x=x2, mean = 1, sd = sqrt(0.9)/sqrt(8)) lines(x2, y2, lty=2, lwd=2, col=&quot;blue&quot;)} {hist(b.32.mean, prob=T, xlim=c(0,4), main=&quot;표본크기: 32&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) x3 &lt;- seq(min(b.32.mean), max(b.32.mean), length=1000) y3 &lt;- dnorm(x=x3, mean = 1, sd = sqrt(0.9)/sqrt(32)) lines(x3, y3, lty=2, lwd=2, col=&quot;blue&quot;)} "],["til20220331.html", "3.31 TIL20220331", " 3.31 TIL20220331 표본평균 \\(\\bar{x}\\)의 분포가 표본 크기 n이 커짐에 따라 모집단의 모양(분포)에 상관없이 모집단에 평균과 분산이 존재한다면 근사적으로 정규분포가 된다. 즉, 모집단의 분포와 상관없이 모집단의 평균 \\(\\mu\\)와 표준편자 \\(\\sigma\\)가 존재할 때 표본 크기 n이 충분히 크다면 표본평균의 분포는 근사적으로 정규분포를 따른다. 이를 중심극한정리(Central Limit Theorem)라 한다. 모수() 구분 추정량 \\(\\mu\\) 평균 \\(\\bar X\\) \\(\\sigma ^2\\) 분산 \\(s^2\\) \\(P\\) 비율 \\(\\hat p\\) 불편성 추정량이 갖춰야 할 가장 기본적인 성질로 한쪽으로 치우치지 않음을 의미한다 불편출정량 추정량의 기댓값이 모수와 같음을 의미하고 불편성을 맍고하는 추정량을 의미한다 \\[ E(\\hat \\theta) = \\theta \\] "],["년-4월.html", "4 2022년 4월 ", " 4 2022년 4월 "],["til20220401.html", "4.1 TIL20220401", " 4.1 TIL20220401 x &lt;- seq(-3, 3, by=0.01) y &lt;- dnorm(x) y.1 &lt;- dnorm(x, sd=sqrt(1/3)) y.2 &lt;- dnorm(x, sd=sqrt(7/18)) pnorm(0.1, sd=sqrt(1/3)) - pnorm(-0.1, sd=sqrt(1/3)) ## [1] 0.1375 pnorm(0.1, sd=sqrt(7/18)) - pnorm(-0.1, sd=sqrt(7/18)) ## [1] 0.1274 { plot(x, y , type=&quot;l&quot;, ylim = c(0, 0.8), axes = F, ylab = &quot;&quot;, lwd = 3, col = &quot;yellow&quot;) lines(x, y.1, col = &quot;red&quot;, lwd = 3) lines(x, y.2, col = &quot;green&quot;, lty=2, lwd = 3) axis(1) } "],["til20220402.html", "4.2 TIL20220402", " 4.2 TIL20220402 options(digits = 3) set.seed(1) mean.seq &lt;- function(x) { n &lt;- length(x) sum &lt;- 0 n2 &lt;- 0 for(i in 1:n) { newx &lt;- i * x[i] sum &lt;- sum + newx n2 &lt;- n2 + i } return (sum/n2) } y1 &lt;- rep(NA, 1000) y2 &lt;- rep(NA, 1000) for(i in 1:1000){ smp &lt;- rnorm(3) y1[i] &lt;- mean(smp) y2[i] &lt;- mean.seq(smp) } n1 &lt;- length(y1[(y1&gt;-0.1) &amp; (y1&lt;0.1)]) n2 &lt;- length(y2[(y2&gt;-0.1) &amp; (y2&lt;0.1)]) data.frame(mean=mean(y1), var=var(y1), n=n1) ## mean var n ## 1 -0.0042 0.36 134 data.frame(mean=mean(y2), var=var(y2), n=n2) ## mean var n ## 1 -0.0113 0.427 120 par(mfrow=c(1,2)) hist(y1, probability = T, xlim=c(-2,2), ylim=c(0,0.65), main = &quot;(x1 + x2 + x3)/3&quot;, xlab = &quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) hist(y2, probability = T, xlim=c(-2,2), ylim=c(0,0.65), main = &quot;(1*x1+ 2*x2 + 6*x3)/6&quot;, xlab = &quot;&quot;, col=&quot;orange&quot;, border=&quot;red&quot;) "],["til20220403.html", "4.3 TIL20220403", " 4.3 TIL20220403 4.3.1 데이터 결합 방법 # finance.yahoo.com: Samsung Electronics, KRW library(quantmod) sec &lt;- getSymbols(Symbols = &quot;005930.KS&quot;, from = &quot;2021-10-01&quot;, to = &quot;2021-12-31&quot;, auto.assign = FALSE) sec &lt;- as.data.frame(sec) str(sec) ## &#39;data.frame&#39;: 63 obs. of 6 variables: ## $ 005930.KS.Open : num 73900 73000 72600 71600 72300 70700 68700 69000 70200 70200 ... ## $ 005930.KS.High : num 74000 73000 72800 72100 72400 70900 69600 69800 71000 70300 ... ## $ 005930.KS.Low : num 72900 71400 71200 71300 71500 68700 68300 68800 70000 69200 ... ## $ 005930.KS.Close : num 73200 72200 71300 71600 71500 69000 68800 69400 70100 70200 ... ## $ 005930.KS.Volume : num 15803395 24013921 18956962 13683532 14043287 ... ## $ 005930.KS.Adjusted: num 72871 71875 70979 71278 71179 ... head(sec[c(&quot;005930.KS.Close&quot;, &quot;005930.KS.Volume&quot;)]) ## 005930.KS.Close 005930.KS.Volume ## 2021-10-01 73200 15803395 ## 2021-10-05 72200 24013921 ## 2021-10-06 71300 18956962 ## 2021-10-07 71600 13683532 ## 2021-10-08 71500 14043287 ## 2021-10-12 69000 31001484 sec &lt;- cbind(date=rownames(sec), symbod = &quot;005930.KS&quot;, sec[c(&quot;005930.KS.Close&quot;, &quot;005930.KS.Volume&quot;)]) rownames(sec) &lt;- NULL colnames(sec)[c(3,4)] &lt;- c(&quot;close&quot;, &quot;volume&quot;) head(sec) ## date symbod close volume ## 1 2021-10-01 005930.KS 73200 15803395 ## 2 2021-10-05 005930.KS 72200 24013921 ## 3 2021-10-06 005930.KS 71300 18956962 ## 4 2021-10-07 005930.KS 71600 13683532 ## 5 2021-10-08 005930.KS 71500 14043287 ## 6 2021-10-12 005930.KS 69000 31001484 hmc &lt;- getSymbols(Symbols = &quot;005387.KS&quot;, from = &quot;2021-10-01&quot;, to = &quot;2021-12-31&quot;, auto.assign = FALSE) hmc &lt;- as.data.frame(hmc) str(hmc) ## &#39;data.frame&#39;: 63 obs. of 6 variables: ## $ 005387.KS.Open : num 95100 92400 91700 93100 96400 96100 95900 98800 99700 100000 ... ## $ 005387.KS.High : num 95500 92400 93300 95900 98000 ... ## $ 005387.KS.Low : num 92600 90100 91000 93100 96100 95200 95900 98500 99200 98600 ... ## $ 005387.KS.Close : num 92800 91500 93100 95800 96100 95700 98500 99100 99700 100000 ... ## $ 005387.KS.Volume : num 108008 142854 85533 65835 80350 ... ## $ 005387.KS.Adjusted: num 89176 87927 89465 92059 92348 ... head(hmc[c(&quot;005387.KS.Close&quot;, &quot;005387.KS.Volume&quot;)]) ## 005387.KS.Close 005387.KS.Volume ## 2021-10-01 92800 108008 ## 2021-10-05 91500 142854 ## 2021-10-06 93100 85533 ## 2021-10-07 95800 65835 ## 2021-10-08 96100 80350 ## 2021-10-12 95700 52477 hmc &lt;- cbind(date=rownames(hmc), symbod = &quot;005387.KS&quot;, hmc[c(&quot;005387.KS.Close&quot;, &quot;005387.KS.Volume&quot;)]) rownames(hmc) &lt;- NULL colnames(hmc)[c(3,4)] &lt;- c(&quot;close&quot;, &quot;volume&quot;) head(hmc) ## date symbod close volume ## 1 2021-10-01 005387.KS 92800 108008 ## 2 2021-10-05 005387.KS 91500 142854 ## 3 2021-10-06 005387.KS 93100 85533 ## 4 2021-10-07 005387.KS 95800 65835 ## 5 2021-10-08 005387.KS 96100 80350 ## 6 2021-10-12 005387.KS 95700 52477 stock &lt;- rbind(sec, hmc); head(stock); ## date symbod close volume ## 1 2021-10-01 005930.KS 73200 15803395 ## 2 2021-10-05 005930.KS 72200 24013921 ## 3 2021-10-06 005930.KS 71300 18956962 ## 4 2021-10-07 005930.KS 71600 13683532 ## 5 2021-10-08 005930.KS 71500 14043287 ## 6 2021-10-12 005930.KS 69000 31001484 fx &lt;- getSymbols(Symbols = &quot;KRW=x&quot;, from = &quot;2021-10-01&quot;, to = &quot;2021-12-31&quot;, auto.assign = FALSE) fx &lt;- as.data.frame(fx) str(fx) ## &#39;data.frame&#39;: 66 obs. of 6 variables: ## $ KRW=X.Open : num 1184 1180 1185 1186 1190 ... ## $ KRW=X.High : num 1189 1185 1189 1197 1192 ... ## $ KRW=X.Low : num 1179 1177 1183 1186 1187 ... ## $ KRW=X.Close : num 1184 1180 1184 1187 1191 ... ## $ KRW=X.Volume : num 0 0 0 0 0 0 0 0 0 0 ... ## $ KRW=X.Adjusted: num 1184 1180 1184 1187 1191 ... head(fx[c(&quot;KRW=X.Close&quot;)]) ## KRW=X.Close ## 2021-10-01 1184 ## 2021-10-04 1180 ## 2021-10-05 1184 ## 2021-10-06 1187 ## 2021-10-07 1191 ## 2021-10-08 1191 fx &lt;- cbind(date=rownames(fx), fx[c(&quot;KRW=X.Close&quot;)]) rownames(fx) &lt;- NULL colnames(fx)[c(2)] &lt;- c(&quot;close&quot;) head(fx) ## date close ## 1 2021-10-01 1184 ## 2 2021-10-04 1180 ## 3 2021-10-05 1184 ## 4 2021-10-06 1187 ## 5 2021-10-07 1191 ## 6 2021-10-08 1191 intersect(names(sec), names(fx)) ## [1] &quot;date&quot; &quot;close&quot; report &lt;- merge(sec, fx, by=&quot;date&quot;); head(report); ## date symbod close.x volume close.y ## 1 2021-10-01 005930.KS 73200 15803395 1184 ## 2 2021-10-05 005930.KS 72200 24013921 1184 ## 3 2021-10-06 005930.KS 71300 18956962 1187 ## 4 2021-10-07 005930.KS 71600 13683532 1191 ## 5 2021-10-08 005930.KS 71500 14043287 1191 ## 6 2021-10-12 005930.KS 69000 31001484 1196 match() 함수를 이용한 데이터 결합 방법 v &lt;-c(10:1) match(7, v) ## [1] 4 match(c(11,5,3,1,0), v) ## [1] NA 6 8 10 NA head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 car &lt;- mtcars car$name &lt;- rownames(car) rownames(car) &lt;- NULL head(car) ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 1 21.0 6 160 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 ## 2 21.0 6 160 110 3.90 2.88 17.0 0 1 4 4 Mazda RX4 Wag ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 Datsun 710 ## 4 21.4 6 258 110 3.08 3.21 19.4 1 0 3 1 Hornet 4 Drive ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Hornet Sportabout ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 Valiant highhp.car &lt;- car[car$hp &gt; 145, ]; highhp.car; ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 Hornet Sportabout ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 Duster 360 ## 12 16.4 8 276 180 3.07 4.07 17.4 0 0 3 3 Merc 450SE ## 13 17.3 8 276 180 3.07 3.73 17.6 0 0 3 3 Merc 450SL ## 14 15.2 8 276 180 3.07 3.78 18.0 0 0 3 3 Merc 450SLC ## 15 10.4 8 472 205 2.93 5.25 18.0 0 0 3 4 Cadillac Fleetwood ## 16 10.4 8 460 215 3.00 5.42 17.8 0 0 3 4 Lincoln Continental ## 17 14.7 8 440 230 3.23 5.34 17.4 0 0 3 4 Chrysler Imperial ## 22 15.5 8 318 150 2.76 3.52 16.9 0 0 3 2 Dodge Challenger ## 23 15.2 8 304 150 3.15 3.44 17.3 0 0 3 2 AMC Javelin ## 24 13.3 8 350 245 3.73 3.84 15.4 0 0 3 4 Camaro Z28 ## 25 19.2 8 400 175 3.08 3.85 17.1 0 0 3 2 Pontiac Firebird ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino ## 31 15.0 8 301 335 3.54 3.57 14.6 0 1 5 8 Maserati Bora lightwt.car &lt;- car[car$wt &lt; 3.2, ]; lightwt.car; ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 1 21.0 6 160.0 110 3.90 2.62 16.5 0 1 4 4 Mazda RX4 ## 2 21.0 6 160.0 110 3.90 2.88 17.0 0 1 4 4 Mazda RX4 Wag ## 3 22.8 4 108.0 93 3.85 2.32 18.6 1 1 4 1 Datsun 710 ## 8 24.4 4 146.7 62 3.69 3.19 20.0 1 0 4 2 Merc 240D ## 9 22.8 4 140.8 95 3.92 3.15 22.9 1 0 4 2 Merc 230 ## 18 32.4 4 78.7 66 4.08 2.20 19.5 1 1 4 1 Fiat 128 ## 19 30.4 4 75.7 52 4.93 1.61 18.5 1 1 4 2 Honda Civic ## 20 33.9 4 71.1 65 4.22 1.83 19.9 1 1 4 1 Toyota Corolla ## 21 21.5 4 120.1 97 3.70 2.46 20.0 1 0 3 1 Toyota Corona ## 26 27.3 4 79.0 66 4.08 1.94 18.9 1 1 4 1 Fiat X1-9 ## 27 26.0 4 120.3 91 4.43 2.14 16.7 0 1 5 2 Porsche 914-2 ## 28 30.4 4 95.1 113 3.77 1.51 16.9 1 1 5 2 Lotus Europa ## 29 15.8 8 351.0 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145.0 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino ## 32 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 Volvo 142E index &lt;- match(highhp.car$name, lighthp.car$name); index; ## Error in match(highhp.car$name, lighthp.car$name): object &#39;lighthp.car&#39; not found ## function (x, ...) ## { ## UseMethod(&quot;index&quot;) ## } ## &lt;bytecode: 0x7fde25c684c0&gt; ## &lt;environment: namespace:zoo&gt; lighthp.car[na.omit(index), ] ## Error in eval(expr, envir, enclos): object &#39;lighthp.car&#39; not found %in%를 이용한 데이터 결합 7 %in% v ## [1] TRUE c(11,5,3,1,0) %in% v ## [1] FALSE TRUE TRUE TRUE FALSE index &lt;- highhp.car$name %in% lightwt.car$name; index; ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] TRUE TRUE FALSE highhp.car[index,] ## mpg cyl disp hp drat wt qsec vs am gear carb name ## 29 15.8 8 351 264 4.22 3.17 14.5 0 1 5 4 Ford Pantera L ## 30 19.7 6 145 175 3.62 2.77 15.5 0 1 5 6 Ferrari Dino "],["til20220404.html", "4.4 TIL20220404", " 4.4 TIL20220404 4.4.1 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

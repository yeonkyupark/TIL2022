## TIL20220321

### 가설검정

#### 범주형 데이터

##### 한 집단일 때

**일원 카이 제곱 검정**

:   one sample $x^2$ test, 적합성 검정에활용

```{r}
# 주사위를 60번 던져 때, 기대빈도와 관측빈도가 적합한지 검정
# 귀무가설: 기대빈도와 관측빈도는 차이가 없다
# 대립가설: 기대빈도와 관측빈도는 차이가 있다.

chisq.test(c(4,6,17,15,9,9), p = rep(1/6, 6))
```

p값에 따라 유의수준 0.05에서 귀무가설을 기각하고 대립가설을 채택한다. 즉 주사위의 기대빈도와 관측빈도에는 차이가 있다고 판단할 수 있다.

```{r}
# 통신 3사 점유율 차이 40%, 30%, 30%인지 검정
chisq.test(c(45, 30, 25), p = c(0.4, 0.3, 0.3))
```

##### 두 집단일 때

**이원 카이 제곱 검정**

```{r}
if(!require(palmerpenguins)) { install.packages("palmerpenguins"); library(palmerpenguins); }
chisq.test(x=penguins$species, y=penguins$island)
```

```{r}
if(!require(gmodels)) { install.packages("gmodels"); library(gmodels); }

CrossTable(x=penguins$species, y=penguins$island, chisq = T)
```

##### 피셔 정확 검정

분할표를 그린 뒤 카이 제곱을 적용할 때 표본 수가 적거나 표본이 분팔표의 셀에 매우 치우치게 분포되어 있다면 카이 제곱 검정의 결과가 부정확할 수 있다. 기대 빈도가 5 이하인 셀이 전체의 20% 수준일 때 표본의 수가 적다고 볼 수 있다. 이런 경우 Fisher's Exact Test를 적용한다.

```{r}
if(!require(MASS)) { install.packages("MASS"); library(MASS); }

xtabs( ~ W.Hnd + Clap, data = survey)
```

```{r}
chisq.test(survey$W.Hnd, survey$Clap)
```

```{r}
fisher.test(survey$W.Hnd, survey$Clap)
```

##### 맥니마 검정 (McNemar Test)

사건 전후의 차이 검정에 활용된다.

```{r}
Performance <-
   matrix(c(794, 86, 150, 570),
          nrow = 2,
          dimnames = list(
          "1st Survey" = c("Approve", "Disapprove"),
          "2nd Survey" = c("Approve", "Disapprove")))
Performance
```

```{r}
mcnemar.test(Performance)
```

p값에 따라 첫번째 조사와 두번째 조사 간에는 유의확률 0.05 하에서 통계적으로 유의미한 차이가 있다.

참고로, 사건 전후의 차이 검정은 b=c를 검토하여 변화 여부를 판단할 수 있다. $$b \sim B(b+c, \frac{1}{2})$$

따라서 위 예제의 경우 86 \~ B(86+150, 1/2)를 검토한다.

```{r}
binom.test(86, 86+150, 0.5)
```

#### 연속형 데이터

##### 정규성 검정

###### shapiro.test()

```{r}
shapiro.test(rnorm(1000))
```

###### ks.test()

콜모고로프 스미르노프 검정(Kolmogorov-Smirnov Test), 두 숫자 벡터 간의 차이가 없는지를 검정한다.

```{r}
ks.test(rnorm(100), rnorm(100))
```

```{r}
ks.test(rnorm(100), runif(100))
```

x를 정규분포에서 추출하였는지 검정을 할 수도 있다.

```{r}
ks.test(rnorm(1000), "pnorm", 0 ,1)
```

```{r}
ks.test(runif(1000), "pnorm", c(0, 1))
```

###### qqplot()

```{r}
x <- rnorm(1000, mean = 10, sd = 1)
qqnorm(x); qqline(x, lty=2, col = "blue")
```

```{r}
x <- runif(1000)
qqnorm(x); qqline(x, lty=2, col = "red")
```

```{r}
qqplot(runif(1000, min=1, max=10), 1:10)
```

```{r}
qqplot(rnorm(1000), 1:1000)
```

##### 한 집단일 때

###### one sample t-test

####### 정규성을 만족할 경우 t.test()

####### 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon signed rank test

##### 두 집단일 때

###### independent two sample t-test

####### 정규성을 만족할 경우 t.test()

####### 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon rank sum test

###### paired two sample t-test

####### 정규성을 만족할 경우 t.test()

####### 정규성을 만족하지 못할 경우 wilcox.test(), Wilcoxon signed rank test with paired

##### 세 집단 이상일 때

####### 정규성을 만족할 경우 aov()

####### 정규성을 만족하지 못할 경우 kruskal()

####### 사후검정

Fisher's LSD, Bonferroni, Shelf, Turkey, Duncan 등

### 비율검정

#### 일표본 binom.test()

#### 이표본 prop.test()

### 동질성 검사

#### 이표본 var.test()

#### 삼표본 이상 bartlett.test()

## TIL20220322

### 비모수 검정

```{r}
if(!require(moonBook)) { install.packages("moonBook"); library(moonBook); }
if(!require(palmerpenguins)) { install.packages("palmerpenguins"); library(palmerpenguins); }
data <- penguins
densityplot(body_mass_g ~ sex, data = data)
```

0.  정규성 검정

```{r}
shapiro.test(data$body_mass_g)
```

1.  Wilcoxon Rank Sum Test

```{r}
wilcox.result <- wilcox.test(body_mass_g ~ sex, data); wilcox.result
```

2.  Kruskal-Wallis Rank Sun Test

```{r}
kruskal.result <- kruskal.test(body_mass_g ~ species, data); kruskal.result
```

3.  다중비교 mctp in nparcomp package

```{r}
if(!require(nparcomp)) { install.packages("nparcomp"); library(nparcomp); }
mctp(body_mass_g ~ species, data)
```

### ANOVA in R

#### ANOVA 가정 점검

```{r}
if(!require(dplyr)) { install.packages("dplyr"); library(dplyr); }
if(!require(palmerpenguins)) { install.packages("palmerpenguins"); library(palmerpenguins); }
if(!require(ggplot2)) { install.packages("ggplot2"); library(ggplot2); }

data <- penguins %>% select(body_mass_g, species, sex) %>% na.omit()

ggplot(data, aes(species, body_mass_g, col=sex)) +
  geom_boxplot() +
  theme_bw()
```

펭귄 종에 따른 몸무게의 유의한 차이가 있는지 ANOVA로 분석한다. 신뢰성 있는 결과 도출을 위해 아래의 가정을 확인한다.

-   변수 유형 독립변수 범주형, 종속변수 연속형

```{r}
str(data)
```

-   독립성, *durbinWatsonTest()* 함수를 통해 통계적으로 검정

```{r}
if(!require(car)) { install.packages("car"); library(car); }

data.aov <- aov(body_mass_g ~ species, data)
durbinWatsonTest(data.aov)
```

-   정규성

    -   Shapiro-Wilk normality test
    -   Kolmogorov-Smirnov test
    -   QQPlot, Histogram

    ```{r}
    # Shapiro-Wilk normality test
    shapiro.test(data.aov$residuals)
    ```

```{r}
# Kolmogorov-Smirnov test
ks.test(x = data$species, y = data$body_mass_g)
```

```{r}
# QQPlot, Histogram
qqPlot(data.aov)
```

-   등분산성
    -   Levene's test
    -   Bartlette test
    -   Boxplot

```{r}
leveneTest(body_mass_g ~ species, data)
```

```{r}
leveneTest(body_mass_g ~ species*sex, data)
```

```{r}
bartlett.test(body_mass_g ~ species, data)
```

```{r}
bartlett.test(body_mass_g ~ interaction(species,sex), data)
```

-   이상치
    -   Boxplot, outlierTest()

```{r}
outlierTest(data.aov)
```

```{r}
range(data$body_mass_g); data[164,]
```

#### ANOVA

-   oneway.test(..., var.equal=)

```{r}
oneway.result <- oneway.test(body_mass_g ~ species, data, var.equal = F); oneway.result
```

-   aov()

```{r}
aov.result <- aov(body_mass_g ~ species, data)
summary(aov.result)
```

-   Kruskal-Wallis test (정규성 불만족 시)

```{r}
kruskal.test(body_mass_g ~ species, data)
```

#### 사후검정

-   Tukey HSD

```{r}
TukeyHSD(aov.result)
```

```{r}
if(!require(multcomp)) { install.packages("multcomp"); library(multcomp); }
tukey.result <- glht(aov.result, 
                       linfct = mcp(species = "Tukey")); tukey.result
```

```{r}
plot(tukey.result, las=1)
```

-   Dunnett

```{r}
if(!require(multcomp)) { install.packages("multcomp"); library(multcomp); }
dunnett.result <- glht(aov.result, 
                       linfct = mcp(species = "Dunnett")); dunnett.result
```

-   Bonferroni correction

```{r}
pairwise.t.test(data$body_mass_g, data$species, p.adjust.method = "bonferroni")
```

## TIL20220323

### 히트맵 in R

```{r}
if(!require(palmerpenguins)) { install.packages("palmerpenguins"); library(palmerpenguins); }
data <- penguins

data.matrix <- as.matrix(cor(data[,3:6], use="complete.obs"))
```

#### heatmap() in base

```{r}
if(!require(reshape2)) { install.packages("reshape2"); library(reshape2); }

heatmap(data.matrix, Rowv = NA, Colv = NA)

```

#### heatmap.2() in gplots

```{r}
if(!require(gplots)) { install.packages("gplots"); library(gplots); }
heatmap.2(data.matrix, Rowv = NA, Colv = NA, )
```

#### geom_tile() in ggplot2

```{r}
if(!require(reshape2)) { install.packages("reshape2"); library(reshape2); }
if(!require(ggplot2)) { install.packages("ggplot2"); library(ggplot2); }


data.melted <- melt(data.matrix); head(data.melted)

ggplot(data.melted, aes(x=Var1, y=Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low="red", mid = "white", high="blue") +
  guides(fill = guide_colorbar(barwidth = .5, barheight = 15))
```

## TIL20220324

### 기계학습 모델링 with Caret

1.  데이터 준비
2.  데이터 탐색
3.  데이터 전처리
4.  데이터 분할
5.  모델 학습
6.  예측 및 성능평가
7.  모델 개선

```{r}
# 데이터 준비
if(!require(dplyr)) { install.packages("dplyr"); library(dplyr); }
if(!require(caret)) { install.packages("caret"); library(caret); }
if(!require(ggplot2)) { install.packages("ggplot2"); library(ggplot2); }
if(!require(mlbench)) { install.packages("mlbench"); library(mlbench); }
data <- BreastCancer
```


```{r}
# 데이터 탐색
str(data)
```


```{r}
summary(data)
```

```{r}
colSums(is.na(data))
```

```{r}
table(data$Class)
```


```{r}
# 데이터 전처리
if(!require(dplyr)) { install.packages("dplyr"); library(dplyr); }

data <- data %>% select(-Id) # 필요한 컬럼 제외
data <- data %>% na.omit() # 결측치 제외 (16/699이므로)
```


```{r}
# 데이터 분할
if(!require(caret)) { install.packages("caret"); library(caret); }

train.index <- createDataPartition(data$Class, p=.7, list=F)
data.train <- data[train.index, ]
data.test <- data[-train.index, ]
```


```{r}
# 모델 학습
trCtrl.up <- trainControl(sampling = "up")
trCtrl.down <- trainControl(sampling = "down")

model.dt.up <- train(Class ~ ., data = data.train, method = "rpart", trControl = trCtrl.up)
model.dt.down <- train(Class ~ ., data = data.train, method = "rpart", trControl = trCtrl.down)

model.list <- list(up = model.dt.up, down = model.dt.down)
model.resamples <- resamples(model.list)
dotplot(model.resamples)
```


```{r}
# 예측 및 성능평가
model.dt.up.pred <- predict(model.dt.up, data.test)
model.dt.down.pred <- predict(model.dt.down, data.test)
rbind(up = mean(model.dt.up.pred == data.test$Class),
      down = mean(model.dt.down.pred == data.test$Class) )
```

```{r}
if(!require(pROC)) { install.packages("pROC"); library(pROC); }
model.dt.up.pred <- predict(model.dt.up, data.test, type = "prob")
model.dt.down.pred <- predict(model.dt.down, data.test, type = "prob")
roc(data.test$Class, model.dt.up.pred[,1], plot=T, print.auc=T, col="red")
roc(data.test$Class, model.dt.down.pred[,1], plot=T, print.auc=T, add=T, col="blue", print.auc.adj=c(0,-1))
text(1.2, 0.8, "Blue: Down sampling\nRed: Up sampling")
```
### 다중범주 ROC

```{r}
if(!require(rpart)) { install.packages("rpart"); library(rpart); }
data <- penguins
data <- na.omit(data)
set.seed(1234)
train.index <- sample(nrow(data), 0.7*nrow(data), replace=F) 
train <- data[train.index,]
test <- data[-train.index,]
model.dt <- rpart(species ~ ., train)
model.dt.pred <- predict(model.dt, test, type="class")

if(!require(pROC)) { install.packages("pROC"); library(pROC); }
mroc <- multiclass.roc(test$species, as.numeric(model.dt.pred))
pROC::plot.roc(mroc$rocs[[1]], plot=T, col=1, print.auc=T)
for(i in 2:3) {
  pROC::plot.roc(mroc$rocs[[i]], plot=T, col=i, print.auc=T, add=T,
                 print.auc.adj = c(0,i))
}
```

## TIL20220325

아... 이날은 잊지 말자 🤮

## TIL20220326

[Github] 깃허브 커밋 날짜를 조작하고 싶지 않으신가요? ^[https://cindycho.tistory.com/71]  

이게 되는구나...

## TIL20220327

```{r}
if(!require(ggplot2)) { install.packages("ggplot2"); library(ggplot2); }

x <- seq(-4, 4, length=100)
y3 <- dt(x, df=3)
y10 <- dt(x, df=10)
y50 <- dt(x, df=50)

ggplot(data.frame(x,y3), aes(x,y3)) +
  geom_line(col=1) +
  geom_line(aes(x, y10), col=2) +
  geom_line(aes(x, y50), col=3) +
  geom_text(aes(-3, 0.3, label="df=50"), color=3) +
  geom_text(aes(-3, 0.25, label="df=10"), col=2) +
  geom_text(aes(-3, 0.2, label="df=3"), col=1) +
  theme_bw()
```

```{r}
str(cars)
plot(cars$speed, cars$dist)
```


```{r}
x <- seq(-4, 4, length=100)
y1 <- dnorm(x, sd=1)
y2 <- dnorm(x, sd=2)
ggplot(data.frame(x,y1), aes(x,y1)) +
  geom_line() +
  geom_line(aes(y=y2), col=2)
```

$$CV, coefficient of variance = \frac{s}{\bar x}$$

```{r}
if(!require(palmerpenguins)) { install.packages("palmerpenguins"); library(palmerpenguins); }
pa <- subset(penguins[penguins$species=="Adelie", ], select = c("species", "body_mass_g"))
pg <- subset(penguins[penguins$species=="Gentoo", ], select = c("species", "body_mass_g"))

pa.cv <- sd(pa$body_mass_g, na.rm=T)/mean(pa$body_mass_g, na.rm = T)
pg.cv <- sd(pg$body_mass_g, na.rm=T)/mean(pg$body_mass_g, na.rm = T)
cv <- rbind(Adelie = pa.cv, Gentoo = pg.cv)
colnames(cv) <- c("CV"); cv
```

Adelie가 Gentoo에 비해 변동성이 큰 것을 알 수 있다.

```{r}
boxplot(pa$body_mass_g, pg$body_mass_g)
```

## TIL20220328

`베르누이 시행`  
:  p의 확률로 원하는 결과가 나타났을 때 성공으로 (1-p)의 확률로 그렇지 않은 결과가 나타났을 때 실패로 하는 두 가지 결과가 나타나는 확률실험을 베르누이 시행이라 한다.  

`이항 분포`  
:  성공 확률이 p로 동일한 베르누이 시행을 n번 반복해서 실험하는 경우, 실험이 n번 반복되더라도 성공 확률 p는 변하지 않고 동일한것으로 이는 앞의 실험이 뒤에 할 실험에 영향을 끼치지 않고 각 실험이 서로 독립적으로 실행될 때 이와 같은 실험에서 성공 횟수가 따르는 분포함수를 이항분포라 한다.  

`이항 계수`  
:  $p^x(1-p)^{n-x}$


```{r}
n <- 6
p <- 1/3
x <- 0:n

dbinom(2, size = n, prob = p)
dbinom(4, size = n, prob = p)
px <- dbinom(x, size = n, prob = p)
plot(x, px, type="s",xlab="성공횟수", ylab="확률", main="B(6, 1/3)")
```

```{r}
# B(6, 1/3)의 기댓값과 분산
n <- 6
p <- 1/3
x <- 0:n
px <- dbinom(x, size = n, prob = p)

ex <- sum(x * px)
ex2 <- sum(x^2 * px)

# V(X) = E(X^2) - {E(X)}^2
varx <- ex2 - ex^2; varx
```

```{r}
options(digits = 3)

mu = 170
sigma <- 6
ll <- mu - 3*sigma
ul <- mu + 3*sigma

x <- seq(ll, ul, by=0.01)
nd <- dnorm(x, mean=mu, sd=sigma)
plot(x, nd, type="l", xlab="x", ylab="P(X=x)", lwd=2, col="red"); abline(v=mu)
```

```{r}
options(digis=5)
set.seed(5)
smp <- rnorm(400, mean=mu, sd=sigma)
c(mean(smp), sd(smp))
hist(smp, prob=T, main="N(170, 6^2)으로부터 추출한 표본의 분포(n=400)", xlab="", ylab="", border="black"); lines(x, nd, lty=2)
```

```{r}
x <- seq(ll, ul, length = 400)
nd <- dnorm(x, mean=mean(smp), sd=sd(smp))
plot(x, nd, type="l", xlab="x", ylab="P(X=x)", lwd=2, col="red");abline(v=mean(smp))
```

## TIL20220329

```{r}
v <- c(1,4,5)
for (i in v) {
  print(i)
}
```

`모수`  
:  모집단의  특성을 나타내는 값, parameter  

`통계량`  
:  표본으로부터 관찰되는 표본의 특성, statistic  

`표본분포`  
:  표본 크기가 n으로 정해졌을 때 추출될 수 있는 모든 표본으로부터 구한 통계량들로 구성된 확률분포

```{r}
# 모집단 100개 중 표본 크기 10이 되도록 하는 표본추출의 경우의 수
choose(100, 10)
```

```{r}
# 카드 4장 중 2장 선택
choose(4, 2)
```

표본평균 $\bar{x}$의 분포

```{r}
m10 <- rep(NA, 1000)
m40 <- rep(NA, 1000)
set.seed(9)
for(i in 1:1000) {
  m10[i] <- mean(rnorm(10))
  m40[i] <- mean(rnorm(40))
}

options(digits = 4)
c(mean(m10), sd(m10))
c(mean(m40), sd(m40))

par(mfrow = c(1,2))
hist(m10, xlim = c(-1.5, 1.5), main="", xlab="x", ylab="y",
     col="cyan", border = "blue")
hist(m40, xlim = c(-1.5, 1.5), main="", xlab="x", ylab="y",
     col="cyan", border = "blue")
par(mfrow = c(1,1))
```

표본 크기가 클수록 기댓값 주변에 많이 몰려 있으며 자료가 분포하는 전체 폭이 줄어듦을 볼 수 있다.

## TIL20220330

### 정규분포에서 추출한 표본평균의 분포

```{r}
set.seed(9)
n <- 1000
r.1.mean <- rep(NA, n)
r.2.mean <- rep(NA, n)

for(i in 1:n) {
  r.1.mean[i] <- mean(rnorm(4, mean=3, sd=1))
  r.2.mean[i] <- mean(rnorm(4, mean=170, sd=6))
}

options(digits = 4)
c(mean(r.1.mean), sd(r.1.mean))
c(mean(r.2.mean), sd(r.2.mean))

{hist(r.1.mean, prob=T, xlab="표본평균", ylab="밀도", main="", col="orange", border="red")
x1 <- seq(min(r.1.mean), max(r.1.mean), length=1000)
y1 <- dnorm(x=x1, mean=3, sd=(1/sqrt(4)))
lines(x1, y1, lty=2, lwd=2, col="blue")}
```

```{r}
{hist(r.2.mean, prob=T, xlab="표본평균", ylab="밀도", main="", col="orange", border="red")
x2 <- seq(min(r.2.mean), max(r.2.mean), length=1000)
y2 <- dnorm(x=x2, mean=170, sd=(6/sqrt(4)))
lines(x2, y2, lty=2, lwd=2, col="blue")}
```

모집단이 정규분포를 다를 경우 표본평균의 분포가 정규분포와 유사함을 확인할 수 있다.

$$
\bar{X} \sim N(\mu, (\frac{\sigma}{\sqrt{n}})^2)
$$

### 모집단이 정규분포 이외의 분포를 따를 경우

시행횟수가 10회, 성공확률이 0.1인 이항분포 B(10, 0.1)의 평균 1, 표준편차 0.9487일 때, 표본 크기 2,4,32로 늘릴 경우

B(10, 01), E(X) = np, VAR(X) = np(1-p)이므로

```{r}
t <- 10; p <- 0.1; x <- 0:10;
px <- dbinom(0:10, 10, prob=0.1)
names(px) <- 0:10
barplot(px, col="orange", border="red")
```

```{r}
set.seed(9)
t <- 10
p <- 0.1
x <- 0:10
n <- 1000
b.2.mean <- rep(NA, n)
b.4.mean <- rep(NA, n)
b.32.mean <- rep(NA, n)

for(i in 1:n) {
  b.2.mean[i] <- mean(rbinom(2, size=t, prob=p))
  b.4.mean[i] <- mean(rbinom(4, size=t, prob=p))
  b.32.mean[i] <- mean(rbinom(32, size=t, prob=p))
}

options(digits = 4)
c(mean(b.2.mean), sd(b.2.mean))
c(mean(b.4.mean), sd(b.4.mean))
c(mean(b.32.mean), sd(b.32.mean))
```

```{r}
{hist(b.2.mean, prob=T, xlim=c(0,4), main="표본크기: 2", col="orange", border="red")
x1 <- seq(min(b.2.mean), max(b.2.mean), length=1000)
y1 <- dnorm(x=x1, mean = 1, sd = sqrt(0.9)/sqrt(2))
lines(x1, y1, lty=2, lwd=2, col="blue")}
```

```{r}
{hist(b.4.mean, prob=T, xlim=c(0,4), main="표본크기: 8", col="orange", border="red")
x2 <- seq(min(b.4.mean), max(b.4.mean), length=1000)
y2 <- dnorm(x=x2, mean = 1, sd = sqrt(0.9)/sqrt(8))
lines(x2, y2, lty=2, lwd=2, col="blue")}
```

```{r}
{hist(b.32.mean, prob=T, xlim=c(0,4), main="표본크기: 32", col="orange", border="red")
x3 <- seq(min(b.32.mean), max(b.32.mean), length=1000)
y3 <- dnorm(x=x3, mean = 1, sd = sqrt(0.9)/sqrt(32))
lines(x3, y3, lty=2, lwd=2, col="blue")}
```





